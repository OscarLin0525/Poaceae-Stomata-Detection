# Multi-Teacher Knowledge Distillation (MTKD) Framework

ç”¨æ–¼ç¦¾æœ¬ç§‘æ°£å­”æª¢æ¸¬çš„å¤šæ•™å¸«çŸ¥è­˜è’¸é¤¾æ¡†æ¶

## ç›®éŒ„

1. [æ¡†æ¶æ¦‚è¿°](#æ¡†æ¶æ¦‚è¿°)
2. [æ¶æ§‹è¨­è¨ˆ](#æ¶æ§‹è¨­è¨ˆ)
3. [å®‰è£èˆ‡ä¾è³´](#å®‰è£èˆ‡ä¾è³´)
4. [å¿«é€Ÿé–‹å§‹](#å¿«é€Ÿé–‹å§‹)
5. [æ¨¡çµ„è©³è§£](#æ¨¡çµ„è©³è§£)
6. [å‡½æ•¸åƒè€ƒ](#å‡½æ•¸åƒè€ƒ)
7. [é…ç½®èªªæ˜](#é…ç½®èªªæ˜)
8. [è¨“ç·´æŒ‡å—](#è¨“ç·´æŒ‡å—)
9. [è‡ªå®šç¾©æ“´å±•](#è‡ªå®šç¾©æ“´å±•)
10. [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)
11. [â­ YOLO Student æ•´åˆæŒ‡å—](#yolo-student-æ•´åˆæŒ‡å—)
12. [â­ å¯¦ä½œç´°ç¯€èˆ‡ç‹€æ…‹](#å¯¦ä½œç´°ç¯€èˆ‡ç‹€æ…‹)

---

## æ¡†æ¶æ¦‚è¿°

### ä»€éº¼æ˜¯ MTKDï¼Ÿ

Multi-Teacher Knowledge Distillation (MTKD) æ˜¯ä¸€ç¨®çµåˆå¤šå€‹æ•™å¸«æ¨¡å‹ä¾†è¨“ç·´å­¸ç”Ÿæ¨¡å‹çš„çŸ¥è­˜è’¸é¤¾æ–¹æ³•ã€‚æœ¬æ¡†æ¶å°ˆç‚ºç‰©é«”æª¢æ¸¬ä»»å‹™è¨­è¨ˆï¼Œçµåˆï¼š

1. **DINO Feature Teacher**: æä¾›å¼·å¤§çš„è¦–è¦ºç‰¹å¾µè¡¨ç¤ºï¼Œç”¨æ–¼ç‰¹å¾µå°é½Š
2. **Detection Teacher(s)**: é è¨“ç·´æª¢æ¸¬æ¨¡å‹ï¼ˆå–®ä¸€æˆ–é›†æˆï¼‰ï¼Œç”¨æ–¼é æ¸¬å°é½Š
3. **Student Detector**: è¦è¨“ç·´çš„å­¸ç”Ÿæ¨¡å‹

### æ”¯æ´çš„æ¶æ§‹

| æ¶æ§‹ | Feature Teacher | Detection Teacher | Student | ç‹€æ…‹ |
|-----|-----------------|-------------------|---------|------|
| **DETR-like** | DINO ViT | Ensemble (WBF) | DETR | âœ… å·²å¯¦ä½œ |
| **YOLO** | DINO ViT | YOLOv8 (å–®ä¸€) | YOLOv11 | ğŸ”„ è¦åŠƒä¸­ |

**æ¨è–¦ï¼šYOLO æ¶æ§‹**ï¼ˆè¦‹ [YOLO Student æ•´åˆæŒ‡å—](#yolo-student-æ•´åˆæŒ‡å—)ï¼‰
- YOLOv8 ä½œç‚º Teacherï¼šæˆç†Ÿç©©å®šï¼Œæä¾›é«˜å“è³ªé æ¸¬
- YOLOv11 ä½œç‚º Studentï¼šC3k2 + C2PSA æ¶æ§‹ï¼Œå­¸ç¿’èƒ½åŠ›å¼·ï¼Œæ”¶æ–‚å¿«

### æ ¸å¿ƒå„ªå‹¢

- **å¤šæºçŸ¥è­˜**: å¾ç‰¹å¾µå’Œé æ¸¬å…©å€‹ç¶­åº¦é€²è¡ŒçŸ¥è­˜è’¸é¤¾
- **éˆæ´»æ¶æ§‹**: æ”¯æŒ DETR-like æˆ– YOLO æ¶æ§‹
- **æ˜“æ–¼æ“´å±•**: æ¨¡çµ„åŒ–è¨­è¨ˆï¼Œæ–¹ä¾¿æ·»åŠ æ–°çµ„ä»¶
- **Hungarian Matching**: è‡ªå‹•è™•ç†ä¸åŒæ•¸é‡çš„é æ¸¬é…å°

---

## æ¶æ§‹è¨­è¨ˆ

### æ•´é«”æ¶æ§‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          Input Image                                â”‚
â”‚                              â”‚                                      â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚          â”‚                   â”‚                   â”‚                 â”‚
â”‚          â–¼                   â–¼                   â–¼                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ DINO Teacher  â”‚  â”‚   Student     â”‚  â”‚ Ensemble Teachers  â”‚     â”‚
â”‚  â”‚   (Frozen)    â”‚  â”‚  (Trainable)  â”‚  â”‚     (Frozen)       â”‚     â”‚
â”‚  â”‚               â”‚  â”‚               â”‚  â”‚                    â”‚     â”‚
â”‚  â”‚  ViT-Base/    â”‚  â”‚  Backbone     â”‚  â”‚  Teacher1          â”‚     â”‚
â”‚  â”‚  Large        â”‚  â”‚     â†“         â”‚  â”‚  Teacher2          â”‚     â”‚
â”‚  â”‚               â”‚  â”‚   Neck        â”‚  â”‚     â†“              â”‚     â”‚
â”‚  â”‚               â”‚  â”‚     â†“         â”‚  â”‚  Weighted Box      â”‚     â”‚
â”‚  â”‚               â”‚  â”‚   Head        â”‚  â”‚  Fusion            â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚          â”‚                  â”‚                     â”‚                â”‚
â”‚          â”‚ Features         â”‚ Features &          â”‚ Predictions    â”‚
â”‚          â”‚                  â”‚ Predictions         â”‚                â”‚
â”‚          â”‚                  â”‚                     â”‚                â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚                       â”‚                                             â”‚
â”‚                       â–¼                                             â”‚
â”‚          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚          â”‚            MTKD Loss                    â”‚               â”‚
â”‚          â”‚                                         â”‚               â”‚
â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚               â”‚
â”‚          â”‚  â”‚  Feature    â”‚  â”‚   Prediction    â”‚  â”‚               â”‚
â”‚          â”‚  â”‚  Alignment  â”‚  â”‚   Alignment     â”‚  â”‚               â”‚
â”‚          â”‚  â”‚  Loss       â”‚  â”‚   Loss          â”‚  â”‚               â”‚
â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚               â”‚
â”‚          â”‚                                         â”‚               â”‚
â”‚          â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚               â”‚
â”‚          â”‚  â”‚  Detection Loss (Optional)      â”‚   â”‚               â”‚
â”‚          â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚               â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è³‡æ–™å¤¾çµæ§‹

```
mtkd_framework/
â”œâ”€â”€ __init__.py                 # æ¡†æ¶å…¥å£
â”œâ”€â”€ README.md                   # æœ¬æ–‡æª”
â”œâ”€â”€ train.py                    # è¨“ç·´è…³æœ¬
â”‚
â”œâ”€â”€ models/                     # æ¨¡å‹æ¨¡çµ„
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ mtkd_model.py          # ä¸»è¦ MTKD æ¨¡å‹
â”‚   â”œâ”€â”€ student_model.py       # Student æ¨¡å‹
â”‚   â””â”€â”€ teacher_ensemble.py    # Teacher Ensemble
â”‚
â”œâ”€â”€ losses/                     # æå¤±å‡½æ•¸æ¨¡çµ„
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ feature_alignment.py   # ç‰¹å¾µå°é½Šæå¤±
â”‚   â”œâ”€â”€ prediction_alignment.py # é æ¸¬å°é½Šæå¤±
â”‚   â””â”€â”€ combined_loss.py       # çµ„åˆæå¤±
â”‚
â””â”€â”€ utils/                      # å·¥å…·å‡½æ•¸
    â”œâ”€â”€ __init__.py
    â””â”€â”€ helpers.py             # è¼”åŠ©å‡½æ•¸
```

---

## å®‰è£èˆ‡ä¾è³´

### ä¾è³´é …

```bash
pip install torch>=2.0.0
pip install torchvision>=0.15.0
pip install numpy
pip install scipy  # ç”¨æ–¼ Hungarian matching
```

### å¯é¸ä¾è³´

```bash
pip install fvcore  # ç”¨æ–¼è¨ˆç®— FLOPs
pip install tensorboard  # ç”¨æ–¼è¨“ç·´å¯è¦–åŒ–
```

---

## å¿«é€Ÿé–‹å§‹

### åŸºæœ¬ä½¿ç”¨

```python
from mtkd_framework import MTKDModel, MTKDLoss

# 1. å‰µå»ºæ¨¡å‹
model = MTKDModel(
    student_config={
        "backbone_config": {"backbone_type": "resnet50"},
        "head_config": {"num_classes": 1, "num_queries": 100},
    },
    dino_teacher_config={"model_name": "vit_base"},
    num_classes=1,
)

# 2. è¼‰å…¥é è¨“ç·´çš„ teachers
model.dino_teacher.load_pretrained("path/to/dino_checkpoint.pth")
model.ensemble_teachers.add_teacher(teacher1_model, weight=0.6)
model.ensemble_teachers.add_teacher(teacher2_model, weight=0.4)

# 3. è¨“ç·´
optimizer = torch.optim.AdamW(model.get_trainable_parameters(), lr=1e-4)

for epoch in range(100):
    for images, targets in train_loader:
        loss, loss_dict = model.training_step(images, targets, epoch=epoch)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

# 4. æ¨ç†
model.eval()
detections = model.inference(test_images, score_threshold=0.5)
```

### ä½¿ç”¨è¨“ç·´è…³æœ¬

```bash
# æ¸¬è©¦é‹è¡Œï¼ˆä½¿ç”¨ dummy æ•¸æ“šï¼‰
python -m mtkd_framework.train --test_run --epochs 2

# æ­£å¼è¨“ç·´
python -m mtkd_framework.train \
    --config config.json \
    --dino_checkpoint path/to/dino.pth \
    --epochs 100 \
    --batch_size 8 \
    --lr 1e-4
```

---

## æ¨¡çµ„è©³è§£

### 1. Feature Alignment Loss (`losses/feature_alignment.py`)

ç”¨æ–¼å°é½Š DINO teacher å’Œ student çš„ç‰¹å¾µè¡¨ç¤ºã€‚

#### FeatureAlignmentLoss

```python
class FeatureAlignmentLoss(nn.Module):
    """
    ç‰¹å¾µå°é½Šæå¤±

    æ”¯æŒå¤šç¨®æå¤±é¡å‹ï¼š
    - "l2": MSE æå¤±
    - "cosine": Cosine Similarity æå¤±
    - "kl": KL Divergence æå¤±
    - "smooth_l1": Smooth L1 æå¤±
    """
```

**åˆå§‹åŒ–åƒæ•¸ï¼š**

| åƒæ•¸ | é¡å‹ | é»˜èªå€¼ | èªªæ˜ |
|------|------|--------|------|
| `loss_type` | str | "l2" | æå¤±é¡å‹ |
| `temperature` | float | 1.0 | KL divergence æº«åº¦ |
| `normalize` | bool | True | æ˜¯å¦ L2 æ­£è¦åŒ– |
| `reduction` | str | "mean" | Reduction æ–¹å¼ |

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from mtkd_framework.losses import FeatureAlignmentLoss

# å‰µå»ºæå¤±å‡½æ•¸
loss_fn = FeatureAlignmentLoss(loss_type="cosine", normalize=True)

# è¨ˆç®—æå¤±
student_feat = torch.randn(4, 768)  # [B, D]
teacher_feat = torch.randn(4, 768)
loss = loss_fn(student_feat, teacher_feat)
```

**æå¤±å…¬å¼ï¼š**

- **L2 Loss**: $L = \frac{1}{N} \sum_{i=1}^{N} ||s_i - t_i||_2^2$

- **Cosine Loss**: $L = 1 - \frac{s \cdot t}{||s|| \cdot ||t||}$

- **KL Loss**: $L = T^2 \cdot \sum_i p_t(i) \log \frac{p_t(i)}{p_s(i)}$

  å…¶ä¸­ $p_t = \text{softmax}(t/T)$, $p_s = \text{softmax}(s/T)$

#### MultiScaleFeatureAlignmentLoss

```python
class MultiScaleFeatureAlignmentLoss(nn.Module):
    """
    å¤šå°ºåº¦ç‰¹å¾µå°é½Šæå¤±

    ç”¨æ–¼å°é½Š FPN ç­‰å¤šå°ºåº¦ç‰¹å¾µã€‚
    """
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from mtkd_framework.losses import MultiScaleFeatureAlignmentLoss

loss_fn = MultiScaleFeatureAlignmentLoss(
    num_scales=4,
    student_channels=[256, 256, 256, 256],
    teacher_channels=[768, 768, 768, 768],
    scale_weights=[1.0, 1.0, 1.0, 1.0],
)

student_feats = [torch.randn(4, 256, 56, 56) for _ in range(4)]
teacher_feats = [torch.randn(4, 768, 56, 56) for _ in range(4)]
loss = loss_fn(student_feats, teacher_feats)
```

---

### 2. Prediction Alignment Loss (`losses/prediction_alignment.py`)

ç”¨æ–¼å°é½Š ensemble teachers å’Œ student çš„é æ¸¬ã€‚

#### BoxAlignmentLoss

```python
class BoxAlignmentLoss(nn.Module):
    """
    Bounding Box å°é½Šæå¤±

    æ”¯æŒï¼š
    - "l1": L1 æå¤±
    - "smooth_l1": Smooth L1 æå¤±
    - "giou": Generalized IoU æå¤±
    - "ciou": Complete IoU æå¤±
    """
```

**GIoU è¨ˆç®—å…¬å¼ï¼š**

$$\text{GIoU} = \text{IoU} - \frac{|C - (A \cup B)|}{|C|}$$

å…¶ä¸­ $C$ æ˜¯åŒ…å« $A$ å’Œ $B$ çš„æœ€å°é–‰åŒ…å€åŸŸã€‚

**CIoU è¨ˆç®—å…¬å¼ï¼š**

$$\text{CIoU} = \text{IoU} - \frac{\rho^2(b, b^{gt})}{c^2} - \alpha v$$

å…¶ä¸­ï¼š
- $\rho$: ä¸­å¿ƒé»è·é›¢
- $c$: é–‰åŒ…å°è§’ç·šé•·åº¦
- $v$: å¯¬é«˜æ¯”ä¸€è‡´æ€§
- $\alpha$: æ¬Šé‡åƒæ•¸

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from mtkd_framework.losses import BoxAlignmentLoss

loss_fn = BoxAlignmentLoss(loss_type="giou", box_format="cxcywh")

student_boxes = torch.randn(100, 4)  # [N, 4] (cx, cy, w, h)
teacher_boxes = torch.randn(100, 4)
loss = loss_fn(student_boxes, teacher_boxes)
```

#### ClassAlignmentLoss

```python
class ClassAlignmentLoss(nn.Module):
    """
    é¡åˆ¥é æ¸¬å°é½Šæå¤±

    ä½¿ç”¨ KL Divergence å°é½Šåˆ†é¡é æ¸¬çš„æ¦‚ç‡åˆ†ä½ˆã€‚
    """
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from mtkd_framework.losses import ClassAlignmentLoss

loss_fn = ClassAlignmentLoss(
    loss_type="kl",
    temperature=4.0,  # è»ŸåŒ–æ¦‚ç‡åˆ†ä½ˆ
)

student_logits = torch.randn(100, 10)  # [N, num_classes]
teacher_logits = torch.randn(100, 10)
loss = loss_fn(student_logits, teacher_logits)
```

#### PredictionAlignmentLoss

```python
class PredictionAlignmentLoss(nn.Module):
    """
    å®Œæ•´çš„é æ¸¬å°é½Šæå¤±

    çµ„åˆ Box å°é½Šå’Œ Class å°é½Šæå¤±ã€‚
    """
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from mtkd_framework.losses import PredictionAlignmentLoss

loss_fn = PredictionAlignmentLoss(
    box_loss_type="giou",
    class_loss_type="kl",
    box_weight=2.0,
    class_weight=1.0,
    temperature=4.0,
)

student_pred = {
    "boxes": torch.randn(4, 100, 4),   # [B, N, 4]
    "logits": torch.randn(4, 100, 10),  # [B, N, num_classes]
}
teacher_pred = {
    "boxes": torch.randn(4, 100, 4),
    "logits": torch.randn(4, 100, 10),
}

loss, loss_dict = loss_fn(student_pred, teacher_pred)
```

---

### 3. Teacher Ensemble (`models/teacher_ensemble.py`)

ç®¡ç†å¤šå€‹æ•™å¸«æ¨¡å‹ä¸¦èåˆå®ƒå€‘çš„é æ¸¬ã€‚

#### WeightedBoxFusion

```python
class WeightedBoxFusion(nn.Module):
    """
    Weighted Box Fusion (WBF)

    å°‡å¤šå€‹æ¨¡å‹çš„ bounding box é æ¸¬é€²è¡ŒåŠ æ¬Šèåˆã€‚
    èˆ‡ NMS ä¸åŒï¼ŒWBF æœƒèåˆé‡ç–Šçš„ boxes è€ŒéæŠ‘åˆ¶å®ƒå€‘ã€‚
    """
```

**WBF ç®—æ³•æµç¨‹ï¼š**

1. æŒ‰ä¿¡å¿ƒåº¦æ’åºæ‰€æœ‰é æ¸¬
2. å°æ¯å€‹é¡åˆ¥åˆ†åˆ¥è™•ç†
3. å°‡ IoU è¶…éé–¾å€¼çš„ boxes èšé¡
4. å°æ¯å€‹ cluster è¨ˆç®—åŠ æ¬Šå¹³å‡ box
5. æ ¹æ“šåƒèˆ‡çš„æ¨¡å‹æ•¸é‡èª¿æ•´ä¿¡å¿ƒåº¦

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from mtkd_framework.models import WeightedBoxFusion

wbf = WeightedBoxFusion(
    iou_threshold=0.55,
    weights=[0.6, 0.4],  # å…©å€‹æ¨¡å‹çš„æ¬Šé‡
    conf_type="avg",
)

# ä¾†è‡ªå…©å€‹æ¨¡å‹çš„é æ¸¬
boxes_list = [
    torch.tensor([[0.1, 0.1, 0.3, 0.3]]),  # model 1
    torch.tensor([[0.12, 0.11, 0.31, 0.32]]),  # model 2
]
scores_list = [torch.tensor([0.9]), torch.tensor([0.85])]
labels_list = [torch.tensor([0]), torch.tensor([0])]

# èåˆ
fused_boxes, fused_scores, fused_labels = wbf(boxes_list, scores_list, labels_list)
```

#### TeacherEnsemble

```python
class TeacherEnsemble(nn.Module):
    """
    Teacher Ensemble æ¨¡çµ„

    çµ„åˆå¤šå€‹é è¨“ç·´çš„ detection teacher æ¨¡å‹ã€‚
    """
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from mtkd_framework.models import TeacherEnsemble

# å‰µå»º ensemble
ensemble = TeacherEnsemble(
    teacher_weights=[0.6, 0.4],
    fusion_method="wbf",
    num_classes=1,
)

# æ·»åŠ æ•™å¸«æ¨¡å‹
ensemble.add_teacher(teacher1_model, weight=0.6)
ensemble.add_teacher(teacher2_model, weight=0.4)

# ç²å–èåˆé æ¸¬
predictions = ensemble(images)
# predictions = {"boxes": [...], "scores": [...], "labels": [...], "valid_mask": [...]}
```

---

### 4. Student Model (`models/student_model.py`)

å­¸ç”Ÿæª¢æ¸¬æ¨¡å‹ï¼ŒåŒ…å«ç‰¹å¾µé©é…å™¨ã€‚

#### FeatureAdapter

```python
class FeatureAdapter(nn.Module):
    """
    ç‰¹å¾µé©é…å™¨

    å°‡ student çš„ç‰¹å¾µç¶­åº¦è½‰æ›åˆ°èˆ‡ teacher ç›¸åŒã€‚

    æ”¯æŒé¡å‹ï¼š
    - "linear": ç·šæ€§æŠ•å½±
    - "mlp": å…©å±¤ MLP
    - "attention": ä½¿ç”¨ attention çš„é©é…
    """
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from mtkd_framework.models.student_model import FeatureAdapter

adapter = FeatureAdapter(
    student_dim=256,
    teacher_dim=768,
    adapter_type="mlp",
)

student_feat = torch.randn(4, 256)
aligned_feat = adapter(student_feat)  # [4, 768]
```

#### StudentDetector

```python
class StudentDetector(nn.Module):
    """
    Student Detector

    å®Œæ•´çš„å­¸ç”Ÿæª¢æ¸¬æ¨¡å‹ï¼š
    - Backbone: ç‰¹å¾µæå–
    - Neck (FPN): å¤šå°ºåº¦èåˆ
    - Head: æª¢æ¸¬é æ¸¬
    - Feature Adapter: èˆ‡ teacher å°é½Š
    """
```

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from mtkd_framework.models import StudentDetector

student = StudentDetector(
    backbone_config={"backbone_type": "resnet50", "pretrained": True},
    head_config={"num_classes": 1, "num_queries": 100},
    dino_teacher_dim=768,
)

outputs = student(images, return_adapted_features=True)
# outputs = {
#     "boxes": [...],
#     "logits": [...],
#     "adapted_features": [...],  # ç”¨æ–¼ç‰¹å¾µå°é½Š
# }
```

---

### 5. MTKD Model (`models/mtkd_model.py`)

æ•´åˆæ‰€æœ‰çµ„ä»¶çš„å®Œæ•´æ¨¡å‹ã€‚

#### MTKDModel

```python
class MTKDModel(nn.Module):
    """
    Multi-Teacher Knowledge Distillation Model

    æ•´åˆï¼š
    1. DINO Feature Teacher
    2. Ensemble Detection Teachers
    3. Student Detector
    4. MTKD Loss
    """
```

**ä¸»è¦æ–¹æ³•ï¼š**

| æ–¹æ³• | èªªæ˜ |
|------|------|
| `forward()` | å®Œæ•´å‰å‘å‚³æ’­ï¼Œè¿”å›è¼¸å‡ºå’Œæå¤± |
| `training_step()` | è¨“ç·´æ­¥é©Ÿï¼Œè¿”å›æå¤±å’Œæå¤±å­—å…¸ |
| `inference()` | æ¨ç†ï¼Œè¿”å›æª¢æ¸¬çµæœ |
| `get_trainable_parameters()` | ç²å–å¯è¨“ç·´åƒæ•¸ |

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from mtkd_framework import MTKDModel

model = MTKDModel(
    student_config={...},
    dino_teacher_config={"model_name": "vit_base"},
    ensemble_config={"teacher_weights": [0.6, 0.4]},
    loss_config={
        "feature_weight": 1.0,
        "prediction_weight": 2.0,
    },
)

# è¨“ç·´
loss, loss_dict = model.training_step(images, targets, epoch=epoch)

# æ¨ç†
detections = model.inference(images, score_threshold=0.5)
```

---

### 6. Combined Loss (`losses/combined_loss.py`)

çµ„åˆæ‰€æœ‰æå¤±çš„æ¨¡çµ„ã€‚

#### MTKDLoss

```python
class MTKDLoss(nn.Module):
    """
    çµ„åˆ MTKD æå¤±

    åŒ…å«ï¼š
    - Feature Alignment Loss
    - Prediction Alignment Loss
    - Detection Loss (å¯é¸)

    æ”¯æŒå‹•æ…‹æ¬Šé‡èª¿æ•´å’Œ warmupã€‚
    """
```

**æå¤±å…¬å¼ï¼š**

$$L_{total} = \alpha \cdot L_{feat} + \beta \cdot L_{pred} + \gamma \cdot L_{det}$$

å…¶ä¸­ï¼š
- $L_{feat}$: ç‰¹å¾µå°é½Šæå¤±
- $L_{pred}$: é æ¸¬å°é½Šæå¤±
- $L_{det}$: æª¢æ¸¬æå¤±ï¼ˆèˆ‡ ground truthï¼‰
- $\alpha, \beta, \gamma$: æ¬Šé‡ä¿‚æ•¸

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
from mtkd_framework.losses import MTKDLoss

loss_fn = MTKDLoss(
    feature_loss_config={"loss_type": "cosine"},
    prediction_loss_config={"box_loss_type": "giou"},
    feature_weight=1.0,
    prediction_weight=2.0,
    warmup_epochs=5,
    weight_schedule="cosine",
)

total_loss, loss_dict = loss_fn(
    student_features=student_feat,
    dino_teacher_features=dino_feat,
    student_predictions=student_pred,
    ensemble_teacher_predictions=ensemble_pred,
    epoch=current_epoch,
)
```

#### UncertaintyWeightedMTKDLoss

```python
class UncertaintyWeightedMTKDLoss(MTKDLoss):
    """
    åŸºæ–¼ä¸ç¢ºå®šæ€§çš„è‡ªå‹•åŠ æ¬Šæå¤±

    ä½¿ç”¨å¯å­¸ç¿’çš„æ¬Šé‡åƒæ•¸ï¼Œæ ¹æ“šåŒæ–¹å·®ä¸ç¢ºå®šæ€§è‡ªå‹•å­¸ç¿’æå¤±æ¬Šé‡ã€‚
    åƒè€ƒ: "Multi-Task Learning Using Uncertainty to Weigh Losses"
    """
```

**æå¤±å…¬å¼ï¼š**

$$L_{total} = \sum_i \frac{1}{2\sigma_i^2} L_i + \log \sigma_i$$

å…¶ä¸­ $\sigma_i$ æ˜¯å¯å­¸ç¿’çš„åƒæ•¸ã€‚

---

## å‡½æ•¸åƒè€ƒ

### å·¥å…·å‡½æ•¸ (`utils/helpers.py`)

#### save_checkpoint

```python
def save_checkpoint(
    model: nn.Module,
    optimizer: torch.optim.Optimizer,
    epoch: int,
    loss: float,
    save_path: str,
    scheduler: Optional = None,
    extra_info: Optional[Dict] = None,
):
    """ä¿å­˜è¨“ç·´ checkpoint"""
```

#### load_checkpoint

```python
def load_checkpoint(
    model: nn.Module,
    checkpoint_path: str,
    optimizer: Optional = None,
    scheduler: Optional = None,
    strict: bool = True,
) -> Dict:
    """è¼‰å…¥è¨“ç·´ checkpoint"""
```

#### AverageMeterDict

```python
class AverageMeterDict:
    """è¿½è¹¤å¤šå€‹æŒ‡æ¨™çš„å¹³å‡å€¼"""

    def update(self, values: Dict[str, float], n: int = 1): ...
    def get_averages(self) -> Dict[str, float]: ...
```

#### EarlyStopping

```python
class EarlyStopping:
    """Early Stopping æ©Ÿåˆ¶"""

    def __call__(self, score: float) -> bool:
        """è¿”å›æ˜¯å¦æ‡‰è©²åœæ­¢è¨“ç·´"""
```

---

## é…ç½®èªªæ˜

### é»˜èªé…ç½®

```python
config = {
    "model": {
        "num_classes": 1,
        "student_config": {
            "backbone_config": {
                "backbone_type": "resnet50",
                "pretrained": True,
            },
            "head_config": {
                "num_classes": 1,
                "num_queries": 100,
            },
        },
        "dino_teacher_config": {
            "model_name": "vit_base",
            "patch_size": 16,
        },
        "ensemble_config": {
            "fusion_method": "wbf",
            "fusion_config": {"iou_threshold": 0.55},
        },
        "loss_config": {
            "feature_weight": 1.0,
            "prediction_weight": 2.0,
            "warmup_epochs": 5,
        },
    },
    "training": {
        "epochs": 100,
        "batch_size": 8,
        "learning_rate": 1e-4,
        "weight_decay": 1e-4,
    },
}
```

---

## è¨“ç·´æŒ‡å—

### å®Œæ•´è¨“ç·´æµç¨‹

```python
import torch
from mtkd_framework import MTKDModel
from mtkd_framework.train import MTKDTrainer, get_default_config

# 1. æº–å‚™é…ç½®
config = get_default_config()
config["training"]["epochs"] = 100
config["training"]["batch_size"] = 8

# 2. å‰µå»ºæ•¸æ“šè¼‰å…¥å™¨
train_loader = create_your_dataloader(...)
val_loader = create_your_dataloader(...)

# 3. å‰µå»ºæ¨¡å‹
model = MTKDModel(
    student_config=config["model"]["student_config"],
    dino_teacher_config=config["model"]["dino_teacher_config"],
    loss_config=config["model"]["loss_config"],
)

# è¼‰å…¥é è¨“ç·´çš„ DINO
model.dino_teacher.load_pretrained("dino_vitb16.pth")

# æ·»åŠ é è¨“ç·´çš„æª¢æ¸¬ teachers
model.ensemble_teachers.add_teacher(load_detection_model("teacher1.pth"))
model.ensemble_teachers.add_teacher(load_detection_model("teacher2.pth"))

# 4. å‰µå»ºè¨“ç·´å™¨
trainer = MTKDTrainer(
    config=config,
    model=model,
    train_loader=train_loader,
    val_loader=val_loader,
)

# 5. é–‹å§‹è¨“ç·´
trainer.train()
```

### è¨“ç·´æŠ€å·§

1. **å­¸ç¿’ç‡èª¿åº¦**: ä½¿ç”¨ cosine annealing é…åˆ warmup
2. **æ¢¯åº¦è£å‰ª**: è¨­ç½® `gradient_clip_max_norm=1.0`
3. **æ··åˆç²¾åº¦**: å•Ÿç”¨ `mixed_precision=True` åŠ é€Ÿè¨“ç·´
4. **æå¤±æ¬Šé‡ warmup**: è¨­ç½® `warmup_epochs=5` é€æ¼¸å¢åŠ  KD æå¤±æ¬Šé‡

---

## è‡ªå®šç¾©æ“´å±•

### è‡ªå®šç¾© Student Backbone

```python
import torch.nn as nn
from mtkd_framework.models import StudentDetector

class CustomBackbone(nn.Module):
    def __init__(self):
        super().__init__()
        # ä½ çš„è‡ªå®šç¾©æ¶æ§‹
        self.layers = nn.Sequential(...)
        self._out_channels = [64, 128, 256, 512]

    @property
    def out_channels_list(self):
        return self._out_channels

    def forward(self, x):
        features = {}
        # è¿”å›å¤šå°ºåº¦ç‰¹å¾µ
        return features

# ä½¿ç”¨è‡ªå®šç¾© backbone
student = StudentDetector(
    custom_backbone=CustomBackbone(),
    head_config={...},
)
```

### è‡ªå®šç¾©æå¤±å‡½æ•¸

```python
from mtkd_framework.losses import FeatureAlignmentLoss

class CustomFeatureLoss(FeatureAlignmentLoss):
    def __init__(self, *args, custom_param=1.0, **kwargs):
        super().__init__(*args, **kwargs)
        self.custom_param = custom_param

    def forward(self, student_feat, teacher_feat, mask=None):
        # è‡ªå®šç¾©æå¤±è¨ˆç®—
        base_loss = super().forward(student_feat, teacher_feat, mask)
        custom_term = ...
        return base_loss + self.custom_param * custom_term
```

### æ·»åŠ æ–°çš„ Teacher

```python
from mtkd_framework.models import TeacherEnsemble

# å‰µå»º ensemble
ensemble = TeacherEnsemble(num_classes=1)

# æ·»åŠ è‡ªå®šç¾© teacher
class MyDetector(nn.Module):
    def forward(self, images):
        # è¿”å› {"boxes": ..., "scores": ..., "labels": ...}
        return predictions

teacher = MyDetector()
teacher.load_state_dict(torch.load("my_detector.pth"))
ensemble.add_teacher(teacher, weight=0.5)
```

---

## å¸¸è¦‹å•é¡Œ

### Q1: å¦‚ä½•è™•ç† teacher å’Œ student ç‰¹å¾µç¶­åº¦ä¸åŒ¹é…ï¼Ÿ

ä½¿ç”¨ `FeatureAdapter` è‡ªå‹•å°é½Šç¶­åº¦ï¼š

```python
from mtkd_framework.models.student_model import FeatureAdapter

adapter = FeatureAdapter(
    student_dim=256,
    teacher_dim=768,
    adapter_type="mlp",
)
```

### Q2: å¦‚ä½•åªä½¿ç”¨ç‰¹å¾µå°é½Šæˆ–é æ¸¬å°é½Šï¼Ÿ

èª¿æ•´æå¤±æ¬Šé‡ï¼š

```python
loss_config = {
    "feature_weight": 1.0,  # åªç”¨ç‰¹å¾µå°é½Š
    "prediction_weight": 0.0,  # ç¦ç”¨é æ¸¬å°é½Š
}
```

### Q3: å¦‚ä½•è™•ç†ä¸åŒæ•¸é‡çš„é æ¸¬ï¼Ÿ

ä½¿ç”¨ `HungarianMatchingLoss` é€²è¡ŒåŒ¹é…ï¼š

```python
from mtkd_framework.losses import HungarianMatchingLoss

loss_fn = HungarianMatchingLoss(
    box_cost_weight=5.0,
    class_cost_weight=2.0,
)
```

---

## YOLO Student æ•´åˆæŒ‡å—

> âš ï¸ **å¯¦ä½œç‹€æ…‹ï¼šè¦åŠƒä¸­ (Planning Stage)**
>
> æœ¬ç« ç¯€ç‚º YOLO æ•´åˆçš„è¨­è¨ˆè¦æ ¼æ›¸ï¼Œå°šæœªæœ‰å¯¦éš› Python å¯¦ä½œã€‚
>
> | é …ç›® | ç‹€æ…‹ |
> |------|------|
> | YOLOv8Teacher | âŒ å¾…å¯¦ä½œ |
> | YOLOv11StudentDetector | âŒ å¾…å¯¦ä½œ |
> | YOLOOutputWrapper | âŒ å¾…å¯¦ä½œ |
> | YOLOFeatureAdapter | âŒ å¾…å¯¦ä½œ |
>
> ç›®å‰ MTKD æ¡†æ¶å·²å¯¦ä½œçš„ Student ç‚º DETR-like æ¶æ§‹ï¼ˆ`StudentDetector`ï¼‰ã€‚

æœ¬ç« ç¯€èªªæ˜å¦‚ä½•å°‡ **YOLOv11** ä½œç‚º Student æ•´åˆåˆ° MTKD æ¡†æ¶ä¸­ï¼Œå¾ **DINO Teacher**ï¼ˆç‰¹å¾µï¼‰å’Œ **YOLOv8 Teacher**ï¼ˆé æ¸¬ï¼‰å­¸ç¿’ã€‚

### æ¶æ§‹è¨­è¨ˆç†å¿µ

MTKD æ¡†æ¶æ¡ç”¨é›™ Teacher è¨­è¨ˆï¼Œå„å¸å…¶è·ï¼š

| è§’è‰² | æ¨¡å‹ | è¼¸å‡º | ç”¨é€” |
|------|------|------|------|
| **Feature Teacher** | DINO ViT-B (Frozen .pth) | CLS token + Patch tokens | Feature Alignment |
| **Detection Teacher** | YOLOv8 (Frozen .pt) | Boxes + Scores + Labels | Prediction Alignment |
| **Student** | YOLOv11 (Trainable) | Features + Predictions | å­¸ç¿’å…©è€… |

**ç‚ºä»€éº¼é¸æ“‡ YOLOv11 ä½œç‚º Studentï¼Ÿ**

| æ¯”è¼ƒé …ç›® | YOLOv8 | YOLOv11 |
|---------|--------|---------|
| æ ¸å¿ƒæ¨¡çµ„ | C2f | C3k2 (æ›´é«˜æ•ˆçš„æ¢¯åº¦æµ) |
| æ³¨æ„åŠ›æ©Ÿåˆ¶ | ç„¡ | C2PSA (Position-Sensitive Attention) |
| è¨“ç·´æ”¶æ–‚é€Ÿåº¦ | è¼ƒæ…¢ (ç´„ 178 epochs é”åˆ° 0.01 loss) | è¼ƒå¿« (ç´„ 36 epochs é”åˆ°ç›¸åŒ loss) |
| è¼¸å‡ºæ ¼å¼ | boxes, scores, labels | èˆ‡ YOLOv8 ç›¸å®¹ |
| æ¨è–¦ç”¨é€” | **ä½œç‚ºæˆç†Ÿçš„ Teacher** | **ä½œç‚ºå­¸ç¿’èƒ½åŠ›å¼·çš„ Student** |

### æ•´é«”æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              Input Image (B, 3, H, W)                        â”‚
â”‚                                       â”‚                                      â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚         â”‚                             â”‚                         â”‚           â”‚
â”‚         â–¼                             â–¼                         â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  DINO Teacher    â”‚    â”‚   YOLOv11 Student       â”‚   â”‚  YOLOv8 Teacher  â”‚â”‚
â”‚  â”‚  (Frozen .pth)   â”‚    â”‚     (Trainable)         â”‚   â”‚  (Frozen .pt)    â”‚â”‚
â”‚  â”‚                  â”‚    â”‚                         â”‚   â”‚                  â”‚â”‚
â”‚  â”‚  ViT-B/16        â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚  Backbone        â”‚â”‚
â”‚  â”‚  patch_size=16   â”‚    â”‚  â”‚  Backbone   â”‚        â”‚   â”‚  Neck            â”‚â”‚
â”‚  â”‚                  â”‚    â”‚  â”‚ (C3k2+C2PSA)â”‚        â”‚   â”‚  Head            â”‚â”‚
â”‚  â”‚  è¼¸å‡º:           â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚                  â”‚â”‚
â”‚  â”‚  â€¢ cls_token     â”‚    â”‚         â”‚               â”‚   â”‚  è¼¸å‡º:           â”‚â”‚
â”‚  â”‚    (B, 768)      â”‚    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚  â€¢ boxes         â”‚â”‚
â”‚  â”‚  â€¢ patch_tokens  â”‚    â”‚  â”‚    Neck     â”‚        â”‚   â”‚    (B, N, 4)     â”‚â”‚
â”‚  â”‚    (B, 196, 768) â”‚    â”‚  â”‚   (PANet)   â”‚        â”‚   â”‚  â€¢ scores        â”‚â”‚
â”‚  â”‚                  â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜        â”‚   â”‚    (B, N)        â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚         â”‚               â”‚   â”‚  â€¢ labels        â”‚â”‚
â”‚           â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”        â”‚   â”‚    (B, N)        â”‚â”‚
â”‚           â”‚              â”‚  â”‚  P3 P4 P5   â”‚â—„â”€â”€â”€â”   â”‚   â”‚                  â”‚â”‚
â”‚           â”‚              â”‚  â”‚  Features   â”‚    â”‚   â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â”‚           â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚         â”‚           â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚  â”‚    Head     â”‚    â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚  â”‚ (Decoupled) â”‚    â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚         â”‚           â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”    â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚  â”‚    NMS      â”‚    â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚         â”‚           â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚  è¼¸å‡º:  â”‚           â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚  â€¢ boxes (B, M, 4)  â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚  â€¢ scores (B, M)    â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â”‚  â€¢ labels (B, M)    â”‚   â”‚            â”‚          â”‚
â”‚           â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚            â”‚          â”‚
â”‚           â”‚                        â”‚               â”‚            â”‚          â”‚
â”‚           â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚            â”‚          â”‚
â”‚           â”‚              â”‚                   â”‚     â”‚            â”‚          â”‚
â”‚           â–¼              â–¼                   â–¼     â”‚            â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚                           MTKD Loss                                     â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚â”‚
â”‚  â”‚   â”‚   Feature Alignment    â”‚      â”‚    Prediction Alignment        â”‚   â”‚â”‚
â”‚  â”‚   â”‚                        â”‚      â”‚                                â”‚   â”‚â”‚
â”‚  â”‚   â”‚  DINO cls_token        â”‚      â”‚  YOLOv8 Teacher predictions    â”‚   â”‚â”‚
â”‚  â”‚   â”‚       â†•                â”‚      â”‚         â†•                      â”‚   â”‚â”‚
â”‚  â”‚   â”‚  YOLO11 P4 (adapted)   â”‚      â”‚  YOLOv11 Student predictions   â”‚   â”‚â”‚
â”‚  â”‚   â”‚                        â”‚      â”‚                                â”‚   â”‚â”‚
â”‚  â”‚   â”‚  â€¢ Cosine Similarity   â”‚      â”‚  â€¢ Hungarian Matching          â”‚   â”‚â”‚
â”‚  â”‚   â”‚  â€¢ L2 Distance         â”‚      â”‚  â€¢ GIoU Loss (boxes)           â”‚   â”‚â”‚
â”‚  â”‚   â”‚                        â”‚      â”‚  â€¢ KL Divergence (logits)      â”‚   â”‚â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚â”‚
â”‚  â”‚                                                                         â”‚â”‚
â”‚  â”‚   L_total = Î»_feat Ã— L_feature + Î»_pred Ã— L_prediction                  â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è³‡æ–™æµè©³è§£

```
1. Input Image â†’ åŒæ™‚è¼¸å…¥ä¸‰å€‹æ¨¡å‹

2. DINO Teacher (Frozen):
   Image (B, 3, 224, 224)
     â†’ Patch Embedding (16Ã—16)
     â†’ 12 Transformer Blocks
     â†’ Output: cls_token (B, 768), patch_tokens (B, 196, 768)

3. YOLOv8 Teacher (Frozen):
   Image (B, 3, 640, 640)
     â†’ Backbone â†’ Neck â†’ Head â†’ NMS
     â†’ Output: boxes, scores, labels (æ•¸é‡ä¸å›ºå®š)

4. YOLOv11 Student (Trainable):
   Image (B, 3, 640, 640)
     â†’ Backbone (æå– P4 ç‰¹å¾µç”¨æ–¼ Feature Alignment)
     â†’ Neck â†’ Head â†’ NMS
     â†’ Output: features (P4), boxes, scores, labels

5. Loss Computation:
   L_feature = cosine_loss(adapt(YOLO11_P4), DINO_cls)
   L_prediction = hungarian_match(YOLO11_pred, YOLOv8_pred)
   L_total = Î»_feat Ã— L_feature + Î»_pred Ã— L_prediction
```

### ç¶­åº¦å°ç…§è¡¨

| éšæ®µ | Tensor | Shape | èªªæ˜ |
|-----|--------|-------|------|
| **DINO Teacher è¼¸å…¥** | image | (B, 3, 224, 224) | éœ€è¦ resize |
| **DINO CLS token** | cls_token | (B, 768) | å…¨å±€èªç¾©ç‰¹å¾µ |
| **DINO Patch tokens** | patch_tokens | (B, 196, 768) | 14Ã—14 ç©ºé–“ç‰¹å¾µ |
| **YOLO è¼¸å…¥** | image | (B, 3, 640, 640) | åŸå§‹è¼¸å…¥å°ºå¯¸ |
| **YOLOv11 P4 ç‰¹å¾µ** | P4 | (B, 512, 40, 40) | stride=16 |
| **P4 Adapted** | adapted_P4 | (B, 768) | GAP å¾ŒæŠ•å½± |
| **YOLOv8/v11 é æ¸¬** | predictions | è®Šé•· | NMS å¾Œæ•¸é‡ä¸å›ºå®š |

### YOLO vs DETR æ ¼å¼å°æ¯”

| ç‰¹æ€§ | DETR (ç•¶å‰å¯¦ä½œ) | YOLO | è§£æ±ºæ–¹æ¡ˆ |
|-----|----------------|------|---------|
| é æ¸¬æ•¸é‡ | å›ºå®š (num_queries=100) | ä¸å›ºå®š (NMS å¾Œ) | Hungarian Matching |
| Box æ ¼å¼ | cxcywh normalized | xyxy æˆ– cxcywh | æ ¼å¼è½‰æ›å±¤ |
| Logits | [N, C+1] å«èƒŒæ™¯é¡ | [N, C] æˆ– objectness åˆ†é–‹ | æ ¼å¼çµ±ä¸€ |
| ç‰¹å¾µå°ºåº¦ | å–®å°ºåº¦ (ä¾†è‡ª Decoder) | å¤šå°ºåº¦ P3/P4/P5 | ä½¿ç”¨ P4 (stride=16) |

---

### YOLOv8Teacher

å°è£å‡çµçš„ YOLOv8 æ¨¡å‹ä½œç‚º Detection Teacherï¼š

```python
class YOLOv8Teacher(nn.Module):
    """
    YOLOv8 Teacher for Prediction Alignment

    è¼‰å…¥é è¨“ç·´çš„ YOLOv8 .pt æ¬Šé‡ï¼Œå®Œå…¨å‡çµï¼Œ
    åªè¼¸å‡ºé æ¸¬çµæœä¾› Student å­¸ç¿’ã€‚
    """

    def __init__(
        self,
        weights_path: str,  # .pt æª”æ¡ˆè·¯å¾‘
        conf_threshold: float = 0.25,
        iou_threshold: float = 0.45,
        max_detections: int = 300,
        device: str = "cuda",
    ):
        super().__init__()
        from ultralytics import YOLO

        # è¼‰å…¥ YOLOv8 æ¨¡å‹
        self.model = YOLO(weights_path)
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold
        self.max_detections = max_detections

        # å®Œå…¨å‡çµ
        for param in self.model.model.parameters():
            param.requires_grad = False

    @torch.no_grad()
    def forward(self, images: torch.Tensor) -> Dict[str, torch.Tensor]:
        """
        Args:
            images: (B, 3, H, W) - å·²æ­£è¦åŒ–çš„åœ–åƒ

        Returns:
            {
                "boxes": List[Tensor],   # æ¯å¼µåœ–çš„ boxes [N_i, 4] (xyxy)
                "scores": List[Tensor],  # æ¯å¼µåœ–çš„ scores [N_i]
                "labels": List[Tensor],  # æ¯å¼µåœ–çš„ labels [N_i]
            }
        """
        # Ultralytics YOLO æ¨ç†
        results = self.model.predict(
            images,
            conf=self.conf_threshold,
            iou=self.iou_threshold,
            max_det=self.max_detections,
            verbose=False,
        )

        # è§£æçµæœ
        boxes_list = []
        scores_list = []
        labels_list = []

        for result in results:
            boxes = result.boxes
            boxes_list.append(boxes.xyxy)      # (N, 4)
            scores_list.append(boxes.conf)     # (N,)
            labels_list.append(boxes.cls)      # (N,)

        return {
            "boxes": boxes_list,
            "scores": scores_list,
            "labels": labels_list,
        }
```

### YOLOv11StudentDetector

**æ¨è–¦ä½¿ç”¨ YOLOv11** ä½œç‚º Studentï¼Œå› ç‚ºå…¶ C3k2 å’Œ C2PSA æ¨¡çµ„æä¾›æ›´å¥½çš„å­¸ç¿’èƒ½åŠ›ï¼š

```python
class YOLOv11StudentDetector(nn.Module):
    """
    YOLOv11 Student Detector for MTKD

    å¯è¨“ç·´çš„ YOLOv11 æ¨¡å‹ï¼ŒåŒæ™‚è¼¸å‡ºï¼š
    1. P4 ç‰¹å¾µ â†’ ç”¨æ–¼ Feature Alignment (å°é½Š DINO)
    2. é æ¸¬çµæœ â†’ ç”¨æ–¼ Prediction Alignment (å°é½Š YOLOv8 Teacher)
    """

    def __init__(
        self,
        model_variant: str = "yolo11n",  # yolo11n/s/m/l/x
        num_classes: int = 1,
        dino_dim: int = 768,
        pretrained: bool = True,
        conf_threshold: float = 0.001,  # è¨“ç·´æ™‚ç”¨ä½é–¾å€¼
        iou_threshold: float = 0.65,
    ):
        super().__init__()
        from ultralytics import YOLO

        # è¼‰å…¥ YOLOv11
        if pretrained:
            self.model = YOLO(f"{model_variant}.pt")
        else:
            self.model = YOLO(f"{model_variant}.yaml")

        self.num_classes = num_classes
        self.conf_threshold = conf_threshold
        self.iou_threshold = iou_threshold

        # P4 ç‰¹å¾µé©é…å™¨ (512 â†’ 768)
        # YOLOv11 P4 é€šé“æ•¸å› æ¨¡å‹å¤§å°è€Œç•°
        p4_channels = self._get_p4_channels(model_variant)
        self.feature_adapter = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Linear(p4_channels, dino_dim),
            nn.LayerNorm(dino_dim),
        )

        # è¨»å†Š hook æå– P4 ç‰¹å¾µ
        self.p4_features = None
        self._register_hooks()

    def _get_p4_channels(self, variant: str) -> int:
        """æ ¹æ“šæ¨¡å‹è®Šé«”è¿”å› P4 é€šé“æ•¸"""
        channels_map = {
            "yolo11n": 256,
            "yolo11s": 256,
            "yolo11m": 512,
            "yolo11l": 512,
            "yolo11x": 512,
        }
        return channels_map.get(variant, 512)

    def _register_hooks(self):
        """è¨»å†Š forward hook æå– P4 ç‰¹å¾µ"""
        def hook_fn(module, input, output):
            self.p4_features = output

        # P4 ä½æ–¼ neck çš„ç‰¹å®šå±¤ï¼ˆéœ€è¦æ ¹æ“šå¯¦éš›æ¨¡å‹çµæ§‹èª¿æ•´ï¼‰
        # é€™è£¡å‡è¨­ä½¿ç”¨ Ultralytics çš„æ¨™æº–çµæ§‹
        # å¯¦éš›ä½¿ç”¨æ™‚éœ€è¦æ ¹æ“š model.model çµæ§‹ç¢ºå®šæ­£ç¢ºçš„å±¤
        pass  # å¯¦ä½œæ™‚éœ€è¦æ ¹æ“šå…·é«”æ¨¡å‹çµæ§‹è¨­ç½®

    def forward(
        self,
        images: torch.Tensor,
        return_features: bool = True,
    ) -> Dict[str, torch.Tensor]:
        """
        Args:
            images: (B, 3, H, W)
            return_features: æ˜¯å¦è¿”å›é©é…å¾Œçš„ç‰¹å¾µ

        Returns:
            {
                "boxes": List[Tensor],        # NMS å¾Œçš„ boxes
                "scores": List[Tensor],       # NMS å¾Œçš„ scores
                "labels": List[Tensor],       # NMS å¾Œçš„ labels
                "adapted_features": Tensor,   # (B, 768) - ç”¨æ–¼ Feature Alignment
            }
        """
        # YOLO forwardï¼ˆåŒæ™‚è§¸ç™¼ hook æå– P4ï¼‰
        results = self.model.predict(
            images,
            conf=self.conf_threshold,
            iou=self.iou_threshold,
            verbose=False,
        )

        # è§£æé æ¸¬çµæœ
        boxes_list = []
        scores_list = []
        labels_list = []

        for result in results:
            boxes = result.boxes
            boxes_list.append(boxes.xyxy)
            scores_list.append(boxes.conf)
            labels_list.append(boxes.cls)

        outputs = {
            "boxes": boxes_list,
            "scores": scores_list,
            "labels": labels_list,
        }

        # ç‰¹å¾µé©é…
        if return_features and self.p4_features is not None:
            adapted = self.feature_adapter(self.p4_features)  # (B, 768)
            outputs["adapted_features"] = adapted

        return outputs
```

### YOLOOutputWrapper

å°‡ YOLO çš„ NMS å¾Œè¼¸å‡ºè½‰æ›ç‚º MTKD çµ±ä¸€æ ¼å¼ï¼š

```python
class YOLOOutputWrapper(nn.Module):
    """
    åŒ…è£ YOLO è¼¸å‡ºç‚º MTKD æ ¼å¼

    YOLO è¼¸å‡º (NMS å¾Œ):
        boxes: List[Tensor] - æ¯å¼µåœ–çš„ [N_i, 4] (xyxy)
        scores: List[Tensor] - æ¯å¼µåœ–çš„ [N_i]
        labels: List[Tensor] - æ¯å¼µåœ–çš„ [N_i]

    MTKD æ ¼å¼:
        {
            "boxes": [B, max_det, 4] (cxcywh normalized),
            "logits": [B, max_det, C],
            "valid_mask": [B, max_det]
        }
    """

    def __init__(
        self,
        max_detections: int = 100,
        num_classes: int = 1,
        box_format: str = "xyxy",  # YOLO è¼¸å‡ºæ ¼å¼
        normalize_boxes: bool = True,
    ):
        super().__init__()
        self.max_detections = max_detections
        self.num_classes = num_classes
        self.box_format = box_format
        self.normalize_boxes = normalize_boxes

    def forward(
        self,
        yolo_boxes: List[torch.Tensor],  # List of [N_i, 4]
        yolo_scores: List[torch.Tensor],  # List of [N_i]
        yolo_labels: List[torch.Tensor],  # List of [N_i]
        image_sizes: torch.Tensor,        # [B, 2] (H, W)
    ) -> Dict[str, torch.Tensor]:
        B = len(yolo_boxes)
        device = yolo_boxes[0].device

        # åˆå§‹åŒ–è¼¸å‡º tensors
        boxes = torch.zeros(B, self.max_detections, 4, device=device)
        logits = torch.zeros(B, self.max_detections, self.num_classes + 1, device=device)
        logits[..., -1] = 1.0  # èƒŒæ™¯é¡åˆå§‹åŒ–ç‚º 1
        valid_mask = torch.zeros(B, self.max_detections, dtype=torch.bool, device=device)

        for b in range(B):
            n_det = min(len(yolo_boxes[b]), self.max_detections)
            if n_det == 0:
                continue

            # è¤‡è£½æª¢æ¸¬çµæœ
            b_boxes = yolo_boxes[b][:n_det]
            b_scores = yolo_scores[b][:n_det]
            b_labels = yolo_labels[b][:n_det].long()

            # Box æ ¼å¼è½‰æ›: xyxy â†’ cxcywh
            if self.box_format == "xyxy":
                x1, y1, x2, y2 = b_boxes.unbind(-1)
                cx = (x1 + x2) / 2
                cy = (y1 + y2) / 2
                w = x2 - x1
                h = y2 - y1
                b_boxes = torch.stack([cx, cy, w, h], dim=-1)

            # æ­£è¦åŒ– boxes
            if self.normalize_boxes:
                img_h, img_w = image_sizes[b]
                b_boxes = b_boxes / torch.tensor([img_w, img_h, img_w, img_h], device=device)

            boxes[b, :n_det] = b_boxes

            # å°‡ scores å’Œ labels è½‰æ›ç‚º logits
            # ä½¿ç”¨ logit = log(p / (1-p)) çš„é€†é‹ç®—
            for i in range(n_det):
                label = b_labels[i]
                score = b_scores[i].clamp(1e-6, 1 - 1e-6)
                logits[b, i, label] = torch.log(score / (1 - score))
                logits[b, i, -1] = torch.log((1 - score) / score)  # èƒŒæ™¯

            valid_mask[b, :n_det] = True

        return {
            "boxes": boxes,
            "logits": logits,
            "valid_mask": valid_mask,
        }
```

### YOLOFeatureAdapter

é©é… YOLO å¤šå°ºåº¦ç‰¹å¾µåˆ° DINO æ ¼å¼ï¼š

```python
class YOLOFeatureAdapter(nn.Module):
    """
    å°‡ YOLO å¤šå°ºåº¦ç‰¹å¾µé©é…åˆ° DINO æ ¼å¼

    ç­–ç•¥é¸é …:
    1. "global": å…¨å±€å¹³å‡æ± åŒ–å¾Œå°é½Š
    2. "p4": åªä½¿ç”¨ P4 (stride=16) èˆ‡ DINO patch å°é½Š
    3. "multi_scale": å¤šå°ºåº¦èšåˆå¾Œå°é½Š
    """

    def __init__(
        self,
        yolo_channels: List[int] = [256, 512, 1024],  # P3, P4, P5
        dino_dim: int = 768,
        strategy: str = "p4",
        adapter_type: str = "mlp",
    ):
        super().__init__()
        self.strategy = strategy
        self.dino_dim = dino_dim

        if strategy == "global":
            # ä½¿ç”¨ P5 çš„é€šé“æ•¸
            self.adapter = FeatureAdapter(
                student_dim=yolo_channels[-1],
                teacher_dim=dino_dim,
                adapter_type=adapter_type,
            )
        elif strategy == "p4":
            # P4 stride=16ï¼Œèˆ‡ DINO patch_size=16 å°æ‡‰
            self.adapter = FeatureAdapter(
                student_dim=yolo_channels[1],  # P4 channels
                teacher_dim=dino_dim,
                adapter_type=adapter_type,
            )
        elif strategy == "multi_scale":
            # å…ˆèšåˆå†é©é…
            total_channels = sum(yolo_channels)
            self.pool = nn.AdaptiveAvgPool2d(1)
            self.adapter = FeatureAdapter(
                student_dim=total_channels,
                teacher_dim=dino_dim,
                adapter_type=adapter_type,
            )

    def forward(
        self,
        yolo_features: Dict[str, torch.Tensor],  # {"P3": ..., "P4": ..., "P5": ...}
        dino_patch_size: Tuple[int, int] = (14, 14),
    ) -> Dict[str, torch.Tensor]:
        """
        Returns:
            {
                "global_features": [B, dino_dim],  # èˆ‡ DINO CLS token å°é½Š
                "spatial_features": [B, H*W, dino_dim],  # èˆ‡ DINO patch tokens å°é½Š (å¯é¸)
            }
        """
        if self.strategy == "global":
            # å…¨å±€ç‰¹å¾µ
            p5 = yolo_features.get("P5", list(yolo_features.values())[-1])
            global_feat = F.adaptive_avg_pool2d(p5, 1).flatten(1)  # [B, C]
            adapted_global = self.adapter(global_feat)  # [B, dino_dim]

            return {"global_features": adapted_global}

        elif self.strategy == "p4":
            # P4 ç‰¹å¾µï¼ˆstride=16ï¼Œèˆ‡ DINO patch å°é½Šï¼‰
            p4 = yolo_features.get("P4", list(yolo_features.values())[1])

            # å…¨å±€ç‰¹å¾µ
            global_feat = F.adaptive_avg_pool2d(p4, 1).flatten(1)
            adapted_global = self.adapter(global_feat)

            # ç©ºé–“ç‰¹å¾µï¼ˆèˆ‡ DINO patch tokens å°é½Šï¼‰
            p4_resized = F.interpolate(p4, size=dino_patch_size, mode="bilinear", align_corners=False)
            B, C, H, W = p4_resized.shape
            spatial_feat = p4_resized.flatten(2).transpose(1, 2)  # [B, H*W, C]
            adapted_spatial = self.adapter(spatial_feat)  # [B, H*W, dino_dim]

            return {
                "global_features": adapted_global,
                "spatial_features": adapted_spatial,
            }

        elif self.strategy == "multi_scale":
            # å¤šå°ºåº¦èšåˆ
            pooled = []
            for feat in yolo_features.values():
                pooled.append(self.pool(feat).flatten(1))
            concat_feat = torch.cat(pooled, dim=-1)  # [B, sum(channels)]
            adapted_global = self.adapter(concat_feat)

            return {"global_features": adapted_global}
```

### Prediction Alignment ç­–ç•¥

YOLOv11 Student çš„é æ¸¬èˆ‡ YOLOv8 Teacher çš„é æ¸¬å°é½Šã€‚ç”±æ–¼å…©è€… NMS å¾Œçš„æª¢æ¸¬æ•¸é‡å¯èƒ½ä¸åŒï¼Œä½¿ç”¨ **Hungarian Matching** é€²è¡Œæœ€å„ªé…å°ï¼š

```python
from mtkd_framework.losses import HungarianMatchingLoss

# å»ºç«‹æå¤±å‡½æ•¸
hungarian_loss = HungarianMatchingLoss(
    box_cost_weight=5.0,
    class_cost_weight=2.0,
    box_loss_type="giou",
    class_loss_type="kl",
)

# YOLOv11 Student predictions
student_pred = yolo11_student(images)
# student_pred["boxes"]: List[Tensor] - æ¯å¼µåœ– N_i å€‹æª¢æ¸¬
# student_pred["scores"]: List[Tensor]
# student_pred["labels"]: List[Tensor]

# YOLOv8 Teacher predictions
teacher_pred = yolo8_teacher(images)
# teacher_pred["boxes"]: List[Tensor] - æ¯å¼µåœ– M_i å€‹æª¢æ¸¬
# teacher_pred["scores"]: List[Tensor]
# teacher_pred["labels"]: List[Tensor]

# Hungarian Matching è‡ªå‹•é…å°ä¸åŒæ•¸é‡çš„é æ¸¬
# å°æ–¼æ¯å¼µåœ–ï¼Œæ‰¾åˆ° min(N_i, M_i) å€‹æœ€å„ªé…å°
loss, loss_dict = hungarian_loss(student_pred, teacher_pred)
# loss_dict: {"box_loss": ..., "class_loss": ..., "total_loss": ...}
```

### Feature Alignment ç­–ç•¥

YOLOv11 Student çš„ P4 ç‰¹å¾µèˆ‡ DINO Teacher çš„ CLS token å°é½Šï¼š

```python
import torch.nn.functional as F

# YOLOv11 P4 ç‰¹å¾µï¼ˆå·²é€šé adapter æŠ•å½±åˆ° 768 ç¶­ï¼‰
student_features = yolo11_student(images)["adapted_features"]  # (B, 768)

# DINO CLS token
dino_output = dino_teacher(images)
dino_cls = dino_output["cls_token"]  # (B, 768)

# Cosine Similarity Loss
feature_loss = 1 - F.cosine_similarity(student_features, dino_cls, dim=-1).mean()

# æˆ–ä½¿ç”¨ L2 Loss
# feature_loss = F.mse_loss(student_features, dino_cls)
```

**ç‚ºä»€éº¼ç”¨ P4 å°é½Š DINOï¼Ÿ**

| ç‰¹å¾µå±¤ | Stride | å°æ–¼ 640Ã—640 è¼¸å…¥ | èªªæ˜ |
|-------|--------|------------------|------|
| P3 | 8 | 80Ã—80 | å¤ªç´°ï¼Œèªç¾©ä¸è¶³ |
| **P4** | **16** | **40Ã—40** | **èˆ‡ DINO patch_size=16 å°æ‡‰** |
| P5 | 32 | 20Ã—20 | éæ–¼æŠ½è±¡ |

### å®Œæ•´ä½¿ç”¨ç¯„ä¾‹

```python
import torch
import torch.nn.functional as F
from mtkd_framework.losses import HungarianMatchingLoss

# ============================================
# 1. è¼‰å…¥ä¸‰å€‹æ¨¡å‹
# ============================================

# DINO Feature Teacher (Frozen)
from dinov3.models import build_model as build_dino
dino_teacher = build_dino(model_name="vit_base", patch_size=16)
dino_teacher.load_state_dict(torch.load("dino_vitb16.pth"))
dino_teacher.eval()
for param in dino_teacher.parameters():
    param.requires_grad = False

# YOLOv8 Detection Teacher (Frozen)
yolo8_teacher = YOLOv8Teacher(
    weights_path="yolov8_stomata.pt",  # æ‚¨çš„é è¨“ç·´ YOLOv8 æ¬Šé‡
    conf_threshold=0.25,
    iou_threshold=0.45,
)

# YOLOv11 Student (Trainable)
yolo11_student = YOLOv11StudentDetector(
    model_variant="yolo11n",
    num_classes=1,
    dino_dim=768,
    pretrained=True,
)

# ============================================
# 2. è¨­å®šæå¤±å‡½æ•¸
# ============================================

# Feature Alignment: Cosine Loss
def feature_alignment_loss(student_feat, teacher_feat):
    return 1 - F.cosine_similarity(student_feat, teacher_feat, dim=-1).mean()

# Prediction Alignment: Hungarian Matching
hungarian_loss = HungarianMatchingLoss(
    box_cost_weight=5.0,
    class_cost_weight=2.0,
    box_loss_type="giou",
    class_loss_type="kl",
)

# ============================================
# 3. è¨“ç·´è¿´åœˆ
# ============================================

# åªæœ‰ Student å¯è¨“ç·´
optimizer = torch.optim.AdamW(
    yolo11_student.parameters(),
    lr=1e-4,
    weight_decay=1e-4,
)

lambda_feat = 1.0
lambda_pred = 2.0

for epoch in range(100):
    for images, _ in train_loader:
        images = images.cuda()

        # ---- Forward ----
        # DINO: éœ€è¦ resize åˆ° 224x224
        dino_images = F.interpolate(images, size=(224, 224), mode="bilinear")
        with torch.no_grad():
            dino_out = dino_teacher(dino_images)
            dino_cls = dino_out["cls_token"]  # (B, 768)

        # YOLOv8 Teacher
        with torch.no_grad():
            teacher_pred = yolo8_teacher(images)

        # YOLOv11 Student
        student_out = yolo11_student(images, return_features=True)
        student_feat = student_out["adapted_features"]  # (B, 768)
        student_pred = {
            "boxes": student_out["boxes"],
            "scores": student_out["scores"],
            "labels": student_out["labels"],
        }

        # ---- Loss ----
        L_feature = feature_alignment_loss(student_feat, dino_cls)
        L_prediction, pred_loss_dict = hungarian_loss(student_pred, teacher_pred)

        loss = lambda_feat * L_feature + lambda_pred * L_prediction

        # ---- Backward ----
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        print(f"Epoch {epoch} | Loss: {loss.item():.4f}")
        print(f"  Feature: {L_feature.item():.4f}")
        print(f"  Prediction: {L_prediction.item():.4f}")

# ============================================
# 4. å„²å­˜è¨“ç·´å¥½çš„ Student
# ============================================
torch.save(yolo11_student.state_dict(), "yolo11_student_mtkd.pt")
```

### é…ç½®ç¯„ä¾‹

```python
yolo_mtkd_config = {
    "model": {
        "num_classes": 1,

        # DINO Feature Teacher
        "dino_teacher": {
            "model_name": "vit_base",
            "patch_size": 16,
            "embed_dim": 768,
            "weights_path": "dino_vitb16.pth",
            "frozen": True,  # å®Œå…¨å‡çµ
        },

        # YOLOv8 Detection Teacher
        "yolo8_teacher": {
            "weights_path": "yolov8_stomata.pt",
            "conf_threshold": 0.25,
            "iou_threshold": 0.45,
            "frozen": True,  # å®Œå…¨å‡çµ
        },

        # YOLOv11 Student (Trainable)
        "yolo11_student": {
            "model_variant": "yolo11n",  # n/s/m/l/x
            "pretrained": True,
            "dino_dim": 768,
            "conf_threshold": 0.001,  # è¨“ç·´æ™‚ä½é–¾å€¼
            "iou_threshold": 0.65,
        },
    },

    "loss": {
        "feature_weight": 1.0,       # Î»_feat
        "prediction_weight": 2.0,    # Î»_pred
        "feature_loss_type": "cosine",
        "prediction_loss_type": "hungarian",
        "box_loss_type": "giou",
        "class_loss_type": "kl",
    },

    "training": {
        "epochs": 100,
        "batch_size": 16,
        "learning_rate": 1e-4,
        "weight_decay": 1e-4,
        "warmup_epochs": 5,
        "scheduler": "cosine",
    },
}
```

### æ³¨æ„äº‹é …

1. **åœ–åƒå°ºå¯¸**ï¼š
   - DINO éœ€è¦ 224Ã—224 è¼¸å…¥ï¼Œéœ€è¦ resize
   - YOLO ä½¿ç”¨ 640Ã—640ï¼ˆæˆ–å…¶ä»–æ¨™æº–å°ºå¯¸ï¼‰

2. **NMS é–¾å€¼**ï¼š
   - Teacher: æ­£å¸¸é–¾å€¼ (conf=0.25) ç”¢ç”Ÿé«˜å“è³ªé æ¸¬
   - Student: ä½é–¾å€¼ (conf=0.001) ä¿ç•™æ›´å¤šé æ¸¬ä¾›é…å°

3. **ç‰¹å¾µæå–**ï¼š
   - ä½¿ç”¨ forward hooks å¾ YOLOv11 æå– P4 ç‰¹å¾µ
   - P4 stride=16 èˆ‡ DINO patch_size=16 å°æ‡‰

4. **æ¢¯åº¦æµ**ï¼š
   - DINO Teacher: `requires_grad=False`
   - YOLOv8 Teacher: `requires_grad=False`
   - YOLOv11 Student: `requires_grad=True`ï¼ˆåªæœ‰é€™å€‹å¯è¨“ç·´ï¼‰

5. **Box æ ¼å¼**ï¼šHungarian Matching å…§éƒ¨è™•ç†æ ¼å¼è½‰æ›

---

## å¯¦ä½œç´°ç¯€èˆ‡ç‹€æ…‹

æœ¬ç« ç¯€è©³ç´°è¨˜éŒ„ MTKD æ¡†æ¶å„æ¨¡çµ„çš„å®Œæ•´å¯¦ä½œç´°ç¯€ï¼ŒåŒ…æ‹¬å·²å¯¦ä½œçš„åŠŸèƒ½ã€API ç´°ç¯€å’Œå…§éƒ¨é‹ä½œæ©Ÿåˆ¶ã€‚

### å¯¦ä½œç‹€æ…‹ç¸½è¦½

| æ¨¡çµ„ | æª”æ¡ˆ | å¯¦ä½œç‹€æ…‹ | èªªæ˜ |
|------|------|---------|------|
| **Feature Alignment Loss** | `losses/feature_alignment.py` | âœ… å®Œæ•´ | L2, Cosine, KL, Smooth L1 |
| **Prediction Alignment Loss** | `losses/prediction_alignment.py` | âœ… å®Œæ•´ | GIoU, CIoU, Hungarian Matching |
| **Combined Loss** | `losses/combined_loss.py` | âœ… å®Œæ•´ | æ¨™æº–ç‰ˆ + Adaptive + Uncertainty |
| **Student Model (DETR)** | `models/student_model.py` | âœ… å®Œæ•´ | DETR-like æ¶æ§‹ |
| **Teacher Ensemble** | `models/teacher_ensemble.py` | âœ… å®Œæ•´ | WBF + Soft-NMS |
| **MTKD Model** | `models/mtkd_model.py` | âœ… å®Œæ•´ | æ•´åˆæ‰€æœ‰çµ„ä»¶ |
| **Training Pipeline** | `train.py` | âœ… å®Œæ•´ | MTKDTrainer é¡åˆ¥ |
| **YOLOv8Teacher** | å¾…å¯¦ä½œ | ğŸ”„ è¦åŠƒä¸­ | è¦‹ YOLO æ•´åˆæŒ‡å— |
| **YOLOv11StudentDetector** | å¾…å¯¦ä½œ | ğŸ”„ è¦åŠƒä¸­ | è¦‹ YOLO æ•´åˆæŒ‡å— |

---

### MTKDLoss è®Šé«”è©³è§£

#### 1. æ¨™æº– MTKDLoss

**æª”æ¡ˆ**: `losses/combined_loss.py:18-191`

```python
class MTKDLoss(nn.Module):
    """
    æ¨™æº– MTKD çµ„åˆæå¤±

    ç‰¹æ€§:
    - å‹•æ…‹æ¬Šé‡èª¿æ•´ï¼ˆWarmup + Scheduleï¼‰
    - æ”¯æ´æª¢æ¸¬æå¤±ï¼ˆèˆ‡ Ground Truthï¼‰
    - æå¤±é …è©³ç´°è¿½è¹¤
    """
```

**åˆå§‹åŒ–åƒæ•¸è©³è§£**:

| åƒæ•¸ | é¡å‹ | é»˜èªå€¼ | èªªæ˜ |
|------|------|--------|------|
| `feature_loss_config` | dict | `{}` | FeatureAlignmentLoss é…ç½® |
| `prediction_loss_config` | dict | `{}` | PredictionAlignmentLoss é…ç½® |
| `feature_weight` | float | 1.0 | ç‰¹å¾µå°é½Šæå¤±æ¬Šé‡ |
| `prediction_weight` | float | 1.0 | é æ¸¬å°é½Šæå¤±æ¬Šé‡ |
| `detection_weight` | float | 0.0 | æª¢æ¸¬æå¤±æ¬Šé‡ï¼ˆ0 è¡¨ç¤ºç¦ç”¨ï¼‰|
| `warmup_epochs` | int | 0 | æ¬Šé‡ warmup è¼ªæ•¸ |
| `weight_schedule` | str | "constant" | æ¬Šé‡èª¿åº¦ç­–ç•¥ |
| `min_weight_ratio` | float | 0.1 | æœ€å°æ¬Šé‡æ¯”ä¾‹ |

**æ¬Šé‡èª¿åº¦ç­–ç•¥**:

```python
# æ”¯æ´çš„èª¿åº¦é¡å‹
weight_schedule: Literal["constant", "linear", "cosine"] = "constant"

# Warmup æœŸé–“çš„æ¬Šé‡è¨ˆç®—
if epoch < warmup_epochs:
    warmup_factor = epoch / warmup_epochs
else:
    warmup_factor = 1.0

# èª¿åº¦è¨ˆç®—
if weight_schedule == "linear":
    schedule_factor = 1 - (1 - min_weight_ratio) * (epoch / total_epochs)
elif weight_schedule == "cosine":
    schedule_factor = min_weight_ratio + (1 - min_weight_ratio) * (1 + cos(Ï€ * epoch / total_epochs)) / 2
else:
    schedule_factor = 1.0

final_weight = base_weight * warmup_factor * schedule_factor
```

**Forward ç°½å**:

```python
def forward(
    self,
    student_features: torch.Tensor,          # [B, D] æˆ– [B, N, D]
    dino_teacher_features: torch.Tensor,      # [B, D] æˆ– [B, N, D]
    student_predictions: Dict[str, Tensor],   # {"boxes": [B, N, 4], "logits": [B, N, C]}
    ensemble_teacher_predictions: Dict,       # åŒä¸Š
    targets: Optional[List[Dict]] = None,     # Ground truthï¼ˆç”¨æ–¼æª¢æ¸¬æå¤±ï¼‰
    epoch: int = 0,
    total_epochs: int = 100,
) -> Tuple[Tensor, Dict[str, Tensor]]:
    """
    Returns:
        total_loss: åŠ æ¬Šç¸½æå¤±
        loss_dict: {
            "feature_align_loss": ...,
            "pred_align_total_loss": ...,
            "pred_align_box_loss": ...,
            "pred_align_class_loss": ...,
            "detection_loss": ...,  # å¦‚æœå•Ÿç”¨
            "total_loss": ...,
            "feature_weight": ...,
            "prediction_weight": ...,
        }
    """
```

#### 2. AdaptiveMTKDLoss

**æª”æ¡ˆ**: `losses/combined_loss.py:194-293`

è‡ªå‹•èª¿æ•´æå¤±æ¬Šé‡ï¼Œæ ¹æ“šå„æå¤±é …çš„ç›¸å°å¤§å°å‹•æ…‹å¹³è¡¡ã€‚

```python
class AdaptiveMTKDLoss(MTKDLoss):
    """
    è‡ªé©æ‡‰ MTKD æå¤±

    ç‰¹æ€§:
    - ä½¿ç”¨ EMA è¿½è¹¤å„æå¤±é …çš„çµ±è¨ˆè³‡è¨Š
    - æ ¹æ“šæå¤±çš„æ¨™æº–å·®è‡ªå‹•èª¿æ•´æ¬Šé‡
    - é˜²æ­¢å–®ä¸€æå¤±é …ä¸»å°è¨“ç·´
    """
```

**é¡å¤–åˆå§‹åŒ–åƒæ•¸**:

| åƒæ•¸ | é¡å‹ | é»˜èªå€¼ | èªªæ˜ |
|------|------|--------|------|
| `ema_decay` | float | 0.999 | EMA è¡°æ¸›ä¿‚æ•¸ |
| `loss_scale_method` | str | "std" | ç¸®æ”¾æ–¹æ³• ("std", "mean", "max") |

**è‡ªé©æ‡‰æ¬Šé‡è¨ˆç®—**:

```python
# EMA æ›´æ–°
self.loss_mean = ema_decay * self.loss_mean + (1 - ema_decay) * current_loss
self.loss_sq_mean = ema_decay * self.loss_sq_mean + (1 - ema_decay) * current_loss ** 2

# è¨ˆç®—æ¨™æº–å·®
std = sqrt(self.loss_sq_mean - self.loss_mean ** 2)

# æ¬Šé‡ç¸®æ”¾ï¼ˆåæ¯”æ–¼æ¨™æº–å·®ï¼‰
adaptive_weight = base_weight / (std + epsilon)
```

#### 3. UncertaintyWeightedMTKDLoss

**æª”æ¡ˆ**: `losses/combined_loss.py:296-413`

åŸºæ–¼åŒæ–¹å·®ä¸ç¢ºå®šæ€§çš„å¯å­¸ç¿’æå¤±æ¬Šé‡ã€‚

```python
class UncertaintyWeightedMTKDLoss(MTKDLoss):
    """
    åŸºæ–¼ä¸ç¢ºå®šæ€§çš„ MTKD æå¤±

    ç†è«–åŸºç¤:
    - è«–æ–‡: "Multi-Task Learning Using Uncertainty to Weigh Losses"
    - ä½¿ç”¨å¯å­¸ç¿’çš„ log_variance åƒæ•¸
    - æå¤±é …çš„æ¬Šé‡èˆ‡å…¶ä¸ç¢ºå®šæ€§æˆåæ¯”

    å…¬å¼:
    L_total = Î£ (1 / (2 * exp(log_var_i))) * L_i + log_var_i / 2
    """
```

**å¯å­¸ç¿’åƒæ•¸**:

```python
# åœ¨ __init__ ä¸­åˆå§‹åŒ–
self.log_var_feature = nn.Parameter(torch.zeros(1))   # log(ÏƒÂ²) for feature loss
self.log_var_prediction = nn.Parameter(torch.zeros(1))  # log(ÏƒÂ²) for prediction loss
self.log_var_detection = nn.Parameter(torch.zeros(1))   # log(ÏƒÂ²) for detection loss
```

**æå¤±è¨ˆç®—**:

```python
# ä¸ç¢ºå®šæ€§åŠ æ¬Š
precision_feature = torch.exp(-self.log_var_feature)
weighted_feature_loss = precision_feature * feature_loss + self.log_var_feature / 2

precision_prediction = torch.exp(-self.log_var_prediction)
weighted_pred_loss = precision_prediction * pred_loss + self.log_var_prediction / 2

total_loss = weighted_feature_loss + weighted_pred_loss + ...
```

**è¨“ç·´å»ºè­°**:

```python
# éœ€è¦å°‡ log_var åƒæ•¸åŠ å…¥ optimizer
optimizer = torch.optim.AdamW([
    {"params": model.student.parameters(), "lr": 1e-4},
    {"params": loss_fn.parameters(), "lr": 1e-3},  # è¼ƒé«˜å­¸ç¿’ç‡
])
```

---

### WeightedBoxFusion (WBF) è©³è§£

**æª”æ¡ˆ**: `models/teacher_ensemble.py:21-178`

å®Œæ•´çš„ WBF å¯¦ä½œï¼Œç”¨æ–¼èåˆå¤šå€‹æª¢æ¸¬æ¨¡å‹çš„é æ¸¬ã€‚

```python
class WeightedBoxFusion(nn.Module):
    """
    Weighted Box Fusion

    èˆ‡ NMS çš„å€åˆ¥:
    - NMS: åˆªé™¤é‡ç–Šçš„ boxesï¼Œåªä¿ç•™æœ€é«˜åˆ†
    - WBF: èåˆé‡ç–Šçš„ boxesï¼Œå–åŠ æ¬Šå¹³å‡

    å„ªé»:
    - åˆ©ç”¨å¤šæ¨¡å‹çš„äº’è£œè³‡è¨Š
    - ç”¢ç”Ÿæ›´ç©©å®šã€æº–ç¢ºçš„ boxes
    - èåˆå¾Œçš„ç½®ä¿¡åº¦æ›´å¯é 
    """
```

**åˆå§‹åŒ–åƒæ•¸**:

| åƒæ•¸ | é¡å‹ | é»˜èªå€¼ | èªªæ˜ |
|------|------|--------|------|
| `iou_threshold` | float | 0.55 | èåˆ IoU é–¾å€¼ |
| `skip_box_thr` | float | 0.0 | å¿½ç•¥ä½æ–¼æ­¤åˆ†æ•¸çš„ boxes |
| `weights` | List[float] | None | å„æ¨¡å‹æ¬Šé‡ |
| `conf_type` | str | "avg" | ç½®ä¿¡åº¦è¨ˆç®—æ–¹å¼ |

**ç½®ä¿¡åº¦è¨ˆç®—æ–¹å¼**:

```python
# conf_type é¸é …
"avg"       # åŠ æ¬Šå¹³å‡
"max"       # å–æœ€å¤§å€¼
"box_and_model_avg"  # Box æ•¸é‡ + æ¨¡å‹æ¬Šé‡åŠ æ¬Š
"absent_model_aware_avg"  # è€ƒæ…®ç¼ºå¤±æ¨¡å‹çš„å¹³å‡
```

**WBF ç®—æ³•æµç¨‹ï¼ˆå¯¦éš›ç¨‹å¼ç¢¼é‚è¼¯ï¼‰**:

```python
def forward(self, boxes_list, scores_list, labels_list):
    """
    Args:
        boxes_list: List[Tensor] - æ¯å€‹æ¨¡å‹çš„ boxes [N_i, 4]
        scores_list: List[Tensor] - æ¯å€‹æ¨¡å‹çš„ scores [N_i]
        labels_list: List[Tensor] - æ¯å€‹æ¨¡å‹çš„ labels [N_i]

    Returns:
        fused_boxes: Tensor [M, 4]
        fused_scores: Tensor [M]
        fused_labels: Tensor [M]
    """
    # 1. æŒ‰é¡åˆ¥åˆ†çµ„
    for label in unique_labels:
        class_boxes = filter_by_label(all_boxes, label)

        # 2. æŒ‰åˆ†æ•¸æ’åº
        sorted_boxes = sort_by_score(class_boxes)

        # 3. èšé¡é‡ç–Š boxes
        clusters = []
        for box in sorted_boxes:
            matched = False
            for cluster in clusters:
                if iou(box, cluster.representative) > iou_threshold:
                    cluster.add(box)
                    matched = True
                    break
            if not matched:
                clusters.append(new_cluster(box))

        # 4. å°æ¯å€‹ cluster è¨ˆç®—åŠ æ¬Šå¹³å‡
        for cluster in clusters:
            weights = [model_weights[box.model_id] * box.score for box in cluster]
            fused_box = weighted_average(cluster.boxes, weights)
            fused_score = calculate_confidence(cluster, conf_type)
            results.append((fused_box, fused_score, label))

    return fused_boxes, fused_scores, fused_labels
```

---

### Soft-NMS è©³è§£

**æª”æ¡ˆ**: `models/teacher_ensemble.py:181-276`

Soft-NMS ä½œç‚º WBF çš„æ›¿ä»£æ–¹æ¡ˆï¼Œé€šéé™ä½é‡ç–Š box åˆ†æ•¸è€Œéåˆªé™¤ã€‚

```python
class SoftNMS(nn.Module):
    """
    Soft Non-Maximum Suppression

    èˆ‡å‚³çµ± NMS çš„å€åˆ¥:
    - å‚³çµ± NMS: ç›´æ¥åˆªé™¤é‡ç–Šçš„ä½åˆ† boxes
    - Soft-NMS: æ ¹æ“š IoU é™ä½é‡ç–Š boxes çš„åˆ†æ•¸

    å„ªé»:
    - ä¿ç•™å¯†é›†ç‰©é«”çš„æª¢æ¸¬
    - æ¸›å°‘æ¼æª¢
    """
```

**åˆå§‹åŒ–åƒæ•¸**:

| åƒæ•¸ | é¡å‹ | é»˜èªå€¼ | èªªæ˜ |
|------|------|--------|------|
| `iou_threshold` | float | 0.3 | é–‹å§‹é™åˆ†çš„ IoU é–¾å€¼ |
| `score_threshold` | float | 0.001 | æœ€çµ‚ä¿ç•™çš„åˆ†æ•¸é–¾å€¼ |
| `sigma` | float | 0.5 | Gaussian è¡°æ¸›åƒæ•¸ |
| `method` | str | "gaussian" | è¡°æ¸›æ–¹æ³• |

**è¡°æ¸›æ–¹æ³•**:

```python
# method = "linear"
if iou > iou_threshold:
    score = score * (1 - iou)

# method = "gaussian" (æ›´å¹³æ»‘)
score = score * exp(-iou^2 / sigma)
```

---

### TeacherEnsemble è©³è§£

**æª”æ¡ˆ**: `models/teacher_ensemble.py:279-655`

ç®¡ç†å¤šå€‹ Teacher æ¨¡å‹ä¸¦èåˆé æ¸¬çš„å®Œæ•´å¯¦ä½œã€‚

```python
class TeacherEnsemble(nn.Module):
    """
    Teacher Ensemble æ¨¡çµ„

    ç‰¹æ€§:
    - å‹•æ…‹æ·»åŠ /ç§»é™¤ Teacher
    - æ”¯æ´å¾ checkpoints æ‰¹é‡è¼‰å…¥
    - è‡ªå‹•ç®¡ç†æ¨¡å‹æ¬Šé‡
    - å¯é¸ WBF æˆ– Soft-NMS èåˆ
    """
```

**ä¸»è¦æ–¹æ³•**:

```python
def add_teacher(
    self,
    model: nn.Module,
    weight: float = 1.0,
    name: Optional[str] = None,
):
    """
    æ·»åŠ  Teacher æ¨¡å‹

    Args:
        model: æª¢æ¸¬æ¨¡å‹ï¼ˆå¿…é ˆè¼¸å‡º boxes, scores, labelsï¼‰
        weight: æ¨¡å‹æ¬Šé‡
        name: æ¨¡å‹åç¨±ï¼ˆç”¨æ–¼è­˜åˆ¥ï¼‰
    """
    model.eval()
    for param in model.parameters():
        param.requires_grad = False
    self.teachers.append(model)
    self.weights.append(weight)

def load_teachers_from_checkpoints(
    self,
    checkpoint_paths: List[str],
    model_class: Type[nn.Module],
    weights: Optional[List[float]] = None,
    **model_kwargs,
):
    """
    å¾å¤šå€‹ checkpoint è¼‰å…¥ Teachers

    Args:
        checkpoint_paths: checkpoint è·¯å¾‘åˆ—è¡¨
        model_class: æ¨¡å‹é¡åˆ¥
        weights: å„æ¨¡å‹æ¬Šé‡
        **model_kwargs: æ¨¡å‹åˆå§‹åŒ–åƒæ•¸
    """

def forward(
    self,
    images: torch.Tensor,
) -> Dict[str, torch.Tensor]:
    """
    ç²å–èåˆé æ¸¬

    Returns:
        {
            "boxes": [B, max_det, 4],
            "scores": [B, max_det],
            "labels": [B, max_det],
            "valid_mask": [B, max_det],
        }
    """
```

---

### MTKDTrainer è¨“ç·´å™¨è©³è§£

**æª”æ¡ˆ**: `train.py:139-437`

å®Œæ•´çš„è¨“ç·´ç®¡ç·šå¯¦ä½œã€‚

```python
class MTKDTrainer:
    """
    MTKD è¨“ç·´å™¨

    ç‰¹æ€§:
    - æ··åˆç²¾åº¦è¨“ç·´ (AMP)
    - æ¢¯åº¦è£å‰ª
    - å­¸ç¿’ç‡èª¿åº¦ï¼ˆWarmup + Cosine Annealingï¼‰
    - Early Stopping
    - Checkpoint ä¿å­˜/è¼‰å…¥
    - è¨“ç·´æŒ‡æ¨™è¿½è¹¤
    """
```

**åˆå§‹åŒ–åƒæ•¸**:

| åƒæ•¸ | é¡å‹ | é»˜èªå€¼ | èªªæ˜ |
|------|------|--------|------|
| `config` | dict | å¿…å¡« | è¨“ç·´é…ç½® |
| `model` | MTKDModel | å¿…å¡« | MTKD æ¨¡å‹ |
| `train_loader` | DataLoader | å¿…å¡« | è¨“ç·´æ•¸æ“š |
| `val_loader` | DataLoader | None | é©—è­‰æ•¸æ“š |
| `device` | str | "cuda" | é‹ç®—è¨­å‚™ |

**é…ç½®çµæ§‹ï¼ˆget_default_configï¼‰**:

```python
def get_default_config() -> Dict:
    return {
        "model": {
            "num_classes": 1,
            "student_config": {
                "backbone_config": {
                    "backbone_type": "resnet50",
                    "pretrained": True,
                    "out_channels": [256, 512, 1024, 2048],
                },
                "head_config": {
                    "num_classes": 1,
                    "num_queries": 100,
                    "hidden_dim": 256,
                    "num_heads": 8,
                    "num_encoder_layers": 6,
                    "num_decoder_layers": 6,
                },
            },
            "dino_teacher_config": {
                "model_name": "vit_base",
                "patch_size": 16,
                "embed_dim": 768,
            },
            "ensemble_config": {
                "fusion_method": "wbf",
                "fusion_config": {
                    "iou_threshold": 0.55,
                    "conf_type": "avg",
                },
            },
            "loss_config": {
                "feature_weight": 1.0,
                "prediction_weight": 2.0,
                "detection_weight": 0.0,
                "warmup_epochs": 5,
                "weight_schedule": "cosine",
                "feature_loss_config": {
                    "loss_type": "cosine",
                    "normalize": True,
                },
                "prediction_loss_config": {
                    "box_loss_type": "giou",
                    "class_loss_type": "kl",
                    "temperature": 4.0,
                },
            },
        },
        "training": {
            "epochs": 100,
            "batch_size": 8,
            "learning_rate": 1e-4,
            "weight_decay": 1e-4,
            "gradient_clip_max_norm": 1.0,
            "mixed_precision": True,
            "lr_scheduler": "cosine",
            "warmup_epochs": 5,
            "min_lr": 1e-6,
        },
        "validation": {
            "val_interval": 1,
            "save_best": True,
            "metric": "loss",
        },
        "checkpoint": {
            "save_dir": "./checkpoints",
            "save_interval": 10,
            "keep_last_n": 5,
        },
        "early_stopping": {
            "enabled": True,
            "patience": 20,
            "min_delta": 1e-4,
        },
    }
```

**è¨“ç·´æµç¨‹**:

```python
def train(self):
    """
    ä¸»è¨“ç·´å¾ªç’°

    æµç¨‹:
    1. åˆå§‹åŒ– optimizer, scheduler, scaler
    2. æ¯å€‹ epoch:
       a. è¨“ç·´ä¸€å€‹ epoch (train_epoch)
       b. é©—è­‰ï¼ˆå¦‚æœæœ‰ val_loaderï¼‰
       c. æ›´æ–° scheduler
       d. ä¿å­˜ checkpoint
       e. æª¢æŸ¥ early stopping
    """
    for epoch in range(self.start_epoch, self.config["training"]["epochs"]):
        # è¨“ç·´
        train_metrics = self.train_epoch(epoch)

        # é©—è­‰
        if self.val_loader and epoch % self.config["validation"]["val_interval"] == 0:
            val_metrics = self.validate(epoch)

        # Scheduler step
        if self.scheduler is not None:
            self.scheduler.step()

        # Checkpoint
        if epoch % self.config["checkpoint"]["save_interval"] == 0:
            self.save_checkpoint(epoch)

        # Early stopping
        if self.early_stopping(val_metrics["loss"]):
            print(f"Early stopping at epoch {epoch}")
            break

def train_epoch(self, epoch: int) -> Dict[str, float]:
    """
    è¨“ç·´ä¸€å€‹ epoch

    ä½¿ç”¨:
    - Mixed precision (GradScaler)
    - Gradient clipping
    - Loss è¿½è¹¤
    """
    self.model.train()
    meter = AverageMeterDict()

    for batch_idx, (images, targets) in enumerate(self.train_loader):
        images = images.to(self.device)

        with torch.cuda.amp.autocast(enabled=self.mixed_precision):
            loss, loss_dict = self.model.training_step(
                images, targets, epoch=epoch,
                total_epochs=self.config["training"]["epochs"]
            )

        # Backward
        self.optimizer.zero_grad()
        self.scaler.scale(loss).backward()

        # Gradient clipping
        if self.gradient_clip_max_norm > 0:
            self.scaler.unscale_(self.optimizer)
            torch.nn.utils.clip_grad_norm_(
                self.model.parameters(),
                self.gradient_clip_max_norm
            )

        self.scaler.step(self.optimizer)
        self.scaler.update()

        meter.update(loss_dict)

    return meter.get_averages()
```

---

### HungarianMatchingLoss è©³è§£

**æª”æ¡ˆ**: `losses/prediction_alignment.py:396-657`

ä½¿ç”¨ Hungarian ç®—æ³•è§£æ±ºé æ¸¬æ•¸é‡ä¸ä¸€è‡´çš„å•é¡Œã€‚

```python
class HungarianMatchingLoss(nn.Module):
    """
    Hungarian Matching Loss

    ç”¨é€”:
    - ç•¶ student å’Œ teacher é æ¸¬æ•¸é‡ä¸åŒæ™‚
    - DETR é¢¨æ ¼çš„ä¸€å°ä¸€åŒ¹é…
    - è‡ªå‹•æ‰¾å‡ºæœ€å„ªé…å°

    ç®—æ³•:
    1. è¨ˆç®— cost matrix (box cost + class cost)
    2. ä½¿ç”¨ Hungarian ç®—æ³•æ‰¾æœ€å„ªåŒ¹é…
    3. åªå°åŒ¹é…çš„é æ¸¬è¨ˆç®—æå¤±
    """
```

**Cost Matrix è¨ˆç®—**:

```python
def _compute_cost_matrix(
    self,
    student_pred: Dict[str, Tensor],
    teacher_pred: Dict[str, Tensor],
) -> Tensor:
    """
    è¨ˆç®—é…å°æˆæœ¬çŸ©é™£

    Cost = box_cost_weight * box_cost + class_cost_weight * class_cost

    box_cost: 1 - GIoU(student_box, teacher_box)
    class_cost: 1 - CosineSim(student_logit, teacher_logit)
    """
    # Box cost
    student_boxes = student_pred["boxes"]  # [B, N_s, 4]
    teacher_boxes = teacher_pred["boxes"]  # [B, N_t, 4]

    # è¨ˆç®—æ‰€æœ‰ pairs çš„ GIoU
    giou_matrix = self._compute_giou_matrix(student_boxes, teacher_boxes)
    box_cost = 1 - giou_matrix  # [B, N_s, N_t]

    # Class cost
    student_logits = F.softmax(student_pred["logits"], dim=-1)
    teacher_logits = F.softmax(teacher_pred["logits"], dim=-1)

    # Cosine similarity
    s_norm = F.normalize(student_logits, dim=-1)  # [B, N_s, C]
    t_norm = F.normalize(teacher_logits, dim=-1)  # [B, N_t, C]
    class_sim = torch.bmm(s_norm, t_norm.transpose(1, 2))  # [B, N_s, N_t]
    class_cost = 1 - class_sim

    # Total cost
    cost_matrix = self.box_cost_weight * box_cost + self.class_cost_weight * class_cost

    return cost_matrix
```

**Hungarian æ±‚è§£**:

```python
def _hungarian_matching(self, cost_matrix: Tensor) -> List[Tuple[Tensor, Tensor]]:
    """
    ä½¿ç”¨ scipy.optimize.linear_sum_assignment æ±‚è§£

    Returns:
        indices: List[(row_indices, col_indices)] for each batch
    """
    from scipy.optimize import linear_sum_assignment

    indices = []
    for b in range(cost_matrix.shape[0]):
        cost_b = cost_matrix[b].detach().cpu().numpy()
        row_ind, col_ind = linear_sum_assignment(cost_b)
        indices.append((
            torch.tensor(row_ind, device=cost_matrix.device),
            torch.tensor(col_ind, device=cost_matrix.device)
        ))
    return indices
```

---

### å·¥å…·é¡åˆ¥

#### AverageMeterDict

**ç”¨é€”**: è¿½è¹¤å¤šå€‹è¨“ç·´æŒ‡æ¨™çš„ç§»å‹•å¹³å‡

```python
class AverageMeterDict:
    def __init__(self):
        self.meters = {}

    def update(self, values: Dict[str, float], n: int = 1):
        for k, v in values.items():
            if k not in self.meters:
                self.meters[k] = {"sum": 0, "count": 0}
            self.meters[k]["sum"] += v * n
            self.meters[k]["count"] += n

    def get_averages(self) -> Dict[str, float]:
        return {
            k: v["sum"] / v["count"]
            for k, v in self.meters.items()
        }
```

#### EarlyStopping

**ç”¨é€”**: æå‰åœæ­¢è¨“ç·´ä»¥é˜²æ­¢éæ“¬åˆ

```python
class EarlyStopping:
    def __init__(
        self,
        patience: int = 10,
        min_delta: float = 0.0,
        mode: str = "min",
    ):
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.counter = 0
        self.best_score = None

    def __call__(self, score: float) -> bool:
        if self.best_score is None:
            self.best_score = score
            return False

        if self._is_improvement(score):
            self.best_score = score
            self.counter = 0
        else:
            self.counter += 1

        return self.counter >= self.patience

    def _is_improvement(self, score: float) -> bool:
        if self.mode == "min":
            return score < self.best_score - self.min_delta
        else:
            return score > self.best_score + self.min_delta
```

---

### æ•ˆèƒ½è€ƒé‡

#### è¨˜æ†¶é«”å„ªåŒ–

```python
# 1. Teachers å®Œå…¨å‡çµï¼Œä¸å„²å­˜æ¢¯åº¦
for teacher in ensemble_teachers:
    teacher.eval()
    for param in teacher.parameters():
        param.requires_grad = False

# 2. ä½¿ç”¨ torch.no_grad() é€²è¡Œ teacher æ¨ç†
with torch.no_grad():
    dino_features = dino_teacher(images)
    ensemble_predictions = ensemble_teachers(images)

# 3. æ··åˆç²¾åº¦è¨“ç·´æ¸›å°‘è¨˜æ†¶é«”
with torch.cuda.amp.autocast():
    student_output = student(images)
    loss = loss_fn(...)
```

#### è¨ˆç®—æ•ˆç‡

| æ“ä½œ | æˆæœ¬ | å„ªåŒ–æ–¹å¼ |
|------|------|---------|
| DINO æ¨ç† | é«˜ | æ‰¹æ¬¡è™•ç† + å‡çµ |
| WBF | ä¸­ | å‘é‡åŒ–æ“ä½œ |
| Hungarian Matching | O(NÂ³) | é™åˆ¶ max_detections |
| Feature Adapter | ä½ | ç°¡å–®ç·šæ€§å±¤ |

---

## åƒè€ƒæ–‡ç»

1. DINO: Emerging Properties in Self-Supervised Vision Transformers
2. Knowledge Distillation: A Survey
3. Weighted Boxes Fusion: Ensembling boxes from different object detection models
4. Multi-Task Learning Using Uncertainty to Weigh Losses
5. YOLOv8: Ultralytics YOLO
6. DETR: End-to-End Object Detection with Transformers
7. Soft-NMS: Improving Object Detection With One Line of Code

---

## License

MIT License
