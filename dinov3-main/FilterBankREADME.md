# SEGM v2: Spatially-Elastic Grid Modulation
## Row-wise Adaptive Multi-Frequency for Stomata Detection

---

> âš ï¸ **å¯¦ä½œç‹€æ…‹ï¼šè¦åŠƒä¸­ (Planning Stage)**
>
> æœ¬æ–‡ä»¶ç‚ºæŠ€è¡“è¦æ ¼æ›¸ï¼Œè©³ç´°æè¿° SEGM v2 çš„è¨­è¨ˆæ¶æ§‹å’Œå¯¦ä½œè¨ˆåŠƒã€‚
>
> | ç‹€æ…‹ | èªªæ˜ |
> |------|------|
> | ğŸ“„ **è¦æ ¼æ–‡ä»¶** | âœ… å·²å®Œæˆ |
> | ğŸ”§ **Python å¯¦ä½œ** | âŒ å°šæœªé–‹å§‹ |
> | ğŸ§ª **æ¸¬è©¦é©—è­‰** | âŒ å°šæœªé–‹å§‹ |
>
> **å¾…å¯¦ä½œçš„æ¨¡çµ„**ï¼ˆå°‡æ”¾åœ¨ `dinov3-main/segm_v2/`ï¼‰ï¼š
> - `models/segm_vision_transformer.py` - ç¹¼æ‰¿ DINOv3 çš„ä¸»æ¨¡å‹
> - `models/segm_adapter.py` - Block é–“çš„ SEGM é©é…å™¨
> - `models/frequency_estimator.py` - Row-wise FFT é »ç‡ä¼°è¨ˆ
> - `models/grid_generator.py` - é€±æœŸæ€§ Grid ç”Ÿæˆ
> - `losses/unsupervised_loss.py` - è‡ªç›£ç£æå¤±å‡½æ•¸
> - `train.py` - è¨“ç·´è…³æœ¬

---

## ç›®éŒ„

1. [å°ˆæ¡ˆæ¦‚è¿°](#1-å°ˆæ¡ˆæ¦‚è¿°)
   - 1.4 [â­ SEGM æ’å…¥ä½ç½®ï¼ˆé‡è¦ï¼‰](#14--segm-æ’å…¥ä½ç½®é‡è¦)
2. [å•é¡ŒèƒŒæ™¯](#2-å•é¡ŒèƒŒæ™¯)
3. [DINOv3 ç¨‹å¼ç¢¼çµæ§‹åˆ†æ](#3-dinov3-ç¨‹å¼ç¢¼çµæ§‹åˆ†æ)
4. [æ•´åˆæ–¹æ¡ˆè¨­è¨ˆ](#4-æ•´åˆæ–¹æ¡ˆè¨­è¨ˆ)
5. [æ ¸å¿ƒæ¨¡çµ„è¦æ ¼](#5-æ ¸å¿ƒæ¨¡çµ„è¦æ ¼)
   - 5.5 [è™•ç†ä¸å®Œç¾é€±æœŸæ€§çš„ç­–ç•¥ï¼ˆA/B/C/Dï¼‰](#55-è™•ç†ä¸å®Œç¾é€±æœŸæ€§çš„ç­–ç•¥)
   - 5.6 [æ¨è–¦æ–¹æ¡ˆï¼šA + C + Soft Modulation](#56-æ¨è–¦æ–¹æ¡ˆa--c--soft-modulation)
6. [æå¤±å‡½æ•¸è¨­è¨ˆ](#6-æå¤±å‡½æ•¸è¨­è¨ˆ)ï¼ˆDINO ç„¡æ³•æª¢æ¸¬ stomata çš„æ‡‰å°ç­–ç•¥ï¼‰
7. [è¨“ç·´é…ç½®](#7-è¨“ç·´é…ç½®)
8. [å¯¦ä½œæª¢æŸ¥æ¸…å–®](#8-å¯¦ä½œæª¢æŸ¥æ¸…å–®)

**é™„éŒ„**
- [é™„éŒ„ Aï¼šDINOv3 é—œéµç¨‹å¼ç¢¼åƒè€ƒ](#é™„éŒ„-adinov3-é—œéµç¨‹å¼ç¢¼åƒè€ƒ)
- [é™„éŒ„ Bï¼šèˆ‡åŸ SPEC çš„å·®ç•°](#é™„éŒ„-bèˆ‡åŸ-spec-çš„å·®ç•°)
- [é™„éŒ„ Cï¼šç¨‹å¼ç¢¼é©—è­‰ä¾†æº](#é™„éŒ„-cç¨‹å¼ç¢¼é©—è­‰ä¾†æº)
- [é™„éŒ„ Dï¼šå¯¦ä½œæ³¨æ„äº‹é …](#é™„éŒ„-då¯¦ä½œæ³¨æ„äº‹é …)
- [é™„éŒ„ Eï¼šç¸½çµèˆ‡æ¨è–¦é…ç½®](#é™„éŒ„-eç¸½çµèˆ‡æ¨è–¦é…ç½®)
- [é™„éŒ„ Fï¼šå®Œæ•´å¯¦ä½œç¨‹å¼ç¢¼](#é™„éŒ„-få®Œæ•´å¯¦ä½œç¨‹å¼ç¢¼)ï¼ˆå¯ç›´æ¥ä½¿ç”¨ï¼‰

---

## 1. å°ˆæ¡ˆæ¦‚è¿°

### 1.1 ç›®æ¨™

åˆ©ç”¨æ°£å­”ï¼ˆStomataï¼‰çš„**æ°´å¹³é€±æœŸæ€§æ’åˆ—è¦å¾‹**ä½œç‚ºå…ˆé©—çŸ¥è­˜ï¼Œåœ¨ DINO çš„ä¸­é–“å±¤å¼•å°ç‰¹å¾µæå–ï¼Œé™ä½ noise å¹²æ“¾ã€‚

### 1.2 æ ¸å¿ƒè§€å¯Ÿ

```
ç¦¾æœ¬ç§‘æ¤ç‰©è‘‰ç‰‡çš„æ°£å­”æ’åˆ—ï¼š

Row 0:  â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘   â† æœ‰ stomataï¼Œé »ç‡ fâ‚€
Row 1:  â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   â† ç„¡ stomata
Row 2:  â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–‘â–‘   â† æœ‰ stomataï¼Œé »ç‡ fâ‚‚ (å¯èƒ½ â‰  fâ‚€)
Row 3:  â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   â† ç„¡ stomata
Row 4:  â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–ˆâ–‘   â† æœ‰ stomataï¼Œå¶çˆ¾æ¼æ‰
```

**ç‰¹æ€§**ï¼š
- åŒä¸€æ°´å¹³è¡Œå…§ï¼Œstomata å¤§è‡´é€±æœŸæ€§å‡ºç¾
- ä¸åŒè¡Œçš„é »ç‡å¯èƒ½ä¸åŒ
- ä¸æ˜¯å®Œç¾é€±æœŸï¼Œå¶çˆ¾æœƒå°‘

### 1.3 è¨­è¨ˆåŸå‰‡

| åŸå‰‡ | èªªæ˜ |
|-----|------|
| **ä¸ä¿®æ”¹ DINOv3 åŸå§‹ç¢¼** | ä½¿ç”¨çµ„åˆæˆ–ç¹¼æ‰¿ |
| **å‡çµé è¨“ç·´æ¬Šé‡** | åªè¨“ç·´ SEGM åƒæ•¸ |
| **Zero-Init Gate** | åˆå§‹æ™‚ä¸å½±éŸ¿ DINO è¼¸å‡º |
| **Unsupervised** | ä¸éœ€è¦æ¨™è¨»è³‡æ–™ |

### 1.4 â­ SEGM æ’å…¥ä½ç½®ï¼ˆé‡è¦ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        DINOv3 ViT-Base æ¶æ§‹                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                          â”‚
â”‚  Input Image                                                             â”‚
â”‚       â†“                                                                  â”‚
â”‚  Patch Embed + CLS Token                                                â”‚
â”‚       â†“                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                            â”‚
â”‚  â”‚ Block 0 â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚                 â”‚
â”‚       â†“                                               â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                          â”‚                 â”‚
â”‚  â”‚ Block 1 â”‚                                          â”‚ å‡çµ            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                          â”‚ (Frozen)        â”‚
â”‚       â†“                                               â”‚                 â”‚
â”‚      ...                                              â”‚                 â”‚
â”‚       â†“                                               â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚                 â”‚
â”‚  â”‚ Block 10 â”‚ â†â”€â”€ å€’æ•¸ç¬¬ 2 å±¤                         â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”˜                 â”‚
â”‚       â†“                                                                  â”‚
â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—  â”‚
â”‚  â•‘                     â­ SEGM æ’å…¥é» â­                              â•‘  â”‚
â”‚  â•‘                                                                    â•‘  â”‚
â”‚  â•‘  patch_tokens â”€â†’ [é »ç‡ä¼°è¨ˆ] â”€â†’ [Gridç”Ÿæˆ] â”€â†’ [èª¿è®Š] â”€â†’ enhanced   â•‘  â”‚
â”‚  â•‘                      â†“              â†“                              â•‘  â”‚
â”‚  â•‘               Row-wise FFT    é€±æœŸæ€§ Grid                          â•‘  â”‚
â”‚  â•‘                                                                    â•‘  â”‚
â”‚  â•‘  ğŸ“ ä½ç½®: Block 10 ä¹‹å¾Œ, Block 11 ä¹‹å‰                             â•‘  â”‚
â”‚  â•‘  ğŸ“ ç¨‹å¼ç¢¼: segm_after_blocks=[10]                                 â•‘  â”‚
â”‚  â•‘  ğŸ“ å¯è¨“ç·´åƒæ•¸: åªæœ‰ SEGMï¼ˆç´„ 2M åƒæ•¸ï¼‰                            â•‘  â”‚
â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚       â†“                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”                 â”‚
â”‚  â”‚ Block 11 â”‚ â†â”€â”€ å—åˆ° SEGM å¼•å°                      â”‚ å‡çµ            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”‚ (Frozen)        â”‚
â”‚       â†“                                               â”‚                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚                 â”‚
â”‚  â”‚ Block 12 â”‚ â†â”€â”€ æœ€å¾Œä¸€å±¤ï¼Œä¹Ÿå—ç›Š                    â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                         â”˜                 â”‚
â”‚       â†“                                                                  â”‚
â”‚  Layer Norm                                                              â”‚
â”‚       â†“                                                                  â”‚
â”‚  Output Features (å·²è¢«é€±æœŸæ€§å¼•å°å¢å¼·)                                    â”‚
â”‚                                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**é—œéµèªªæ˜**ï¼š

| é …ç›® | èªªæ˜ |
|-----|------|
| **æ’å…¥ä½ç½®** | Block 10 è¼¸å‡ºä¹‹å¾Œï¼ŒBlock 11 è¼¸å…¥ä¹‹å‰ |
| **Block ç´¢å¼•** | `segm_after_blocks=[10]`ï¼ˆ0-indexedï¼Œç¬¬ 11 å€‹ Blockï¼‰ |
| **ç‚ºä»€éº¼é¸é€™è£¡** | è®“ Block 11, 12 éƒ½èƒ½å—åˆ°é€±æœŸæ€§å¼•å° |
| **å¯¦ä½œæ–¹å¼** | ç¹¼æ‰¿ `DinoVisionTransformer`ï¼Œè¦†å¯« `forward_features_list` |
| **å‡çµç‹€æ…‹** | DINO å…¨éƒ¨å‡çµï¼Œåªè¨“ç·´ SEGM æ¨¡çµ„ |

### 1.5 â­ ç†è«–åŸºç¤èˆ‡é—œéµæ´å¯Ÿ

#### ç‚ºä»€éº¼æ­¤è¨­è¨ˆæœ‰æ•ˆï¼ˆå³ä½¿ DINO ç„¡æ³•å€åˆ†å–®å€‹ stomataï¼‰

**å¸¸è¦‹èª¤è§£**ï¼šã€ŒDINO ç‰¹å¾µç„¡æ³•å€åˆ† stomata å’Œ noiseï¼Œæ‰€ä»¥ FilterBank ç„¡æ³•å·¥ä½œã€

**æ­£ç¢ºç†è§£**ï¼šL_intra ä¾è³´çš„æ˜¯ **ç¾¤é«”ä¸€è‡´æ€§ï¼ˆGroup Consistencyï¼‰**ï¼Œè€Œéå–®å€‹ç‰¹å¾µçš„å€åˆ†åº¦

```
Individual levelï¼ˆå–®å€‹æ¨£æœ¬ï¼‰:
  stomata_feature â‰ˆ noise_feature  â† é›£ä»¥å€åˆ† âŒ

Group levelï¼ˆç¾¤é«”ï¼‰:
  {stomata_1, stomata_2, stomata_3} â†’ é«˜åº¦ä¸€è‡´ï¼ˆåŒä¸€é¡ç‰©é«”ï¼‰âœ“
  {reflection, cell_wall, vein}    â†’ ä¸ä¸€è‡´ï¼ˆä¸åŒé¡ç‰©é«”ï¼‰âœ—
```

**é—œéµæ´å¯Ÿ**ï¼š

| å ´æ™¯ | å³°å€¼ä½ç½®åŒ…å« | ç‰¹å¾µä¸€è‡´æ€§ | L_intra |
|-----|------------|----------|---------|
| Grid å°åˆ° stomata | å…¨æ˜¯ stomata | é«˜ï¼ˆåŒé¡ç‰©é«”ï¼‰ | **ä½** âœ“ |
| Grid å°åˆ° noise | å„ç¨® noise æ··åˆ | ä½ï¼ˆä¸åŒé¡ç‰©é«”ï¼‰ | **é«˜** âœ— |
| Grid å°åˆ°æ··åˆ | stomata + noise | ä¸­ç­‰ | **ä¸­ç­‰** âœ— |

**è¨“ç·´æ©Ÿåˆ¶**ï¼š
```
åˆå§‹: FFT ä¼°è¨ˆé »ç‡ â†’ ç”Ÿæˆåˆå§‹ Gridï¼ˆå¯èƒ½ä¸æº–ï¼‰
  â†“
L_intra æª¢æŸ¥: å³°å€¼ä½ç½®çš„ç‰¹å¾µæ˜¯å¦ä¸€è‡´ï¼Ÿ
  â†“
å¦‚æœä¸ä¸€è‡´ â†’ Loss é«˜ â†’ æ¢¯åº¦èª¿æ•´ Grid åƒæ•¸ï¼ˆé »ç‡ã€ç›¸ä½ï¼‰
  â†“
è¿­ä»£æ”¶æ–‚ â†’ Grid å°é½Šåˆ°ã€Œç‰¹å¾µæœ€ä¸€è‡´ã€çš„é€±æœŸæ€§ä½ç½®ï¼ˆ= stomataï¼‰
```

#### L_intra æœ‰æ•ˆçš„å‰ææ¢ä»¶

```python
# æ ¸å¿ƒå‡è¨­ï¼šstomata ç¾¤é«”ä¸€è‡´æ€§ > noise ç¾¤é«”ä¸€è‡´æ€§

# é©—è­‰æ–¹æ³•ï¼ˆè¨“ç·´å‰å»ºè­°åŸ·è¡Œï¼‰
stomata_features = dino_features[stomata_positions]  # äººå·¥æ¨™è¨˜å¹¾å€‹
noise_features = dino_features[noise_positions]      # åå…‰ã€è‘‰è„ˆã€ç´°èƒå£ç­‰

stomata_consistency = pairwise_cosine_sim(stomata_features).mean()
noise_consistency = pairwise_cosine_sim(noise_features).mean()

assert stomata_consistency > noise_consistency, "å‡è¨­ä¸æˆç«‹ï¼Œéœ€é‡æ–°è¨­è¨ˆ"
```

#### 14Ã—14 FFT è§£æåº¦çš„è€ƒé‡

**å•é¡Œ**ï¼š14 é» FFT åªæœ‰ 7 å€‹é »ç‡ binï¼Œè§£æåº¦å¾ˆç²—

**ç‚ºä»€éº¼ä»å¯è¡Œ**ï¼š
1. FFT åªæ˜¯æä¾›**åˆå§‹æ–¹å‘**ï¼Œä¸éœ€è¦ç²¾ç¢º
2. **Loss å‡½æ•¸åšæœ€çµ‚èª¿æ•´**ï¼šL_intra æœƒ fine-tune Grid åˆ°æ­£ç¢ºä½ç½®
3. é€±æœŸæ€§ç´„æŸé™åˆ¶è§£ç©ºé–“ï¼šGrid å¿…é ˆæ˜¯é€±æœŸçš„ï¼Œé˜²æ­¢ä»»æ„è®Šå½¢

```
FFT è§’è‰²: ç²—ç•¥ä¼°è¨ˆ â†’ "å¤§ç´„æ¯ 3-5 å€‹ patch æœ‰ä¸€å€‹ stomata"
Loss è§’è‰²: ç²¾ç¢ºèª¿æ•´ â†’ "å…·é«”åœ¨å“ªå€‹ç›¸ä½ï¼Œå“ªå€‹ç¢ºåˆ‡é »ç‡"
```

#### èˆ‡ MTKD æ¡†æ¶çš„æ•´åˆ

FilterBank-enhanced DINO å¯ä»¥èˆ‡ MTKD æ¡†æ¶çµåˆï¼š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          MTKD + FilterBank                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                      â”‚
â”‚  Input Image                                                         â”‚
â”‚       â”‚                                                              â”‚
â”‚       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚       â”‚                â”‚                â”‚                â”‚          â”‚
â”‚       â–¼                â–¼                â–¼                â–¼          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚  â”‚  DINO   â”‚    â”‚ DINO +      â”‚   â”‚ YOLOv8   â”‚   â”‚ YOLOv11  â”‚      â”‚
â”‚  â”‚(åŸå§‹)   â”‚    â”‚ FilterBank  â”‚   â”‚ Teacher  â”‚   â”‚ Student  â”‚      â”‚
â”‚  â”‚         â”‚    â”‚(é€±æœŸæ€§å¢å¼·)  â”‚   â”‚ (Frozen) â”‚   â”‚(Trainable)â”‚      â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜      â”‚
â”‚       â”‚                â”‚               â”‚              â”‚             â”‚
â”‚       â”‚         Enhanced Features      â”‚         Predictions        â”‚
â”‚       â”‚         (é€±æœŸæ€§å€åŸŸå¼·åŒ–)        â”‚              â”‚             â”‚
â”‚       â”‚                â”‚               â”‚              â”‚             â”‚
â”‚       â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚             â”‚
â”‚       â”‚                        â”‚                      â”‚             â”‚
â”‚       â”‚                        â–¼                      â–¼             â”‚
â”‚       â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚       â”‚              â”‚           MTKD Loss                 â”‚        â”‚
â”‚       â”‚              â”‚                                     â”‚        â”‚
â”‚       â”‚              â”‚  Feature Align: YOLO11 â†” Enhanced   â”‚        â”‚
â”‚       â”‚              â”‚  Pred Align: YOLO11 â†” YOLO8         â”‚        â”‚
â”‚       â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚       â”‚                                                              â”‚
â”‚       â”‚   è¨“ç·´æ•ˆæœ:                                                  â”‚
â”‚       â”‚   - YOLO11 å­¸ç¿’å°é½Š Enhanced Features                        â”‚
â”‚       â”‚   - Enhanced Features å¼·èª¿é€±æœŸæ€§å€åŸŸï¼ˆçœŸ stomataï¼‰            â”‚
â”‚       â”‚   - YOLO11 å› æ­¤åå¥½é€±æœŸæ€§ä½ç½® â†’ æ¸›å°‘ False Positives          â”‚
â”‚       â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**æ•´åˆé‚è¼¯**ï¼š
1. YOLOv8 Teacher æä¾›é æ¸¬ï¼ˆå« stomata + noiseï¼‰
2. FilterBank-enhanced DINO æä¾›ç‰¹å¾µï¼ˆé€±æœŸæ€§å€åŸŸè¢«å¼·åŒ–ï¼‰
3. YOLOv11 Student åŒæ™‚å°é½Šå…©è€…
4. ç”±æ–¼ Enhanced Features å¼·èª¿é€±æœŸæ€§ï¼ŒStudent å­¸æœƒåå¥½é€±æœŸæ€§ä½ç½®
5. çµæœï¼šStudent çš„ False Positives æ¸›å°‘

---

## 2. å•é¡ŒèƒŒæ™¯

### 2.1 ç¾æœ‰å•é¡Œ

DINO çš„ attention heatmap æŠ“åˆ°å¤ªå¤š noiseï¼ˆåå…‰ã€è‘‰è„ˆã€ç´°èƒå£ç­‰ï¼‰ï¼Œå°è‡´é›£ä»¥æº–ç¢ºæª¢æ¸¬ stomataã€‚

### 2.2 ç‚ºä»€éº¼è¦åœ¨å…§éƒ¨æ’å…¥ï¼Ÿ

```
Post-process æ–¹æ¡ˆï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Block 1 â†’ ... â†’ Block 12 â†’ [å·²ç¶“æœ‰ noise çš„è¼¸å‡º]       â”‚
â”‚                                      â†“                  â”‚
â”‚                                Post-process             â”‚
â”‚                                (åªèƒ½éæ¿¾ï¼Œç„¡æ³•å¼•å°)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Internal æ’å…¥æ–¹æ¡ˆï¼š
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Block 1 â†’ ... â†’ Block 10 â†’ [SEGM å¼•å°] â†’ Block 11-12   â”‚
â”‚                                  â†“                      â”‚
â”‚                   å¼•å°å¾ŒçºŒå±¤é—œæ³¨é€±æœŸæ€§ä½ç½®               â”‚
â”‚                                  â†“                      â”‚
â”‚                          æ›´ä¹¾æ·¨çš„æœ€çµ‚è¼¸å‡º               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. DINOv3 ç¨‹å¼ç¢¼çµæ§‹åˆ†æ

> ä»¥ä¸‹åˆ†æåŸºæ–¼å¯¦éš›ç¨‹å¼ç¢¼ `dinov3-main/dinov3/`

### 3.1 DinoVisionTransformer é¡åˆ¥çµæ§‹

**æª”æ¡ˆ**ï¼š`models/vision_transformer.py`

```
DinoVisionTransformer(nn.Module)
â”œâ”€â”€ patch_embed: PatchEmbed
â”œâ”€â”€ cls_token: Parameter (1, 1, embed_dim)
â”œâ”€â”€ storage_tokens: Parameter (1, n_storage, embed_dim)  # å¯é¸
â”œâ”€â”€ rope_embed: RopePositionEmbedding
â”œâ”€â”€ blocks: ModuleList[SelfAttentionBlock]  # depth å€‹
â”œâ”€â”€ norm: LayerNorm
â”œâ”€â”€ cls_norm: LayerNorm  # å¯é¸
â””â”€â”€ mask_token: Parameter (1, embed_dim)
```

**é—œéµå±¬æ€§**ï¼š

| å±¬æ€§ | ViT-Base å€¼ | èªªæ˜ |
|-----|------------|------|
| `embed_dim` | 768 | ç‰¹å¾µç¶­åº¦ |
| `n_blocks` / `depth` | 12 | Block æ•¸é‡ |
| `num_heads` | 12 | Attention heads |
| `patch_size` | 16 | Patch å¤§å° |
| `n_storage_tokens` | 0 | Storage tokens æ•¸é‡ï¼ˆé è¨­ 0ï¼‰ |

### 3.2 Token è™•ç†æµç¨‹

**æ–¹æ³•**ï¼š`prepare_tokens_with_masks` (lines 190-220)

```
è¼¸å…¥: x (B, 3, H_img, W_img)
  â†“ patch_embed
(B, H, W, C)  # H = H_img/patch_size, W = W_img/patch_size
  â†“ flatten(1, 2)
(B, HÃ—W, C)
  â†“ cat([cls_token, storage_tokens, x])
(B, 1 + n_storage + HÃ—W, C)

è¼¸å‡º: (tokens, (H, W))
```

**ç¯„ä¾‹**ï¼ˆViT-Base, 224Ã—224 è¼¸å…¥ï¼‰ï¼š

| éšæ®µ | Shape | èªªæ˜ |
|-----|-------|------|
| åŸå§‹åœ–åƒ | (B, 3, 224, 224) | RGB |
| patch_embed å¾Œ | (B, 14, 14, 768) | 14 = 224/16 |
| flatten å¾Œ | (B, 196, 768) | 196 = 14Ã—14 |
| åŠ  CLS å¾Œ | (B, 197, 768) | +1 for CLS |

### 3.3 forward_features_list æ–¹æ³•

**æª”æ¡ˆ**ï¼š`vision_transformer.py` (lines 222-261)

```python
def forward_features_list(self, x_list: List[Tensor], masks_list: List[Tensor]):
    # 1. æº–å‚™ tokens
    x = []
    rope = []
    for t_x, t_masks in zip(x_list, masks_list):
        t2_x, hw_tuple = self.prepare_tokens_with_masks(t_x, t_masks)
        x.append(t2_x)
        rope.append(hw_tuple)  # rope å­˜çš„æ˜¯ (H, W) tupleï¼

    # 2. Block è¿´åœˆ
    for _, blk in enumerate(self.blocks):  # âš ï¸ index è¢«ä¸Ÿæ£„
        if self.rope_embed is not None:
            rope_sincos = [self.rope_embed(H=H, W=W) for H, W in rope]
        else:
            rope_sincos = [None for r in rope]
        x = blk(x, rope_sincos)  # x æ˜¯ List[Tensor]ï¼

    # 3. Norm å’Œè¼¸å‡º
    ...
```

**é‡è¦ç™¼ç¾**ï¼š

| é …ç›® | èªªæ˜ |
|-----|------|
| `x` æ˜¯ **List[Tensor]** | ä¸æ˜¯å–®ä¸€ Tensorï¼Œå› ç‚ºè¦æ”¯æ´ multi-crop |
| `rope` å­˜ **(H, W) tuples** | ä¸æ˜¯ position embeddings |
| Block è¿´åœˆçš„ index è¢«ä¸Ÿæ£„ | åŸå§‹ç¨‹å¼ç¢¼ç”¨ `for _, blk in enumerate(...)` |

### 3.4 SelfAttentionBlock çµæ§‹

**æª”æ¡ˆ**ï¼š`layers/block.py` (lines 21-212)

```python
class SelfAttentionBlock(nn.Module):
    def forward(self, x_or_x_list, rope_or_rope_list=None):
        if isinstance(x_or_x_list, Tensor):
            # å–®ä¸€ tensorï¼šåŒ…æˆ list è™•ç†
            return self._forward_list([x_or_x_list], [rope_or_rope_list])[0]
        elif isinstance(x_or_x_list, list):
            # List of tensors
            return self._forward_list(x_or_x_list, rope_list=rope_or_rope_list)
```

**è¼¸å…¥è¼¸å‡ºæ ¼å¼**ï¼š
- è¼¸å…¥ï¼š`List[Tensor]`ï¼Œæ¯å€‹ tensor æ˜¯ `(B, N, C)`
- è¼¸å‡ºï¼š`List[Tensor]`ï¼ŒåŒæ¨£æ ¼å¼

### 3.5 Attention æ©Ÿåˆ¶

**æª”æ¡ˆ**ï¼š`layers/attention.py` (lines 106-118)

```python
def compute_attention(self, qkv, attn_bias=None, rope=None):
    ...
    x = torch.nn.functional.scaled_dot_product_attention(q, k, v)  # Flash Attention
    ...
```

**é™åˆ¶**ï¼šä½¿ç”¨ Flash Attentionï¼Œ**ç„¡æ³•ç›´æ¥æå– attention weights**ã€‚

### 3.6 ç¾æœ‰ Adapter è¨­è¨ˆåƒè€ƒ

**æª”æ¡ˆ**ï¼š`eval/segmentation/models/backbone/dinov3_adapter.py`

DINOv3 å®˜æ–¹çš„ Adapter ä½¿ç”¨ï¼š
- **çµ„åˆ**è€Œéç¹¼æ‰¿
- å‡çµ backboneï¼š`self.backbone.requires_grad_(False)`
- ä½¿ç”¨ `get_intermediate_layers` API æå–ä¸­é–“å±¤ç‰¹å¾µ

---

## 4. æ•´åˆæ–¹æ¡ˆè¨­è¨ˆ

### 4.1 æ–¹æ¡ˆæ¯”è¼ƒ

| æ–¹æ¡ˆ | å„ªé» | ç¼ºé» |
|-----|------|------|
| **A: ç¹¼æ‰¿ + è¦†å¯«** | å®Œå…¨æ§åˆ¶ forward | éœ€è¦è¤‡è£½å¤§é‡ç¨‹å¼ç¢¼ |
| **B: çµ„åˆ + Hooks** | ä¸ä¿®æ”¹åŸå§‹ç¢¼ | Hook æ©Ÿåˆ¶è¼ƒè¤‡é›œ |
| **C: çµ„åˆ + å¤–éƒ¨è™•ç†** | æœ€ç°¡å–® | åªèƒ½ post-process |

**å»ºè­°ï¼šæ–¹æ¡ˆ Aï¼ˆç¹¼æ‰¿ + è¦†å¯«ï¼‰**

ç†ç”±ï¼š
1. éœ€è¦åœ¨ Block ä¹‹é–“æ’å…¥ SEGMï¼Œè€Œéåªæ˜¯æå–ç‰¹å¾µ
2. Hook æ©Ÿåˆ¶é›–å¯è¡Œä½†è¼ƒè¤‡é›œ
3. å®˜æ–¹çš„ Adapter æ˜¯ post-processï¼Œä¸ç¬¦åˆæˆ‘å€‘çš„éœ€æ±‚

### 4.2 æ–¹æ¡ˆ A è©³ç´°è¨­è¨ˆ

#### 4.2.1 é¡åˆ¥ç¹¼æ‰¿

```
DinoVisionTransformer (dinov3-main)
         â”‚
         â–¼
SEGMDinoVisionTransformer (segm_v2)
    - è¦†å¯« forward_features_list()
    - æ–°å¢ segm_modules: ModuleDict
    - æ–°å¢ _apply_segm() æ–¹æ³•
```

#### 4.2.2 éœ€è¦è¦†å¯«çš„æ–¹æ³•

`forward_features_list`ï¼šä¿®æ”¹ Block è¿´åœˆï¼ŒåŠ å…¥ index è¿½è¹¤å’Œ SEGM æ’å…¥é»

```python
# åŸå§‹ï¼ˆvision_transformer.py:229-234ï¼‰
for _, blk in enumerate(self.blocks):
    ...
    x = blk(x, rope_sincos)

# ä¿®æ”¹å¾Œ
for blk_idx, blk in enumerate(self.blocks):
    ...
    x = blk(x, rope_sincos)
    if blk_idx in self.segm_after_blocks:
        x = self._apply_segm(x, blk_idx, rope)
```

#### 4.2.3 SEGM æ’å…¥ä½ç½®

| ä½ç½® | Block Index | èªªæ˜ |
|-----|-------------|------|
| Block 10 ä¹‹å¾Œ | 10 | è®“ Block 11, 12 éƒ½å—ç›Šï¼ˆ**æ¨è–¦**ï¼‰ |
| Block 11 ä¹‹å¾Œ | 11 | åªå½±éŸ¿æœ€å¾Œä¸€å±¤ |

#### 4.2.4 _apply_segm æ–¹æ³•è¨­è¨ˆ

```
è¼¸å…¥:
  - x_list: List[Tensor]ï¼Œæ¯å€‹ (B, N, C) å…¶ä¸­ N = 1 + n_storage + HÃ—W
  - blk_idx: int
  - rope: List[(H, W)]

è™•ç†:
  for x, (H, W) in zip(x_list, rope):
      1. åˆ†é›¢ prefix tokens å’Œ patch tokens
         prefix = x[:, :1+n_storage, :]
         patches = x[:, 1+n_storage:, :]

      2. SEGM è™•ç† patch tokens
         enhanced = segm_module(patches, H, W)

      3. é‡æ–°çµ„åˆ
         x = cat([prefix, enhanced])

è¼¸å‡º:
  - enhanced_x_list: List[Tensor]ï¼Œæ ¼å¼åŒè¼¸å…¥
```

### 4.3 æª”æ¡ˆçµæ§‹

```
Poaceae-Stomata-Detection/
â”œâ”€â”€ dinov3-main/                           # ä¸ä¿®æ”¹
â”‚   â””â”€â”€ dinov3/
â”‚       â”œâ”€â”€ models/vision_transformer.py   # åƒè€ƒ
â”‚       â””â”€â”€ layers/
â”‚           â”œâ”€â”€ block.py                   # åƒè€ƒ
â”‚           â””â”€â”€ attention.py               # åƒè€ƒ
â”‚
â”œâ”€â”€ segm_v2/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ segm_vision_transformer.py     # ç¹¼æ‰¿ DinoVisionTransformer
â”‚   â”‚   â”œâ”€â”€ segm_adapter.py                # SEGM æ ¸å¿ƒæ¨¡çµ„
â”‚   â”‚   â”œâ”€â”€ frequency_estimator.py         # Row-wise FFT
â”‚   â”‚   â””â”€â”€ grid_generator.py              # é€±æœŸæ€§ Grid ç”Ÿæˆ
â”‚   â”œâ”€â”€ losses/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ unsupervised_loss.py
â”‚   â””â”€â”€ train.py
â”‚
â””â”€â”€ configs/
    â””â”€â”€ segm_v2_config.yaml
```

---

## 5. æ ¸å¿ƒæ¨¡çµ„è¦æ ¼

### 5.1 SEGMAdapter

**è·è²¬**ï¼šåœ¨ Block ä¹‹é–“è™•ç† patch tokensï¼ŒåŠ å…¥é€±æœŸæ€§èª¿è®Š

#### è¼¸å…¥è¼¸å‡º

| é …ç›® | æ ¼å¼ | èªªæ˜ |
|-----|------|------|
| **è¼¸å…¥** | `(B, HÃ—W, C)` | åªæœ‰ patch tokens |
| | `H, W: int` | ä¾†è‡ª rope tuple |
| **è¼¸å‡º** | `(B, HÃ—W, C)` | å¢å¼·å¾Œçš„ tokens |
| | `grid: (B, H, W)` | é€±æœŸæ€§ Gridï¼ˆç”¨æ–¼ lossï¼‰ |
| | `freq_info: dict` | é »ç‡ä¼°è¨ˆè³‡è¨Šï¼ˆç”¨æ–¼ lossï¼‰ |

#### å…§éƒ¨æµç¨‹

```
è¼¸å…¥ patch_tokens (B, HÃ—W, C)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. Reshape to Spatial                   â”‚
â”‚    (B, HÃ—W, C) â†’ view â†’ (B, H, W, C)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Row-wise Frequency Estimation        â”‚
â”‚    å°æ¯ä¸€è¡Œåš 1D FFTï¼Œä¼°è¨ˆä¸»é »ç‡         â”‚
â”‚    è¼¸å‡º: dominant_freq (B, H)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Periodic Grid Generation             â”‚
â”‚    æ ¹æ“š freq ç”Ÿæˆé€±æœŸæ€§ Grid            â”‚
â”‚    è¼¸å‡º: grid (B, 1, H, W)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Channel Projection                   â”‚
â”‚    1Ã—1 Conv: (B, 1, H, W) â†’ (B, C, H, W)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Gated Residual                       â”‚
â”‚    output = input + gate Ã— delta        â”‚
â”‚    gate åˆå§‹åŒ–ç‚º 0                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
è¼¸å‡º enhanced_tokens (B, HÃ—W, C)
```

#### åƒæ•¸

| åƒæ•¸ | é¡å‹ | é è¨­å€¼ | èªªæ˜ |
|-----|------|-------|------|
| `embed_dim` | int | 768 | ç‰¹å¾µç¶­åº¦ |
| `num_freq_bins` | int | 32 | FFT é »ç‡ bin æ•¸é‡ |
| `hidden_dim` | int | 256 | é »ç‡ä¼°è¨ˆçš„éš±è—ç¶­åº¦ |

### 5.2 RowFrequencyEstimator

**è·è²¬**ï¼šå°æ¯ä¸€è¡Œé€²è¡Œé »ç‡åˆ†æï¼Œä¼°è¨ˆæ°´å¹³æ–¹å‘çš„é€±æœŸæ€§

#### è¼¸å…¥è¼¸å‡º

| é …ç›® | æ ¼å¼ | èªªæ˜ |
|-----|------|------|
| **è¼¸å…¥** | `(B, H, W, C)` | ç©ºé–“æ ¼å¼ç‰¹å¾µ |
| **è¼¸å‡º** | `dominant_freq: (B, H)` | æ¯è¡Œä¸»é »ç‡ï¼Œç¯„åœ [0, 1] |
| | `freq_spectrum: (B, H, num_bins)` | å®Œæ•´é »è­œ |

#### è™•ç†æµç¨‹

```
1. Feature Projection
   (B, H, W, C) â†’ MLP â†’ (B, H, W, hidden_dim)

2. Row-wise 1D rFFT
   å°æ¯è¡Œæ²¿ W æ–¹å‘åš FFT
   (B, H, W, hidden_dim) â†’ (B, H, hidden_dim, W//2+1) [complex]

3. Power Spectrum
   magnitudeÂ² â†’ mean over hidden_dim â†’ (B, H, W//2+1)

4. Interpolate to fixed bins
   (B, H, W//2+1) â†’ (B, H, num_freq_bins)

5. Find Dominant Frequency
   argmax (æ’é™¤ DC) â†’ normalize to [0, 1]
```

#### ã€ŒæŸè¡Œæ²’æœ‰ stomataã€çš„è™•ç†

ç•¶æŸè¡Œæ²’æœ‰æ˜é¡¯é€±æœŸæ€§æ™‚ï¼ŒFFT æœƒä¼°å‡º noiseã€‚è™•ç†æ–¹å¼ï¼š

| ç­–ç•¥ | èªªæ˜ |
|-----|------|
| **èƒ½é‡é–¾å€¼** | è‹¥ç¸½èƒ½é‡ä½æ–¼é–¾å€¼ï¼Œé »ç‡è¨­ç‚º 0 |
| **ç›¸é„°è¡Œå¹³æ»‘** | ç”¨ç›¸é„°è¡Œçš„é »ç‡åš weighted average |
| **å¯å­¸ç¿’æ¿¾æ³¢å™¨** | è®“æ¨¡å‹å­¸ç¿’å“ªäº›é »ç‡æ˜¯é‡è¦çš„ |

### 5.3 PeriodicGridGenerator

**è·è²¬**ï¼šæ ¹æ“šä¼°è¨ˆçš„é »ç‡ç”Ÿæˆé€±æœŸæ€§ Grid

#### è¼¸å…¥è¼¸å‡º

| é …ç›® | æ ¼å¼ | èªªæ˜ |
|-----|------|------|
| **è¼¸å…¥** | `dominant_freq: (B, H)` | æ¯è¡Œé »ç‡ |
| | `H, W: int` | ç©ºé–“ç¶­åº¦ |
| **è¼¸å‡º** | `grid: (B, 1, H, W)` | é€±æœŸæ€§ Gridï¼Œå€¼åŸŸ [0, 1] |

#### Grid ç”Ÿæˆå…¬å¼

**Power Cosine Wave**ï¼š

$$
\text{Wave}(t; f, \phi, \kappa) = \left( \frac{\cos(2\pi f t + \phi) + 1}{2} \right)^\kappa
$$

å…¶ä¸­ï¼š
- $f$ï¼šé »ç‡ï¼ˆä¾†è‡ª FFT ä¼°è¨ˆï¼‰
- $\phi$ï¼šç›¸ä½ï¼ˆå¯å­¸ç¿’åƒæ•¸ï¼‰
- $\kappa$ï¼šå°–éŠ³åº¦ï¼ˆæ§åˆ¶æ³¢å³°å¯¬åº¦ï¼‰

**ç‰¹æ€§**ï¼š
- $\kappa = 1$ï¼šæ¨™æº–é¤˜å¼¦æ³¢
- $\kappa > 1$ï¼šæ³¢å³°è®Šå°–ï¼ˆå°æ‡‰æ›´ç²¾ç¢ºçš„ä½ç½®ï¼‰
- $\kappa \to \infty$ï¼šè¶¨è¿‘è„ˆè¡

**2D Grid ç”Ÿæˆ**ï¼š

```
Row wave: R(x, h) = Wave(x; freq[h], phase[h], Îº)
Col wave: C(y) = Wave(y; freq_col, phase_col, Îº)  # å…¨å±€åƒæ•¸
Grid: G(x, y, h) = R(x, h) Ã— C(y)
```

#### å¯å­¸ç¿’åƒæ•¸

| åƒæ•¸ | Shape | åˆå§‹åŒ– | èªªæ˜ |
|-----|-------|--------|------|
| `row_phase` | (1, max_H) | Uniform(-Ï€, Ï€) | æ¯è¡Œçš„ç›¸ä½ |
| `col_freq` | (1,) | 0 | åˆ—æ–¹å‘é »ç‡ |
| `col_phase` | (1,) | 0 | åˆ—æ–¹å‘ç›¸ä½ |
| `kappa` | (1,) | 0 | å°–éŠ³åº¦ï¼ˆç¶“ softplusï¼‰ |

### 5.4 Gate æ©Ÿåˆ¶

**ç›®çš„**ï¼šç¢ºä¿è¨“ç·´åˆæœŸ SEGM ä¸å½±éŸ¿ DINO åŸå§‹è¼¸å‡º

```
output = input + gate Ã— delta
```

**gate åˆå§‹åŒ–**ï¼š

| æ–¹å¼ | åˆå§‹å€¼ | åˆå§‹æ•ˆæœ |
|-----|-------|---------|
| ç›´æ¥ç”¨ Î± | 0 | output = input |
| sigmoid(Î±) | 0 â†’ 0.5 | output = input + 0.5 Ã— deltaï¼ˆä¸å¥½ï¼‰ |

**å»ºè­°**ï¼šç›´æ¥ä½¿ç”¨ `gate = nn.Parameter(torch.zeros(1))`ï¼Œä¸ç¶“é sigmoidã€‚

### 5.5 è™•ç†ä¸å®Œç¾é€±æœŸæ€§çš„ç­–ç•¥

**å•é¡ŒèƒŒæ™¯**ï¼šæ ¹æ“šå¯¦éš› Ground Truth è§€å¯Ÿï¼ŒStomata çš„é€±æœŸæ€§ä¸¦éå®Œç¾è¦å¾‹ï¼š

```
å¯¦éš›è§€å¯Ÿï¼ˆGround Truth åˆ†æï¼‰ï¼š

Row 0: â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘   â† é€±æœŸç´„ 4-5ï¼Œä½†æœ‰ jitter
Row 1: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   â† ç„¡ stomataï¼ˆç©ºè¡Œï¼‰
Row 2: â–‘â–ˆâ–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–‘   â† é€±æœŸç´„ 3-4ï¼Œèˆ‡ Row 0 ä¸åŒ
Row 3: â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   â† ç„¡ stomataï¼ˆç©ºè¡Œï¼‰
Row 4: â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–‘â–‘â–ˆâ–‘â–‘â–‘â–ˆâ–‘â–‘   â† é€±æœŸç´„ 4ï¼Œå¶çˆ¾ç¼ºå¤±

ç‰¹æ€§ç¸½çµï¼š
â”œâ”€â”€ æ°´å¹³æ–¹å‘ï¼šé›¢æ•£åˆ†å¸ƒ [stomata â”€ é–“éš” â”€ stomata â”€ é–“éš” â”€ ...]
â”œâ”€â”€ æ¯è¡Œé »ç‡ä¸åŒï¼šæœ‰çš„è¡Œå¯†é›†ï¼Œæœ‰çš„ç¨€ç–
â”œâ”€â”€ å°é½Šä¸æ¨™æº–ï¼šåŒè¡Œå…§é–“è·æœ‰ Â±20% jitter
â”œâ”€â”€ æœ‰äº›è¡Œç„¡ stomataï¼šå‚ç›´æ–¹å‘ä¹Ÿæœ‰è¦å¾‹ï¼ˆstomata row / empty row äº¤æ›¿ï¼‰
â””â”€â”€ å¶çˆ¾ç¼ºå¤±ï¼šæŸäº›é æœŸä½ç½®æ²’æœ‰ stomata
```

**ä¸å®Œç¾é€±æœŸæ€§çš„é¡å‹**ï¼š

| é¡å‹ | èªªæ˜ | å½±éŸ¿ |
|-----|------|------|
| **Phase Jitter** | ä½ç½®åç§» Â±20% | Grid å³°å€¼å¯èƒ½åé›¢å¯¦éš›ä½ç½® |
| **Frequency Variation** | æ¯è¡Œé »ç‡ä¸åŒ | éœ€è¦ per-row é »ç‡ä¼°è¨ˆ |
| **Missing Stomata** | å¶çˆ¾ç¼ºå¤± | Grid å³°å€¼è™•å¯èƒ½æ²’æœ‰ stomata |
| **Empty Rows** | æ•´è¡Œç„¡ stomata | è©²è¡Œçš„ Grid æ‡‰è©²å…¨æš— |

**æä¾›å››ç¨®ç­–ç•¥ï¼ˆA, B, C, Dï¼‰ï¼Œå»ºè­°çµ„åˆä½¿ç”¨**ï¼š

#### æ–¹æ¡ˆ Aï¼šå¯¬é¬†å³°å€¼ï¼ˆWide Peaksï¼‰â€” æ¨è–¦

**åŸç†**ï¼šä½¿ç”¨è¼ƒä½çš„ Îº å€¼ï¼Œè®“æ³¢å³°æ›´å¯¬ã€æ›´å®¹å¿ä½ç½®åå·®

```
Îº = 1ï¼šæ¨™æº–é¤˜å¼¦æ³¢ï¼ˆè¼ƒå¯¬ï¼‰
Îº = 5ï¼šä¸­ç­‰å°–éŠ³
Îº = 10ï¼šè¼ƒå°–éŠ³
Îº â†’ âˆï¼šè¶¨è¿‘è„ˆè¡ï¼ˆç„¡å®¹å¿åº¦ï¼‰
```

**å»ºè­°**ï¼šåˆå§‹ Îº = 1~2ï¼Œè®“æ¨¡å‹è‡ªå·±å­¸ç¿’èª¿æ•´

**å„ªé»**ï¼š
- å¯¦ä½œç°¡å–®
- å®¹å¿ Â±20-30% çš„ä½ç½®åå·®
- å¯å­¸ç¿’æœ€ä½³å¯¬åº¦

**ç¼ºé»**ï¼š
- å¯èƒ½ç´å…¥éå¤š noise

#### æ–¹æ¡ˆ Bï¼šé »ç‡å¸¶é€šï¼ˆFrequency Band-passï¼‰â€” Phase-Invariant

**åŸç†**ï¼šä¸è¦æ±‚ç²¾ç¢ºä½ç½®å°é½Šï¼Œåªè¦æ±‚ã€Œè©²é »ç‡æˆåˆ†å­˜åœ¨ã€

```
ä¸ç”¨ Grid ç›´æ¥ maskï¼Œæ”¹ç”¨é »åŸŸæ“ä½œï¼š

1. å°ç‰¹å¾µåš row-wise FFT
2. åªä¿ç•™ä¼°è¨ˆé »ç‡ Â± Î”f ç¯„åœçš„æˆåˆ†
3. é€† FFT å›ç©ºé–“åŸŸ
```

**æ•¸å­¸è¡¨é”**ï¼š

$$
\hat{X}[f] = \begin{cases} X[f] \cdot w(f) & \text{if } |f - f_{\text{estimated}}| < \Delta f \\ X[f] \cdot \epsilon & \text{otherwise} \end{cases}
$$

å…¶ä¸­ $w(f)$ æ˜¯å¹³æ»‘æ¬Šé‡ï¼Œ$\epsilon$ æ˜¯å°å€¼ï¼ˆå¦‚ 0.1ï¼‰

**å„ªé»**ï¼š
- å®Œå…¨ä¸å— phase å½±éŸ¿
- æ•¸å­¸ä¸Šæ›´ principled

**ç¼ºé»**ï¼š
- å¤±å»ç©ºé–“ä½ç½®ä¿¡æ¯
- å¯èƒ½éåº¦å¹³æ»‘

#### æ–¹æ¡ˆ Cï¼šçµ±è¨ˆå…ˆé©—ï¼ˆStatistical/Probabilistic Priorï¼‰â€” æ¨è–¦

**åŸç†**ï¼šä¸åš hard modulationï¼Œè€Œæ˜¯ç”¨çµ±è¨ˆé‡ä¾†æ­£å‰‡åŒ–

```
1. è¨ˆç®—æ¯è¡Œçš„é »ç‡åˆ†å¸ƒ p(f)
2. è¨ˆç®—é€±æœŸæ€§ã€Œå¼·åº¦ã€: strength = max(p) / mean(p)
3. åªåœ¨ strength > threshold æ™‚å¼·åŒ–è©²é »ç‡
```

**å¯¦ä½œæ€è·¯**ï¼š

```python
# è¨ˆç®— periodicity scoreï¼ˆä¸ä¾è³´ç²¾ç¢º phaseï¼‰
fft_power = torch.abs(torch.fft.rfft(features, dim=-1))
peak_power = fft_power.max(dim=-1)
mean_power = fft_power.mean(dim=-1)
periodicity_score = peak_power / (mean_power + eps)

# åªåœ¨é€±æœŸæ€§æ˜é¡¯æ™‚æ‰æ–½åŠ èª¿è®Š
weight = sigmoid((periodicity_score - threshold) * temperature)
output = input * (1 + gate * weight * delta)
```

**å„ªé»**ï¼š
- æ›´ç©©å¥
- è‡ªå‹•è™•ç†ã€Œç„¡é€±æœŸæ€§ã€çš„è¡Œ

**ç¼ºé»**ï¼š
- éœ€è¦é¡å¤–çš„ threshold tuning

#### æ–¹æ¡ˆ Dï¼šç‰¹å¾µå¼•å°ç´°åŒ–ï¼ˆFeature-Guided Refinementï¼‰

**åŸç†**ï¼šç”¨ Grid çš„åˆæ­¥ä¼°è¨ˆä¾†æ‰¾ candidate ä½ç½®ï¼Œå†ç”¨ç‰¹å¾µç›¸ä¼¼åº¦ç´°åŒ–

```
1. ç”Ÿæˆåˆæ­¥ Gridï¼ˆå¯¬å³°ï¼‰
2. åœ¨ Grid å³°å€¼é™„è¿‘æœç´¢ï¼ˆÂ±2 pixelsï¼‰
3. é¸æ“‡ç‰¹å¾µæœ€ä¸€è‡´çš„ä½ç½®
```

**å„ªé»**ï¼š
- çµåˆé »ç‡å…ˆé©—å’Œç‰¹å¾µä¿¡æ¯

**ç¼ºé»**ï¼š
- è¨ˆç®—è¼ƒè¤‡é›œ
- è‹¥ç‰¹å¾µæœ¬èº«æœ‰ noiseï¼Œå¯èƒ½å¤±æ•ˆ

### 5.6 æ¨è–¦æ–¹æ¡ˆï¼šA + C + Soft Modulation

**çµ„åˆç­–ç•¥**ï¼š

1. **å¯¬å³°ï¼ˆAï¼‰**ï¼šÎº = 1~2ï¼Œå®¹å¿ä½ç½®åå·®
2. **çµ±è¨ˆå…ˆé©—ï¼ˆCï¼‰**ï¼šåªåœ¨é€±æœŸæ€§æ˜é¡¯æ™‚èª¿è®Š
3. **Soft Modulation**ï¼šä¸åš hard maskingï¼Œç”¨åŠ æ¬Šèª¿è®Š

**Soft Modulation å¯¦ä½œ**ï¼š

```python
# å–ä»£ hard modulation
# åŸæœ¬: output = input + gate * delta

# Soft attention modulation
attention_weight = sigmoid(grid * temperature)  # temperature æ§åˆ¶å°–éŠ³åº¦
output = input * (1 + gate * attention_weight * scale)

# æˆ–è€…åŠ æ€§ç‰ˆæœ¬
output = input + gate * attention_weight * delta
```

**åƒæ•¸å»ºè­°**ï¼š

| åƒæ•¸ | å»ºè­°å€¼ | èªªæ˜ |
|-----|-------|------|
| Îº (kappa) | 1.0 ~ 2.0 | åˆå§‹å¯¬å³° |
| temperature | 5.0 ~ 10.0 | Soft modulation å°–éŠ³åº¦ |
| periodicity_threshold | 2.0 | é€±æœŸæ€§å¼·åº¦é–¾å€¼ |
| Î”f (é »ç‡å®¹å¿) | Â±10% | è‹¥ä½¿ç”¨æ–¹æ¡ˆ B |

---

## 6. æå¤±å‡½æ•¸è¨­è¨ˆ

### 6.1 æ ¸å¿ƒæŒ‘æˆ°ï¼šDINO ç„¡æ³•æª¢æ¸¬ Stomata

**é‡è¦ç™¼ç¾**ï¼šç¶“éå¯¦éš›æ¸¬è©¦ï¼ŒDINO **å¹¾ä¹ç„¡æ³•æª¢æ¸¬ stomata**ã€‚

**åŸå› åˆ†æ**ï¼š

| å•é¡Œ | èªªæ˜ |
|-----|------|
| èƒŒæ™¯ noise èˆ‡ stomata å¤–è§€ç›¸ä¼¼ | åå…‰ã€ç´°èƒå£ç­‰èˆ‡ stomata åœ¨ç‰¹å¾µç©ºé–“ä¸­ç›¸ä¼¼ |
| Flash Attention ç„¡æ³•æå– weights | ç„¡æ³•ç”¨ attention heatmap ä½œç‚ºç›£ç£ |
| ç‰¹å¾µç›¸ä¼¼åº¦ä¸å¯é  | CLS-patch similarity ç„¡æ³•å€åˆ† stomata å’Œ noise |

**çµè«–**ï¼šä¸èƒ½ä¾è³´ DINO çš„ç‰¹å¾µä¾†å®šä½ stomataã€‚å¿…é ˆ**ç´”ç²¹ä¾è³´é€±æœŸæ€§å…ˆé©—**ã€‚

**è¨­è¨ˆåŸå‰‡**ï¼š
- Stomata æ˜¯é€±æœŸæ€§æ’åˆ—çš„
- Noise æ˜¯éš¨æ©Ÿåˆ†å¸ƒçš„
- åˆ©ç”¨é€™å€‹å€åˆ¥ä¾†éæ¿¾ noise

### 6.2 æå¤±å‡½æ•¸åˆ—è¡¨ï¼ˆä¿®æ­£ç‰ˆï¼‰

| Loss | ç›®çš„ | æ¬Šé‡ | èªªæ˜ |
|-----|------|------|------|
| **L_intra** | Grid å³°å€¼ä½ç½®çš„ç‰¹å¾µä¸€è‡´æ€§ | 1.0 | åŒé¡ç‰©é«”ç‰¹å¾µæ‡‰ç›¸ä¼¼ |
| **L_inter** | å³°å€¼ vs è°·å€¼çš„ç‰¹å¾µå€åˆ†åº¦ | 1.0 | å‰æ™¯/èƒŒæ™¯æ‡‰ä¸åŒ |
| **L_period** | Grid æ‡‰ä¿æŒé€±æœŸæ€§ | 0.5 | é˜²æ­¢é€€åŒ– |
| **L_freq_smooth** | ç›¸é„°è¡Œé »ç‡é€£çºŒæ€§ | 0.5 | ç©ºé–“å¹³æ»‘ |
| **L_sparse** | Grid ç¨€ç–æ€§ | 0.1 | é˜²æ­¢å…¨äº® |

### 6.3 å„é …æå¤±è©³è§£

#### L_intra: Intra-Peak Consistency Lossï¼ˆæ ¸å¿ƒï¼‰

**ç›®çš„**ï¼šGrid å³°å€¼ä½ç½®çš„ç‰¹å¾µæ‡‰è©²å½¼æ­¤ç›¸ä¼¼ï¼ˆå› ç‚ºéƒ½æ˜¯ stomataï¼‰

**ç›´è¦º**ï¼šå¦‚æœ Grid æ­£ç¢ºæ¨™è¨˜äº† stomata ä½ç½®ï¼Œé€™äº›ä½ç½®çš„ç‰¹å¾µæ‡‰è©²æ˜¯ä¸€è‡´çš„

**â­ ç¾¤é«”ä¸€è‡´æ€§åŸç†**ï¼š

```
é—œéµæ´å¯Ÿï¼šL_intra åˆ©ç”¨çš„æ˜¯ã€Œç¾¤é«”ä¸€è‡´æ€§ã€è€Œéã€Œå€‹é«”å€åˆ†åº¦ã€

å³ä½¿å–®å€‹ stomata ç‰¹å¾µ â‰ˆ å–®å€‹ noise ç‰¹å¾µï¼ˆé›£ä»¥å€åˆ†ï¼‰
ä½†æ˜¯ï¼š
  - Stomata ç¾¤é«” = {stomata_1, stomata_2, ...} â†’ éƒ½æ˜¯åŒé¡ç‰©é«” â†’ å½¼æ­¤ç›¸ä¼¼
  - Noise ç¾¤é«” = {åå…‰, è‘‰è„ˆ, ç´°èƒå£, ...} â†’ ä¸åŒé¡ç‰©é«” â†’ å½¼æ­¤ä¸ç›¸ä¼¼

å› æ­¤ï¼š
  - Grid å°åˆ° stomata â†’ å³°å€¼ç‰¹å¾µç¾¤é«”ä¸€è‡´æ€§é«˜ â†’ L_intra ä½ âœ“
  - Grid å°åˆ° noise â†’ å³°å€¼ç‰¹å¾µç¾¤é«”ä¸€è‡´æ€§ä½ â†’ L_intra é«˜ âœ—
```

**è¨ˆç®—æ–¹å¼**ï¼š

```python
# 1. æ‰¾å‡º Grid å³°å€¼ä½ç½®ï¼ˆtop-k æˆ– thresholdï¼‰
peak_mask = (grid > threshold)  # (B, H, W)

# 2. æå–å³°å€¼ä½ç½®çš„ç‰¹å¾µ
peak_features = features[peak_mask]  # (N_peaks, C)

# 3. è¨ˆç®—å³°å€¼ç‰¹å¾µä¹‹é–“çš„ç›¸ä¼¼åº¦çŸ©é™£
sim_matrix = cosine_similarity(peak_features, peak_features)  # (N_peaks, N_peaks)

# 4. æœ€å¤§åŒ–å¹³å‡ç›¸ä¼¼åº¦ï¼ˆæ’é™¤å°è§’ç·šï¼‰
mask = ~torch.eye(N_peaks, dtype=bool)
L_intra = -sim_matrix[mask].mean()
```

$$
\mathcal{L}_{\text{intra}} = -\frac{1}{N(N-1)} \sum_{i \neq j} \cos(\mathbf{f}_i^{\text{peak}}, \mathbf{f}_j^{\text{peak}})
$$

**æ³¨æ„**ï¼šé€™å€‹ loss ä¸ä¾è³´ DINO èƒ½å¦æª¢æ¸¬ stomataï¼Œåªè¦æ±‚ã€Œè¢«é¸ä¸­çš„ä½ç½®ç‰¹å¾µä¸€è‡´ã€

**âš ï¸ å‰ææ¢ä»¶é©—è­‰**ï¼š

```python
# è¨“ç·´å‰å»ºè­°åŸ·è¡Œæ­¤é©—è­‰ï¼Œç¢ºèªå‡è¨­æˆç«‹
def verify_group_consistency(dino_model, image, stomata_positions, noise_positions):
    """
    é©—è­‰ stomata ç¾¤é«”ä¸€è‡´æ€§ > noise ç¾¤é«”ä¸€è‡´æ€§

    Args:
        stomata_positions: äººå·¥æ¨™è¨˜çš„å¹¾å€‹ stomata ä½ç½® [(x1,y1), (x2,y2), ...]
        noise_positions: äººå·¥æ¨™è¨˜çš„å¹¾å€‹ noise ä½ç½®ï¼ˆåå…‰ã€è‘‰è„ˆã€ç´°èƒå£ç­‰ï¼‰
    """
    with torch.no_grad():
        features = dino_model(image)['x_norm_patchtokens']  # (1, 196, 768)
        features = features.view(1, 14, 14, 768)

        # è½‰æ›åº§æ¨™åˆ° feature map ç©ºé–“
        stomata_feats = [features[0, y//16, x//16, :] for (x, y) in stomata_positions]
        noise_feats = [features[0, y//16, x//16, :] for (x, y) in noise_positions]

        stomata_feats = torch.stack(stomata_feats)  # (N_stomata, 768)
        noise_feats = torch.stack(noise_feats)      # (N_noise, 768)

        # è¨ˆç®—ç¾¤é«”å…§çš„ pairwise similarity
        stomata_sim = F.cosine_similarity(
            stomata_feats.unsqueeze(1),
            stomata_feats.unsqueeze(0),
            dim=-1
        )
        noise_sim = F.cosine_similarity(
            noise_feats.unsqueeze(1),
            noise_feats.unsqueeze(0),
            dim=-1
        )

        # æ’é™¤å°è§’ç·šå¾Œè¨ˆç®—å¹³å‡
        n_s = len(stomata_positions)
        n_n = len(noise_positions)
        stomata_consistency = (stomata_sim.sum() - n_s) / (n_s * (n_s - 1))
        noise_consistency = (noise_sim.sum() - n_n) / (n_n * (n_n - 1))

        print(f"Stomata group consistency: {stomata_consistency:.4f}")
        print(f"Noise group consistency: {noise_consistency:.4f}")
        print(f"Ratio: {stomata_consistency / noise_consistency:.2f}x")

        if stomata_consistency > noise_consistency:
            print("âœ“ å‡è¨­æˆç«‹ï¼šL_intra é æœŸæœ‰æ•ˆ")
        else:
            print("âœ— å‡è¨­ä¸æˆç«‹ï¼šéœ€è¦é‡æ–°è©•ä¼°è¨­è¨ˆ")

        return stomata_consistency, noise_consistency
```

#### L_inter: Inter-Region Contrast Lossï¼ˆæ ¸å¿ƒï¼‰

**ç›®çš„**ï¼šå³°å€¼å€åŸŸå’Œè°·å€¼å€åŸŸçš„ç‰¹å¾µæ‡‰è©²ä¸åŒ

**ç›´è¦º**ï¼šå¦‚æœå³°å€¼æ˜¯ stomataï¼Œè°·å€¼æ˜¯èƒŒæ™¯ï¼Œå®ƒå€‘çš„ç‰¹å¾µæ‡‰è©²æœ‰å€åˆ¥

**è¨ˆç®—æ–¹å¼**ï¼š

```python
# 1. è¨ˆç®—å³°å€¼å€åŸŸçš„å¹³å‡ç‰¹å¾µ
peak_features = (features * grid.unsqueeze(-1)).sum(dim=[1,2]) / grid.sum(dim=[1,2], keepdim=True)

# 2. è¨ˆç®—è°·å€¼å€åŸŸçš„å¹³å‡ç‰¹å¾µ
valley_mask = 1 - grid
valley_features = (features * valley_mask.unsqueeze(-1)).sum(dim=[1,2]) / valley_mask.sum(dim=[1,2], keepdim=True)

# 3. æœ€å°åŒ–å…©è€…çš„ç›¸ä¼¼åº¦ï¼ˆ= æœ€å¤§åŒ–å€åˆ†åº¦ï¼‰
L_inter = cosine_similarity(peak_features, valley_features).mean()
```

$$
\mathcal{L}_{\text{inter}} = \cos\left( \frac{\sum G \cdot \mathbf{x}}{\sum G}, \frac{\sum (1-G) \cdot \mathbf{x}}{\sum (1-G)} \right)
$$

**èˆ‡åŸ L_contrast çš„å·®ç•°**ï¼šæ¦‚å¿µç›¸åŒï¼Œä½†å¼·èª¿é€™æ˜¯**æ ¸å¿ƒ loss**ï¼Œä¸ä¾è³´ DINO çš„æª¢æ¸¬èƒ½åŠ›

#### L_period: Periodicity Loss

**ç›®çš„**ï¼šç¢ºä¿ Grid æœ¬èº«ä¿æŒé€±æœŸæ€§çµæ§‹

**è¨ˆç®—æ–¹å¼**ï¼š

```python
# 1. å° Grid æ¯è¡Œåš FFT
grid_fft = torch.fft.rfft(grid, dim=-1)
grid_power = torch.abs(grid_fft) ** 2

# 2. æ‰¾å‡º Grid çš„ä¸»é »ç‡
grid_dominant_freq = grid_power[:, :, 1:].argmax(dim=-1) + 1

# 3. èˆ‡ä¼°è¨ˆçš„é »ç‡æ¯”è¼ƒ
L_period = F.l1_loss(grid_dominant_freq.float(), estimated_freq)
```

$$
\mathcal{L}_{\text{period}} = \frac{1}{BH} \sum_{b,h} |f_h^{\text{grid}} - f_h^{\text{estimated}}|
$$

**ç›®çš„**ï¼šé˜²æ­¢ Grid é€€åŒ–ç‚ºä»»æ„ pattern

#### L_freq_smooth: Frequency Smoothness Loss

**ç›®çš„**ï¼šç›¸é„°è¡Œçš„é »ç‡æ‡‰è©²ç›¸ä¼¼ï¼ˆç©ºé–“é€£çºŒæ€§ï¼‰

$$
\mathcal{L}_{\text{freq\_smooth}} = \frac{1}{B(H-1)} \sum_{b,h} |f_h - f_{h+1}|
$$

**ç›´è¦º**ï¼šæ¤ç‰©çµ„ç¹”çš„çµæ§‹æ˜¯é€£çºŒçš„ï¼Œç›¸é„°è¡Œä¸æœƒæœ‰åŠ‡çƒˆçš„é »ç‡è®ŠåŒ–

#### L_sparse: Sparsity Loss

**ç›®çš„**ï¼šGrid æ‡‰è©²æ˜¯ç¨€ç–çš„ï¼ˆå¤§éƒ¨åˆ†å€åŸŸç‚ºæš—ï¼‰

$$
\mathcal{L}_{\text{sparse}} = \text{mean}(G)
$$

**ç›´è¦º**ï¼šStomata åªä½”åœ–åƒçš„ä¸€å°éƒ¨åˆ†ï¼ŒGrid ä¸æ‡‰è©²å…¨äº®

**è®Šé«”**ï¼ˆæ›´å¼·çš„ç¨€ç–ç´„æŸï¼‰ï¼š

$$
\mathcal{L}_{\text{sparse}} = \max(0, \text{mean}(G) - \tau)
$$

å…¶ä¸­ $\tau$ æ˜¯ç›®æ¨™ç¨€ç–åº¦ï¼ˆå¦‚ 0.1 = 10% è¦†è“‹ç‡ï¼‰

### 6.4 ç‚ºä»€éº¼é€™äº› Loss æœ‰æ•ˆï¼Ÿ

**é—œéµæ´å¯Ÿ**ï¼šå³ä½¿ DINO ç„¡æ³•ç›´æ¥æª¢æ¸¬ stomataï¼Œä½†ï¼š

1. **Stomata çš„ç‰¹å¾µæ˜¯ä¸€è‡´çš„**ï¼šåŒä¸€å¼µåœ–çš„ stomata é•·å¾—å¾ˆåƒ
2. **Stomata èˆ‡èƒŒæ™¯ä¸åŒ**ï¼šé›–ç„¶ noise å¯èƒ½å’Œ stomata ç›¸ä¼¼ï¼Œä½†å¹³å‡ä¾†çœ‹èƒŒæ™¯é‚„æ˜¯ä¸åŒçš„
3. **Stomata æ˜¯é€±æœŸæ€§çš„**ï¼šé€™æ˜¯æœ€å¼·çš„å…ˆé©—

**å·¥ä½œæ©Ÿåˆ¶**ï¼š

```
åˆå§‹ç‹€æ…‹ï¼š
  - Grid æ˜¯æ ¹æ“š FFT é »ç‡ç”Ÿæˆçš„é€±æœŸæ€§ pattern
  - é€™å€‹ pattern å¯èƒ½å°ä¹Ÿå¯èƒ½ä¸å°

è¨“ç·´éç¨‹ï¼š
  - L_intra æ¨å‹•ï¼šè¢«é¸ä¸­çš„ä½ç½®ç‰¹å¾µè¦ä¸€è‡´
    â†’ å¦‚æœé¸éŒ¯äº†ï¼ˆé¸åˆ° noiseï¼‰ï¼Œç‰¹å¾µä¸ä¸€è‡´ï¼Œloss é«˜
    â†’ å¦‚æœé¸å°äº†ï¼ˆé¸åˆ° stomataï¼‰ï¼Œç‰¹å¾µä¸€è‡´ï¼Œloss ä½

  - L_inter æ¨å‹•ï¼šå³°å€¼å’Œè°·å€¼ç‰¹å¾µè¦ä¸åŒ
    â†’ é˜²æ­¢ Grid é€€åŒ–ç‚ºå…¨äº®æˆ–å…¨æš—

  - L_period æ¨å‹•ï¼šGrid å¿…é ˆä¿æŒé€±æœŸæ€§
    â†’ é˜²æ­¢ Grid ä»»æ„è®Šå½¢å»ã€Œä½œå¼Šã€

æ”¶æ–‚çµæœï¼š
  - Grid æœƒæ”¶æ–‚åˆ°èƒ½æœ€å¤§åŒ–ç‰¹å¾µä¸€è‡´æ€§çš„é€±æœŸæ€§ pattern
  - é€™å€‹ pattern å°±å°æ‡‰åˆ° stomata çš„ä½ç½®
```

### 6.5 ç¸½æå¤±

$$
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{intra}} + \mathcal{L}_{\text{inter}} + 0.5 \mathcal{L}_{\text{period}} + 0.5 \mathcal{L}_{\text{freq\_smooth}} + 0.1 \mathcal{L}_{\text{sparse}}
$$

### 6.6 Loss æ¬Šé‡èª¿æ•´å»ºè­°

| æƒ…æ³ | èª¿æ•´ |
|-----|------|
| Grid å…¨äº® | å¢åŠ  L_sparse æ¬Šé‡ |
| Grid ä¸åƒé€±æœŸæ€§ | å¢åŠ  L_period æ¬Šé‡ |
| ç‰¹å¾µå€åˆ†åº¦ä½ | å¢åŠ  L_inter æ¬Šé‡ |
| é »ç‡è·³å‹•å¤ªå¤§ | å¢åŠ  L_freq_smooth æ¬Šé‡ |

### 6.7 èˆ‡åŸè¨­è¨ˆçš„å·®ç•°ç¸½çµ

| é …ç›® | åŸè¨­è¨ˆ | ä¿®æ­£å¾Œ |
|-----|-------|--------|
| ä¾è³´ DINO æª¢æ¸¬èƒ½åŠ› | æ˜¯ï¼ˆL_alignï¼‰ | **å¦** |
| æ ¸å¿ƒç›£ç£ä¿¡è™Ÿ | Feature Similarity Map | **ç‰¹å¾µä¸€è‡´æ€§ + é€±æœŸæ€§å…ˆé©—** |
| L_align | CLS-patch ç›¸ä¼¼åº¦ | **ç§»é™¤**ï¼ˆDINO ç„¡æ³•æª¢æ¸¬ï¼‰ |
| L_contrast | è¼”åŠ© loss | **å‡ç´šç‚ºæ ¸å¿ƒ L_inter** |
| æ–°å¢ | - | **L_intra**ï¼ˆæœ€é‡è¦ï¼‰ |

---

## 7. è¨“ç·´é…ç½®

### 7.1 æ¨¡å‹è¨­å®š

| é …ç›® | å€¼ | èªªæ˜ |
|-----|---|------|
| Backbone | ViT-Base | DINOv3 é è¨“ç·´ |
| patch_size | 16 | |
| embed_dim | 768 | |
| SEGM æ’å…¥é» | Block 10 ä¹‹å¾Œ | è®“ Block 11, 12 å—ç›Š |

### 7.2 è¨“ç·´åƒæ•¸

| åƒæ•¸ | å»ºè­°å€¼ | èªªæ˜ |
|-----|-------|------|
| learning_rate | 1e-4 | åªè¨“ç·´ SEGM |
| optimizer | AdamW | |
| weight_decay | 0.01 | |
| batch_size | 16-32 | æ ¹æ“š GPU |
| warmup_epochs | 5 | è®“ gate æ…¢æ…¢æ‰“é–‹ |
| num_epochs | 50-100 | è‡ªç›£ç£éœ€è¦è¼ƒå¤š epochs |

### 7.3 å‡çµç­–ç•¥

```python
# å‡çµ DINO backbone
for name, param in model.named_parameters():
    if 'segm' not in name:
        param.requires_grad = False
```

### 7.4 æ¬Šé‡è¼‰å…¥

```python
# è¼‰å…¥ DINO é è¨“ç·´æ¬Šé‡ï¼Œå¿½ç•¥ SEGM åƒæ•¸
checkpoint = torch.load('dinov3_vitb16.pth')
model.load_state_dict(checkpoint, strict=False)
```

---

## 8. å¯¦ä½œæª¢æŸ¥æ¸…å–®

### 8.1 ç¨‹å¼ç¢¼çµæ§‹é©—è­‰

- [ ] ç¢ºèª `dinov3-main` åœ¨ Python path ä¸­
- [ ] ç¢ºèªå¯ä»¥ import `DinoVisionTransformer`
- [ ] ç¢ºèª `n_storage_tokens` å±¬æ€§å­˜åœ¨

### 8.2 Tensor Shape é©—è­‰

| æª¢æŸ¥é» | é æœŸ Shape |
|-------|-----------|
| åŸå§‹ x_list | `List[Tensor(B, N, C)]` |
| rope | `List[(H, W)]` |
| åˆ†é›¢å¾Œ patch_tokens | `(B, HÃ—W, C)` |
| Reshape å¾Œ | `(B, H, W, C)` |
| FFT å¾Œ | `(B, H, hidden_dim, W//2+1)` [complex] |
| dominant_freq | `(B, H)` |
| Grid | `(B, 1, H, W)` |
| enhanced_tokens | `(B, HÃ—W, C)` |

### 8.3 åˆå§‹åŒ–é©—è­‰

- [ ] `gate` åˆå§‹åŒ–ç‚º 0
- [ ] `row_phase` éš¨æ©Ÿåˆå§‹åŒ–
- [ ] `kappa` åˆå§‹åŒ–è®“æ³¢å½¢è¼ƒå¹³ç·©

### 8.4 åŠŸèƒ½é©—è­‰

- [ ] ç¬¬ä¸€å€‹ epochï¼Œè¼¸å‡ºæ‡‰æ¥è¿‘åŸå§‹ DINOï¼ˆå›  gate=0ï¼‰
- [ ] Grid è¦–è¦ºåŒ–é¡¯ç¤ºé€±æœŸæ€§çµæ§‹
- [ ] é »ç‡ä¼°è¨ˆå€¼åœ¨åˆç†ç¯„åœ

### 8.5 æ¢¯åº¦æµé©—è­‰

```python
# ç¢ºèªæ¢¯åº¦åªæµå‘ SEGM åƒæ•¸
loss.backward()
for name, param in model.named_parameters():
    if param.grad is not None:
        assert 'segm' in name, f"æ¢¯åº¦æ´©æ¼åˆ°: {name}"
```

---

## é™„éŒ„ Aï¼šDINOv3 é—œéµç¨‹å¼ç¢¼åƒè€ƒ

### A.1 forward_features_list (éœ€è¦è¦†å¯«)

**ä½ç½®**ï¼š`vision_transformer.py:222-261`

```python
def forward_features_list(self, x_list, masks_list):
    x = []
    rope = []
    for t_x, t_masks in zip(x_list, masks_list):
        t2_x, hw_tuple = self.prepare_tokens_with_masks(t_x, t_masks)
        x.append(t2_x)
        rope.append(hw_tuple)

    # â˜… é€™è£¡æ˜¯é—œéµä¿®æ”¹é» â˜…
    for _, blk in enumerate(self.blocks):
        if self.rope_embed is not None:
            rope_sincos = [self.rope_embed(H=H, W=W) for H, W in rope]
        else:
            rope_sincos = [None for r in rope]
        x = blk(x, rope_sincos)

    # å¾ŒçºŒ norm å’Œè¼¸å‡ºè™•ç†...
```

### A.2 Token çµæ§‹

```
æ¯å€‹ tensor çš„çµæ§‹ï¼ˆN = 1 + n_storage + HÃ—Wï¼‰ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLS â”‚ storage_0 â”‚ ... â”‚ storage_n â”‚ patch_0 â”‚ ... â”‚ patch_HW â”‚
â”‚  1  â”‚â†â”€â”€â”€â”€â”€â”€ n_storage â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚â†â”€â”€â”€â”€â”€â”€ HÃ—W â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

åˆ†é›¢æ–¹å¼ï¼š
prefix_len = 1 + self.n_storage_tokens
prefix_tokens = x[:, :prefix_len, :]
patch_tokens = x[:, prefix_len:, :]
```

### A.3 Block è¼¸å…¥è¼¸å‡º

**ä½ç½®**ï¼š`block.py:200-212`

```python
def forward(self, x_or_x_list, rope_or_rope_list=None):
    if isinstance(x_or_x_list, Tensor):
        return self._forward_list([x_or_x_list], [rope_or_rope_list])[0]
    elif isinstance(x_or_x_list, list):
        return self._forward_list(x_or_x_list, rope_list=rope_or_rope_list)
```

---

## é™„éŒ„ Bï¼šèˆ‡åŸ SPEC çš„å·®ç•°

### B.1 DINOv3 æ•´åˆç›¸é—œ

| è¨­è¨ˆé» | åŸ SPEC | ä¿®æ­£å¾Œ |
|-------|---------|--------|
| Tensor æ ¼å¼ | `(B, C, H, W)` | **`List[(B, N, C)]`** |
| ç©ºé–“ç¶­åº¦ä¾†æº | å¾ tensor shape æ¨æ–· | **å¾ rope tuple å–å¾—** |
| Block è¿´åœˆ | å‡è¨­æœ‰ index | **éœ€è¦è‡ªå·±åŠ  enumerate** |
| é »ç‡é æ¸¬ | MLP | **FFT per-row** |
| æ•´åˆæ–¹å¼ | Hook | **ç¹¼æ‰¿ + è¦†å¯«** |

### B.2 ç›£ç£ä¿¡è™Ÿèˆ‡æå¤±å‡½æ•¸

| è¨­è¨ˆé» | åŸ SPEC | ä¿®æ­£å¾Œ |
|-------|---------|--------|
| DINO æª¢æ¸¬èƒ½åŠ›å‡è¨­ | éƒ¨åˆ†å¯ç”¨ | **å¹¾ä¹ç„¡æ³•æª¢æ¸¬ stomata** |
| ç›£ç£ä¿¡è™Ÿ | CLS-patch similarity | **ç´”ç²¹ä¾è³´é€±æœŸæ€§å…ˆé©—** |
| L_align | æ ¸å¿ƒ loss | **ç§»é™¤**ï¼ˆç„¡æ•ˆï¼‰ |
| L_contrast | è¼”åŠ© loss (0.3) | **å‡ç´šç‚º L_inter (1.0)** |
| æ–°å¢ L_intra | - | **æ ¸å¿ƒ lossï¼Œå³°å€¼ç‰¹å¾µä¸€è‡´æ€§** |
| L_freq | é »ç‡é€£çºŒæ€§ | **æ”¹åç‚º L_freq_smooth** |

### B.3 é€±æœŸæ€§è™•ç†

| è¨­è¨ˆé» | åŸ SPEC | ä¿®æ­£å¾Œ |
|-------|---------|--------|
| é€±æœŸå‡è¨­ | å®Œç¾é€±æœŸ | **ä¸å®Œç¾ï¼Œéœ€è¦å®¹å¿** |
| Îº (kappa) | æœªæ˜ç¢º | **å»ºè­° 1~2ï¼ˆå¯¬å³°ï¼‰** |
| Modulation æ–¹å¼ | Hard: `input + gate Ã— delta` | **Soft: åŠ æ¬Šèª¿è®Š** |
| é€±æœŸæ€§ç­–ç•¥ | å–®ä¸€ | **å››ç¨®æ–¹æ¡ˆ A/B/C/D** |

---

## é™„éŒ„ Cï¼šç¨‹å¼ç¢¼é©—è­‰ä¾†æº

> ä»¥ä¸‹æ‰€æœ‰ç™¼ç¾å‡ç¶“ç”±å¯¦éš›è®€å–ç¨‹å¼ç¢¼é©—è­‰ï¼Œé™„ä¸Šç¢ºåˆ‡æª”æ¡ˆè·¯å¾‘å’Œè¡Œè™Ÿã€‚

### C.1 Tensor æ ¼å¼é©—è­‰

| ç™¼ç¾ | æª”æ¡ˆ | è¡Œè™Ÿ | ç¨‹å¼ç¢¼ç‰‡æ®µ |
|-----|------|-----|-----------|
| x æ˜¯ List | `vision_transformer.py` | 222-228 | `x = []; for t_x, t_masks in zip(x_list, masks_list): x.append(t2_x)` |
| rope å­˜ (H, W) | `vision_transformer.py` | 227-228 | `rope.append(hw_tuple)` |
| Block æ¥å— List | `block.py` | 200-212 | `if isinstance(x_or_x_list, list): return self._forward_list(...)` |

### C.2 Token çµæ§‹é©—è­‰

| ç™¼ç¾ | æª”æ¡ˆ | è¡Œè™Ÿ | ç¨‹å¼ç¢¼ç‰‡æ®µ |
|-----|------|-----|-----------|
| CLS token | `vision_transformer.py` | 112 | `self.cls_token = nn.Parameter(torch.empty(1, 1, embed_dim))` |
| Storage tokens | `vision_transformer.py` | 113-115 | `self.n_storage_tokens = n_storage_tokens` |
| Token é †åº | `vision_transformer.py` | 211-218 | `torch.cat([cls_token.expand(...), storage_tokens.expand(...), x], dim=1)` |

### C.3 æº–å‚™ Tokens æµç¨‹

| ç™¼ç¾ | æª”æ¡ˆ | è¡Œè™Ÿ | ç¨‹å¼ç¢¼ç‰‡æ®µ |
|-----|------|-----|-----------|
| patch_embed è¼¸å‡º | `vision_transformer.py` | 191-192 | `x = self.patch_embed(x); B, H, W, _ = x.shape` |
| Flatten | `vision_transformer.py` | 193 | `x = x.flatten(1, 2)` |
| å›å‚³ H, W | `vision_transformer.py` | 220 | `return x, (H, W)` |

### C.4 Block è¿´åœˆé©—è­‰

| ç™¼ç¾ | æª”æ¡ˆ | è¡Œè™Ÿ | ç¨‹å¼ç¢¼ç‰‡æ®µ |
|-----|------|-----|-----------|
| Index è¢«ä¸Ÿæ£„ | `vision_transformer.py` | 229 | `for _, blk in enumerate(self.blocks):` |
| RoPE è™•ç† | `vision_transformer.py` | 230-233 | `rope_sincos = [self.rope_embed(H=H, W=W) for H, W in rope]` |
| Block forward | `vision_transformer.py` | 234 | `x = blk(x, rope_sincos)` |

### C.5 Attention æ©Ÿåˆ¶é©—è­‰

| ç™¼ç¾ | æª”æ¡ˆ | è¡Œè™Ÿ | ç¨‹å¼ç¢¼ç‰‡æ®µ |
|-----|------|-----|-----------|
| Flash Attention | `attention.py` | 116 | `x = torch.nn.functional.scaled_dot_product_attention(q, k, v)` |
| ç„¡æ³•å– weights | - | - | `scaled_dot_product_attention` ä¸å›å‚³ attention weights |

### C.6 è¼¸å‡ºæ ¼å¼é©—è­‰

| ç™¼ç¾ | æª”æ¡ˆ | è¡Œè™Ÿ | ç¨‹å¼ç¢¼ç‰‡æ®µ |
|-----|------|-----|-----------|
| x_norm_clstoken | `vision_transformer.py` | 254 | `"x_norm_clstoken": x_norm_cls_reg[:, 0]` |
| x_norm_patchtokens | `vision_transformer.py` | 256 | `"x_norm_patchtokens": x_norm_patch` |
| åˆ†é›¢ prefix/patch | `vision_transformer.py` | 247, 250-251 | `x_norm_patch = self.norm(x[:, self.n_storage_tokens + 1 :])` |

### C.7 ç¾æœ‰ Adapter åƒè€ƒ

| ç™¼ç¾ | æª”æ¡ˆ | è¡Œè™Ÿ | ç¨‹å¼ç¢¼ç‰‡æ®µ |
|-----|------|-----|-----------|
| çµ„åˆè¨­è¨ˆ | `dinov3_adapter.py` | 324 | `self.backbone = backbone` |
| å‡çµ backbone | `dinov3_adapter.py` | 326 | `self.backbone.requires_grad_(False)` |
| ä½¿ç”¨ get_intermediate_layers | `dinov3_adapter.py` | 424-426 | `all_layers = self.backbone.get_intermediate_layers(...)` |

### C.8 é—œéµå±¬æ€§é©—è­‰

| å±¬æ€§ | æª”æ¡ˆ | è¡Œè™Ÿ | ç¨‹å¼ç¢¼ç‰‡æ®µ |
|-----|------|-----|-----------|
| embed_dim | `vision_transformer.py` | 99 | `self.num_features = self.embed_dim = embed_dim` |
| n_blocks | `vision_transformer.py` | 100 | `self.n_blocks = depth` |
| patch_size | `vision_transformer.py` | 102 | `self.patch_size = patch_size` |
| n_storage_tokens | `vision_transformer.py` | 113 | `self.n_storage_tokens = n_storage_tokens` |
| blocks | `vision_transformer.py` | 160 | `self.blocks = nn.ModuleList(blocks_list)` |

---

## é™„éŒ„ Dï¼šå¯¦ä½œæ³¨æ„äº‹é …

### D.1 Import è·¯å¾‘è¨­å®š

ç”±æ–¼ DINOv3 ä¸æ˜¯æ¨™æº– pip å¥—ä»¶ï¼Œéœ€è¦æ‰‹å‹•è¨­å®š pathï¼š

```python
import sys
sys.path.insert(0, '/path/to/dinov3-main')

from dinov3.models.vision_transformer import DinoVisionTransformer
```

### D.2 è¦†å¯« forward_features_list çš„å®Œæ•´æ€§

è¦†å¯«æ™‚éœ€è¦**å®Œæ•´è¤‡è£½** `forward_features_list` çš„å¾ŒåŠéƒ¨åˆ†ï¼ˆnorm å’Œè¼¸å‡ºè™•ç†ï¼‰ï¼Œå› ç‚ºï¼š

1. ç„¡æ³•åªè¦†å¯« Block è¿´åœˆéƒ¨åˆ†
2. éœ€è¦ä¿æŒè¼¸å‡º dict æ ¼å¼ä¸€è‡´

å»ºè­°è¤‡è£½ç¯„åœï¼š`vision_transformer.py:222-261`ï¼ˆç´„ 40 è¡Œï¼‰

### D.3 Multi-crop æ”¯æ´

DINOv3 çš„ `forward_features_list` è¨­è¨ˆæ˜¯ç‚ºäº†æ”¯æ´ multi-crop è¨“ç·´ï¼š
- `x_list` å¯èƒ½åŒ…å«å¤šå€‹ä¸åŒè§£æåº¦çš„ crop
- æ¯å€‹ crop æœ‰ä¸åŒçš„ `(H, W)`

SEGM è¨­è¨ˆå·²è€ƒæ…®é€™é»ï¼Œæ¯å€‹ crop ç¨ç«‹è™•ç†ã€‚

### D.4 Gradient Checkpointing

è‹¥éœ€è¦ç¯€çœè¨˜æ†¶é«”ï¼Œå¯ä»¥å° SEGM æ¨¡çµ„ä½¿ç”¨ gradient checkpointingï¼š

```python
from torch.utils.checkpoint import checkpoint

# åœ¨ _apply_segm ä¸­
enhanced_patches = checkpoint(segm_module, patch_tokens, H, W)
```

---

## é™„éŒ„ Eï¼šç¸½çµèˆ‡æ¨è–¦é…ç½®

### E.1 æ ¸å¿ƒè¨­è¨ˆç†å¿µ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SEGM v2 è¨­è¨ˆç†å¿µ                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  å•é¡Œï¼šDINO ç„¡æ³•ç›´æ¥æª¢æ¸¬ stomataï¼ˆnoise å¤–è§€ç›¸ä¼¼ï¼‰               â”‚
â”‚                                                                  â”‚
â”‚  è§£æ³•ï¼šåˆ©ç”¨ stomata çš„å”¯ä¸€å¯é ç‰¹å¾µ â€”â€” é€±æœŸæ€§æ’åˆ—                 â”‚
â”‚                                                                  â”‚
â”‚  åŸç†ï¼š                                                          â”‚
â”‚    â€¢ Stomata æ˜¯é€±æœŸæ€§çš„ â†’ å¯ç”¨ FFT ä¼°è¨ˆé »ç‡                     â”‚
â”‚    â€¢ Noise æ˜¯éš¨æ©Ÿçš„ â†’ ä¸ç¬¦åˆé€±æœŸæ€§ pattern                       â”‚
â”‚    â€¢ ç”¨é€±æœŸæ€§ Grid å¼•å° DINO é—œæ³¨æ­£ç¢ºä½ç½®                        â”‚
â”‚                                                                  â”‚
â”‚  â­ ç¾¤é«”ä¸€è‡´æ€§åŸç†ï¼ˆL_intra çš„ç†è«–åŸºç¤ï¼‰ï¼š                       â”‚
â”‚    â€¢ å–®å€‹æ¯”è¼ƒ: stomata_feat â‰ˆ noise_featï¼ˆé›£å€åˆ†ï¼‰              â”‚
â”‚    â€¢ ç¾¤é«”æ¯”è¼ƒ:                                                   â”‚
â”‚      - {stomata_1, stomata_2, ...} â†’ åŒé¡ç‰©é«” â†’ é«˜ä¸€è‡´æ€§        â”‚
â”‚      - {åå…‰, è‘‰è„ˆ, ç´°èƒå£, ...}  â†’ ä¸åŒç‰©é«” â†’ ä½ä¸€è‡´æ€§         â”‚
â”‚    â€¢ Grid å°åˆ° stomata â†’ å³°å€¼ç‰¹å¾µä¸€è‡´ â†’ L_intra ä½ â†’ ç¶­æŒ       â”‚
â”‚    â€¢ Grid å°åˆ° noise â†’ å³°å€¼ç‰¹å¾µä¸ä¸€è‡´ â†’ L_intra é«˜ â†’ èª¿æ•´       â”‚
â”‚                                                                  â”‚
â”‚  è‡ªç›£ç£ï¼š                                                        â”‚
â”‚    â€¢ L_intraï¼šè¢«é¸ä½ç½®çš„ç‰¹å¾µæ‡‰ä¸€è‡´ï¼ˆç¾¤é«”ä¸€è‡´æ€§ï¼‰                 â”‚
â”‚    â€¢ L_interï¼šå³°/è°·ç‰¹å¾µæ‡‰ä¸åŒï¼ˆå‰æ™¯/èƒŒæ™¯å€åˆ†ï¼‰                   â”‚
â”‚    â€¢ L_period + L_sparseï¼šç¢ºä¿ Grid åˆç†                         â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### E.1.1 èˆ‡ MTKD æ¡†æ¶çš„æ•´åˆ

FilterBank-enhanced DINO å¯ä»¥ä½œç‚º MTKD æ¡†æ¶ä¸­çš„ Feature Teacherï¼š

```
MTKD + FilterBank æ•´åˆæ¶æ§‹ï¼š

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                                 â”‚
â”‚  DINO + FilterBank (Feature Teacher)                           â”‚
â”‚  â”œâ”€â”€ æä¾›ï¼šEnhanced Featuresï¼ˆé€±æœŸæ€§å€åŸŸè¢«å¼·åŒ–ï¼‰                â”‚
â”‚  â””â”€â”€ è§’è‰²ï¼šå¼•å° Student é—œæ³¨é€±æœŸæ€§ä½ç½®                          â”‚
â”‚                                                                 â”‚
â”‚  YOLOv8 (Detection Teacher)                                    â”‚
â”‚  â”œâ”€â”€ æä¾›ï¼šPredictionsï¼ˆå« stomata + false positivesï¼‰          â”‚
â”‚  â””â”€â”€ è§’è‰²ï¼šæä¾›æª¢æ¸¬çŸ¥è­˜                                         â”‚
â”‚                                                                 â”‚
â”‚  YOLOv11 (Student)                                             â”‚
â”‚  â”œâ”€â”€ å­¸ç¿’ï¼šåŒæ™‚å°é½Š Enhanced Features å’Œ YOLOv8 Predictions     â”‚
â”‚  â””â”€â”€ æ•ˆæœï¼šåå¥½é€±æœŸæ€§ä½ç½® â†’ æ¸›å°‘ False Positives                â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

è¨“ç·´æ•ˆæœï¼š
1. YOLOv8 é æ¸¬çš„ FPï¼ˆnoiseï¼‰ä½ç½® â†’ Enhanced Features éŸ¿æ‡‰ä½
2. YOLOv8 é æ¸¬çš„ TPï¼ˆstomataï¼‰ä½ç½® â†’ Enhanced Features éŸ¿æ‡‰é«˜
3. YOLOv11 å°é½Š Enhanced Features â†’ å­¸æœƒå€åˆ† TP/FP
4. çµæœï¼šYOLOv11 çš„ FP æ¸›å°‘
```

### E.2 è™•ç†ä¸å®Œç¾é€±æœŸæ€§çš„å››ç¨®ç­–ç•¥

| æ–¹æ¡ˆ | ç­–ç•¥ | æ ¸å¿ƒæ€è·¯ | æ¨è–¦åº¦ |
|-----|------|---------|--------|
| **A** | å¯¬é¬†å³°å€¼ | ä½ Îº å€¼ï¼Œå®¹å¿ä½ç½®åå·® | â˜…â˜…â˜…â˜…â˜… |
| **B** | é »ç‡å¸¶é€š | é »åŸŸæ“ä½œï¼Œä¸ä¾è³´ phase | â˜…â˜…â˜… |
| **C** | çµ±è¨ˆå…ˆé©— | åªåœ¨é€±æœŸæ€§æ˜é¡¯æ™‚èª¿è®Š | â˜…â˜…â˜…â˜…â˜… |
| **D** | ç‰¹å¾µå¼•å° | ç”¨ç‰¹å¾µç›¸ä¼¼åº¦ç´°åŒ–ä½ç½® | â˜…â˜… |

**æ¨è–¦çµ„åˆ**ï¼š**A + C + Soft Modulation**

### E.3 æ¨è–¦é…ç½®ç¸½è¡¨

```yaml
# segm_v2_config.yaml

model:
  backbone: "dinov3_vitb16"
  segm_after_blocks: [10]

segm:
  # é »ç‡ä¼°è¨ˆ
  num_freq_bins: 32
  hidden_dim: 256

  # Grid ç”Ÿæˆ
  kappa_init: 1.0            # å¯¬å³° (æ–¹æ¡ˆ A)
  use_soft_modulation: true  # Soft Modulation
  soft_temperature: 5.0

  # çµ±è¨ˆå…ˆé©— (æ–¹æ¡ˆ C)
  use_periodicity_gate: true
  periodicity_threshold: 2.0

loss:
  # æ ¸å¿ƒ loss
  intra_weight: 1.0          # å³°å€¼ç‰¹å¾µä¸€è‡´æ€§
  inter_weight: 1.0          # å³°/è°·å€åˆ†åº¦

  # æ­£å‰‡åŒ–
  period_weight: 0.5         # é€±æœŸæ€§ç´„æŸ
  freq_smooth_weight: 0.5    # é »ç‡å¹³æ»‘
  sparse_weight: 0.1         # ç¨€ç–æ€§
  sparse_target: 0.1         # ç›®æ¨™è¦†è“‹ç‡ 10%

training:
  learning_rate: 1e-4
  optimizer: "AdamW"
  weight_decay: 0.01
  batch_size: 16
  warmup_epochs: 5
  num_epochs: 100

  # å‡çµç­–ç•¥
  freeze_backbone: true
```

### E.4 é æœŸè¡Œç‚º

| è¨“ç·´éšæ®µ | é æœŸç¾è±¡ |
|---------|---------|
| Epoch 0 | Grid æ˜¯ FFT ä¼°è¨ˆçš„é€±æœŸ patternï¼›gate â‰ˆ 0ï¼Œè¼¸å‡º â‰ˆ åŸå§‹ DINO |
| Epoch 1-10 | Gate é€æ¼¸æ‰“é–‹ï¼›Grid é–‹å§‹å¾®èª¿ä»¥æœ€å¤§åŒ– L_intra |
| Epoch 10-50 | Grid æ”¶æ–‚åˆ°ç©©å®š patternï¼›é »ç‡ä¼°è¨ˆè®Šæº–ç¢º |
| æ”¶æ–‚å¾Œ | Grid å³°å€¼å°æ‡‰ stomata ä½ç½®ï¼›ç‰¹å¾µè¢«é€±æœŸæ€§å¼•å°å¢å¼· |

### E.5 é©—è­‰æª¢æŸ¥é»

1. **Grid è¦–è¦ºåŒ–**ï¼šæ‡‰é¡¯ç¤ºæ˜é¡¯çš„é€±æœŸæ€§çµæ§‹
2. **é »ç‡ä¼°è¨ˆ**ï¼šæ¯è¡Œçš„ä¸»é »ç‡æ‡‰åœ¨åˆç†ç¯„åœï¼ˆå¦‚ 2-8 cycles/rowï¼‰
3. **L_intra ä¸‹é™**ï¼šè¡¨ç¤ºå³°å€¼ä½ç½®çš„ç‰¹å¾µè¶Šä¾†è¶Šä¸€è‡´
4. **L_inter ä¸‹é™**ï¼šè¡¨ç¤ºå³°/è°·å€åˆ†åº¦è¶Šä¾†è¶Šå¤§
5. **èˆ‡åŸå§‹ DINO æ¯”è¼ƒ**ï¼šå¢å¼·å¾Œçš„ç‰¹å¾µæ‡‰æ›´èšç„¦åœ¨é€±æœŸæ€§ä½ç½®

### E.6 æ½›åœ¨é¢¨éšªèˆ‡ç·©è§£

| é¢¨éšª | å¾µå…† | ç·©è§£æªæ–½ |
|-----|------|---------|
| Grid å…¨äº®/å…¨æš— | L_sparse å¾ˆå¤§æˆ–å¾ˆå° | èª¿æ•´ sparse_weight å’Œ sparse_target |
| é »ç‡ä¼°è¨ˆå¤±æ•ˆ | Grid ä¸åƒé€±æœŸæ€§ | å¢åŠ  period_weightï¼›æª¢æŸ¥ FFT å¯¦ä½œ |
| Gate ç„¡æ³•æ‰“é–‹ | è¼¸å‡ºå§‹çµ‚ â‰ˆ åŸå§‹ DINO | å¢åŠ  learning_rateï¼›æª¢æŸ¥æ¢¯åº¦æµ |
| éæ“¬åˆå–®ä¸€é »ç‡ | æ‰€æœ‰è¡Œé »ç‡ç›¸åŒ | å¢åŠ  freq_smooth_weightï¼›åŠ é »ç‡å¤šæ¨£æ€§æ­£å‰‡åŒ– |
| L_intra ä¸ä¸‹é™ | ç¾¤é«”ä¸€è‡´æ€§å‡è¨­ä¸æˆç«‹ | åŸ·è¡Œ E.7 é©—è­‰å¯¦é©—ï¼›è€ƒæ…®æ›¿ä»£æ–¹æ¡ˆ |

### E.7 â­ è¨“ç·´å‰é©—è­‰å¯¦é©—ï¼ˆå¼·çƒˆå»ºè­°ï¼‰

åœ¨æŠ•å…¥è¨“ç·´è³‡æºå‰ï¼Œå…ˆé©—è­‰ L_intra çš„æ ¸å¿ƒå‡è¨­æ˜¯å¦æˆç«‹ï¼š

> **ğŸ”§ ç¨ç«‹é©—è­‰è…³æœ¬**
>
> æˆ‘å€‘æä¾›äº†å…©å€‹å¯ç›´æ¥åŸ·è¡Œçš„é©—è­‰è…³æœ¬ï¼š
>
> #### é©—è­‰ 1ï¼šç¾¤é«”ä¸€è‡´æ€§ï¼ˆL_intra åŸºç¤å‡è¨­ï¼‰
> ```bash
> # ä½ç½®ï¼šdinov3-main/verify_group_consistency.py
> python verify_group_consistency.py
> ```
> - **æ¸¬è©¦å…§å®¹**ï¼šStomata ç‰¹å¾µå½¼æ­¤ç›¸ä¼¼ vs Noise ç‰¹å¾µå½¼æ­¤ä¸åŒ
> - **è¼¸å…¥**ï¼š5-10 å€‹ stomata åº§æ¨™ + 5-10 å€‹ noise åº§æ¨™
> - **é æœŸçµæœ**ï¼šstomata_consistency > noise_consistency
>
> #### é©—è­‰ 2ï¼šè¡Œé€±æœŸæ€§ï¼ˆFilterBank æ ¸å¿ƒæ©Ÿåˆ¶ï¼‰â­
> ```bash
> # ä½ç½®ï¼šdinov3-main/verify_row_periodicity.py
> python verify_row_periodicity.py
> ```
> - **æ¸¬è©¦å…§å®¹**ï¼šæœ‰ stomata çš„è¡Œæœ‰é€±æœŸæ€§ vs æ²’æœ‰ stomata çš„è¡Œç„¡é€±æœŸæ€§
> - **è¼¸å…¥**ï¼š3-5 å€‹æœ‰ stomata çš„è¡Œ Y åº§æ¨™ + 3-5 å€‹ç„¡ stomata çš„è¡Œ Y åº§æ¨™
> - **é æœŸçµæœ**ï¼šstomata_row_periodicity > non_stomata_row_periodicity
> - **é€™æ˜¯ FilterBank éæ¿¾ noise çš„æ ¸å¿ƒæ©Ÿåˆ¶**ï¼šå³ä½¿ noise é•·å¾—åƒ stomataï¼Œä½†å®ƒä¸åœ¨é€±æœŸä½ç½®ä¸Šï¼Œå°±æœƒè¢«å£“ä½
>
> **å»ºè­°**ï¼šå…©å€‹é©—è­‰éƒ½åŸ·è¡Œï¼Œç¢ºä¿å‡è¨­æˆç«‹å¾Œå†é€²è¡Œè¨“ç·´ã€‚

**ä»¥ä¸‹ç‚ºé©—è­‰é‚è¼¯çš„è©³ç´°èªªæ˜**ï¼š

```python
"""
é©—è­‰å¯¦é©—ï¼šç¢ºèª stomata ç¾¤é«”ä¸€è‡´æ€§ > noise ç¾¤é«”ä¸€è‡´æ€§

åŸ·è¡Œæ–¹å¼ï¼š
1. æº–å‚™ä¸€å¼µå¸¶æœ‰ Ground Truth æ¨™æ³¨çš„åœ–åƒ
2. äººå·¥æ¨™è¨˜ 5-10 å€‹ stomata ä½ç½®
3. äººå·¥æ¨™è¨˜ 5-10 å€‹ noise ä½ç½®ï¼ˆåå…‰ã€è‘‰è„ˆã€ç´°èƒå£ç­‰ï¼‰
4. åŸ·è¡Œæ­¤è…³æœ¬
"""

import torch
import torch.nn.functional as F

def verify_group_consistency_assumption(
    dino_model,
    image,                    # (1, 3, 224, 224)
    stomata_pixel_positions,  # [(x1, y1), (x2, y2), ...] åƒç´ åº§æ¨™
    noise_pixel_positions,    # [(x1, y1), (x2, y2), ...]
    patch_size=16,
):
    """
    Returns:
        is_valid: bool - å‡è¨­æ˜¯å¦æˆç«‹
        stomata_consistency: float
        noise_consistency: float
    """
    dino_model.eval()

    with torch.no_grad():
        # æå– DINO ç‰¹å¾µ
        output = dino_model(image)
        features = output['x_norm_patchtokens']  # (1, 196, 768)
        features = features.view(1, 14, 14, 768)  # (1, H, W, C)

        # è½‰æ›åƒç´ åº§æ¨™åˆ° patch åº§æ¨™
        def pixel_to_patch(positions):
            return [(x // patch_size, y // patch_size) for (x, y) in positions]

        stomata_patches = pixel_to_patch(stomata_pixel_positions)
        noise_patches = pixel_to_patch(noise_pixel_positions)

        # æå–ç‰¹å¾µ
        stomata_feats = torch.stack([
            features[0, py, px, :] for (px, py) in stomata_patches
        ])  # (N_stomata, 768)

        noise_feats = torch.stack([
            features[0, py, px, :] for (px, py) in noise_patches
        ])  # (N_noise, 768)

        # è¨ˆç®— pairwise cosine similarity
        def pairwise_cosine(feats):
            feats_norm = F.normalize(feats, dim=-1)
            sim_matrix = feats_norm @ feats_norm.T  # (N, N)
            # æ’é™¤å°è§’ç·š
            n = feats.shape[0]
            mask = ~torch.eye(n, dtype=bool, device=feats.device)
            return sim_matrix[mask].mean()

        stomata_consistency = pairwise_cosine(stomata_feats).item()
        noise_consistency = pairwise_cosine(noise_feats).item()

        # çµæœåˆ†æ
        print("=" * 60)
        print("ç¾¤é«”ä¸€è‡´æ€§é©—è­‰çµæœ")
        print("=" * 60)
        print(f"Stomata ç¾¤é«”ä¸€è‡´æ€§: {stomata_consistency:.4f}")
        print(f"Noise ç¾¤é«”ä¸€è‡´æ€§:   {noise_consistency:.4f}")
        print(f"æ¯”å€¼ (stomata/noise): {stomata_consistency/noise_consistency:.2f}x")
        print("-" * 60)

        is_valid = stomata_consistency > noise_consistency

        if is_valid:
            print("âœ… å‡è¨­æˆç«‹ï¼šL_intra é æœŸæœ‰æ•ˆ")
            print("   â†’ å¯ä»¥é€²è¡Œ FilterBank è¨“ç·´")
        else:
            print("âŒ å‡è¨­ä¸æˆç«‹ï¼šL_intra å¯èƒ½ç„¡æ•ˆ")
            print("   â†’ å»ºè­°æª¢æŸ¥ï¼š")
            print("     1. æ¨™è¨˜çš„ä½ç½®æ˜¯å¦æ­£ç¢ºï¼Ÿ")
            print("     2. Noise é¡åˆ¥æ˜¯å¦å¤ªå–®ä¸€ï¼Ÿï¼ˆæ‡‰åŒ…å«å¤šç¨®ï¼‰")
            print("     3. è€ƒæ…®æ›¿ä»£æ–¹æ¡ˆï¼ˆè¦‹ E.8ï¼‰")

        print("=" * 60)

        return is_valid, stomata_consistency, noise_consistency


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    from dinov3.models import build_model

    # è¼‰å…¥ DINO
    dino = build_model(model_name="vit_base", patch_size=16)
    dino.load_state_dict(torch.load("dinov3_vitb16.pth"))

    # è¼‰å…¥æ¸¬è©¦åœ–åƒ
    image = load_image("test_stomata.jpg")  # éœ€è‡ªè¡Œå¯¦ä½œ

    # äººå·¥æ¨™è¨˜çš„ä½ç½®ï¼ˆåƒç´ åº§æ¨™ï¼‰
    stomata_positions = [
        (45, 30), (120, 32), (195, 28),  # Row 0 çš„å¹¾å€‹ stomata
        (60, 95), (135, 98), (210, 92),  # Row 2 çš„å¹¾å€‹ stomata
    ]

    noise_positions = [
        (80, 60),   # åå…‰
        (150, 120), # è‘‰è„ˆäº¤å‰
        (30, 150),  # ç´°èƒå£
        (200, 45),  # æ¨¡ç³Šå€åŸŸ
        (100, 180), # å¦ä¸€å€‹åå…‰
    ]

    is_valid, s_cons, n_cons = verify_group_consistency_assumption(
        dino, image, stomata_positions, noise_positions
    )
```

### E.8 å‡è¨­ä¸æˆç«‹æ™‚çš„æ›¿ä»£æ–¹æ¡ˆ

å¦‚æœ E.7 é©—è­‰å¯¦é©—é¡¯ç¤º `stomata_consistency â‰¤ noise_consistency`ï¼š

| æ›¿ä»£æ–¹æ¡ˆ | èªªæ˜ | è¤‡é›œåº¦ |
|---------|------|--------|
| **æ–¹æ¡ˆ 1ï¼šå¢åŠ  noise å¤šæ¨£æ€§** | ç¢ºä¿ noise åŒ…å«å¤šç¨®é¡å‹ï¼ˆåå…‰ã€è‘‰è„ˆã€ç´°èƒå£ã€æ¨¡ç³Šç­‰ï¼‰ | ä½ |
| **æ–¹æ¡ˆ 2ï¼šä½¿ç”¨ YOLO é æ¸¬å¼•å°** | ç”¨ YOLOv8 é æ¸¬ä½ç½®ä¾†ä¼°è¨ˆé€±æœŸæ€§ï¼Œè€Œé DINO ç‰¹å¾µ | ä¸­ |
| **æ–¹æ¡ˆ 3ï¼šå¤šå°ºåº¦ç‰¹å¾µ** | çµåˆ DINO æ—©æœŸå±¤ï¼ˆæ›´ç´°ç²’åº¦ï¼‰å’Œæ™šæœŸå±¤ç‰¹å¾µ | ä¸­ |
| **æ–¹æ¡ˆ 4ï¼šæ”¹ç”¨ Autocorrelation** | ç”¨ç‰¹å¾µè‡ªç›¸é—œæ›¿ä»£ FFT ä¼°è¨ˆé€±æœŸ | ä¸­ |
| **æ–¹æ¡ˆ 5ï¼šæ”¾æ£„ DINO Feature** | ç›´æ¥åœ¨ YOLO é æ¸¬ä¸Šåšé€±æœŸæ€§å¾Œè™•ç† | ä½ |

---

## é™„éŒ„ Fï¼šå®Œæ•´å¯¦ä½œç¨‹å¼ç¢¼

> ä»¥ä¸‹ç‚ºå¯ç›´æ¥ä½¿ç”¨çš„å®Œæ•´å¯¦ä½œç¨‹å¼ç¢¼

### F.1 æª”æ¡ˆçµæ§‹

```
segm_v2/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ frequency_estimator.py      # F.2
â”‚   â”œâ”€â”€ grid_generator.py           # F.3
â”‚   â”œâ”€â”€ segm_adapter.py             # F.4
â”‚   â””â”€â”€ segm_vision_transformer.py  # F.5
â”œâ”€â”€ losses/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ unsupervised_loss.py        # F.6
â””â”€â”€ train.py                        # F.7
```

### F.2 frequency_estimator.py

```python
# segm_v2/models/frequency_estimator.py

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch import Tensor


class RowFrequencyEstimator(nn.Module):
    """
    å°æ¯ä¸€è¡Œé€²è¡Œé »ç‡åˆ†æï¼Œä¼°è¨ˆæ°´å¹³æ–¹å‘çš„é€±æœŸæ€§

    è¼¸å…¥: (B, H, W, C) - ç©ºé–“æ ¼å¼ç‰¹å¾µ
    è¼¸å‡º: dict containing:
        - dominant_freq: (B, H) - æ¯è¡Œä¸»é »ç‡ï¼Œç¯„åœ [0, 1]
        - freq_spectrum: (B, H, num_freq_bins) - å®Œæ•´é »è­œ
        - periodicity_score: (B, H) - é€±æœŸæ€§å¼·åº¦
    """

    def __init__(
        self,
        embed_dim: int = 768,
        hidden_dim: int = 256,
        num_freq_bins: int = 32,
        use_learnable_filter: bool = True,
    ):
        super().__init__()

        self.embed_dim = embed_dim
        self.hidden_dim = hidden_dim
        self.num_freq_bins = num_freq_bins

        # 1. Feature projection: C â†’ hidden_dim
        self.feature_proj = nn.Sequential(
            nn.Linear(embed_dim, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, hidden_dim),
        )

        # 2. Learnable frequency filter (å¯é¸)
        self.use_learnable_filter = use_learnable_filter
        if use_learnable_filter:
            self.freq_filter = nn.Parameter(torch.ones(num_freq_bins))

        # 3. Frequency encoding: num_freq_bins â†’ embed_dim
        self.freq_encoder = nn.Sequential(
            nn.Linear(num_freq_bins, hidden_dim),
            nn.GELU(),
            nn.Linear(hidden_dim, embed_dim),
        )

    def forward(self, spatial_features: Tensor) -> dict:
        """
        Args:
            spatial_features: (B, H, W, C)

        Returns:
            dict with keys:
                - dominant_freq: (B, H)
                - freq_spectrum: (B, H, num_freq_bins)
                - periodicity_score: (B, H)
                - row_freq_features: (B, H, C)
        """
        B, H, W, C = spatial_features.shape

        # 1. Feature projection
        # (B, H, W, C) â†’ (B, H, W, hidden_dim)
        projected = self.feature_proj(spatial_features)

        # 2. Row-wise 1D rFFT
        # å°æ¯è¡Œæ²¿ W æ–¹å‘åš FFT
        # (B, H, W, hidden_dim) â†’ (B, H, hidden_dim, W//2+1) [complex]
        projected_transposed = projected.permute(0, 1, 3, 2)  # (B, H, hidden_dim, W)
        fft_result = torch.fft.rfft(projected_transposed, dim=-1)  # (B, H, hidden_dim, W//2+1)

        # 3. Power spectrum
        # magnitudeÂ² â†’ mean over hidden_dim â†’ (B, H, W//2+1)
        power_spectrum = torch.abs(fft_result) ** 2
        power_spectrum = power_spectrum.mean(dim=2)  # (B, H, W//2+1)

        # 4. Interpolate to fixed number of bins
        # (B, H, W//2+1) â†’ (B, H, num_freq_bins)
        power_spectrum_resized = F.interpolate(
            power_spectrum.unsqueeze(1),  # (B, 1, H, W//2+1)
            size=(H, self.num_freq_bins),
            mode='bilinear',
            align_corners=False,
        ).squeeze(1)  # (B, H, num_freq_bins)

        # 5. Apply learnable filter (å¯é¸)
        if self.use_learnable_filter:
            freq_spectrum = power_spectrum_resized * F.softplus(self.freq_filter)
        else:
            freq_spectrum = power_spectrum_resized

        # 6. Find dominant frequency (æ’é™¤ DC component)
        # DC åœ¨ index 0ï¼Œæ‰€ä»¥å¾ index 1 é–‹å§‹æ‰¾
        freq_spectrum_no_dc = freq_spectrum[:, :, 1:]  # (B, H, num_freq_bins-1)
        dominant_freq_idx = freq_spectrum_no_dc.argmax(dim=-1) + 1  # (B, H)

        # æ­£è¦åŒ–åˆ° [0, 1]
        dominant_freq = dominant_freq_idx.float() / self.num_freq_bins

        # 7. Calculate periodicity score (peak / mean ratio)
        peak_power = freq_spectrum_no_dc.max(dim=-1).values  # (B, H)
        mean_power = freq_spectrum_no_dc.mean(dim=-1)  # (B, H)
        periodicity_score = peak_power / (mean_power + 1e-6)  # (B, H)

        # 8. Frequency encoding
        # (B, H, num_freq_bins) â†’ (B, H, C)
        row_freq_features = self.freq_encoder(freq_spectrum)

        return {
            'dominant_freq': dominant_freq,           # (B, H)
            'freq_spectrum': freq_spectrum,           # (B, H, num_freq_bins)
            'periodicity_score': periodicity_score,   # (B, H)
            'row_freq_features': row_freq_features,   # (B, H, C)
        }
```

### F.3 grid_generator.py

```python
# segm_v2/models/grid_generator.py

import math
import torch
import torch.nn as nn
from torch import Tensor


class PeriodicGridGenerator(nn.Module):
    """
    æ ¹æ“šä¼°è¨ˆçš„é »ç‡ç”Ÿæˆé€±æœŸæ€§ Grid

    ä½¿ç”¨ Power Cosine Wave: ((cos(2Ï€ft + Ï†) + 1) / 2)^Îº

    è¼¸å…¥:
        - dominant_freq: (B, H) - æ¯è¡Œçš„ä¸»é »ç‡
        - H, W: ç©ºé–“ç¶­åº¦
    è¼¸å‡º:
        - grid: (B, 1, H, W) - é€±æœŸæ€§ Gridï¼Œå€¼åŸŸ [0, 1]
    """

    def __init__(
        self,
        max_height: int = 64,
        kappa_init: float = 1.0,
        use_col_modulation: bool = True,
        use_soft_modulation: bool = True,
        soft_temperature: float = 5.0,
    ):
        super().__init__()

        self.max_height = max_height
        self.use_col_modulation = use_col_modulation
        self.use_soft_modulation = use_soft_modulation
        self.soft_temperature = soft_temperature

        # å¯å­¸ç¿’çš„ per-row ç›¸ä½
        self.row_phases = nn.Parameter(torch.zeros(1, max_height))

        # å¯å­¸ç¿’çš„ kappa (å°–éŠ³åº¦)
        # ä½¿ç”¨ softplus ç¢ºä¿ > 0ï¼Œåˆå§‹åŒ–ä½¿å¾— softplus(x) â‰ˆ kappa_init
        kappa_init_value = math.log(math.exp(kappa_init) - 1)  # inverse softplus
        self.kappa_raw = nn.Parameter(torch.tensor([kappa_init_value]))

        # åˆ—æ–¹å‘èª¿è®Šï¼ˆå¯é¸ï¼‰
        if use_col_modulation:
            self.col_freq = nn.Parameter(torch.zeros(1))
            self.col_phase = nn.Parameter(torch.zeros(1))

    @property
    def kappa(self) -> Tensor:
        """ç¢ºä¿ kappa > 0"""
        return F.softplus(self.kappa_raw) + 0.1  # æœ€å°å€¼ 0.1

    def forward(
        self,
        dominant_freq: Tensor,
        periodicity_score: Tensor = None,
        H: int = None,
        W: int = None,
    ) -> Tensor:
        """
        Args:
            dominant_freq: (B, H) - æ¯è¡Œé »ç‡ï¼Œç¯„åœ [0, 1]
            periodicity_score: (B, H) - é€±æœŸæ€§å¼·åº¦ï¼ˆå¯é¸ï¼Œç”¨æ–¼æ–¹æ¡ˆ Cï¼‰
            H, W: ç©ºé–“ç¶­åº¦

        Returns:
            grid: (B, 1, H, W)
        """
        B = dominant_freq.shape[0]
        if H is None:
            H = dominant_freq.shape[1]

        device = dominant_freq.device
        dtype = dominant_freq.dtype

        # 1. ç”Ÿæˆ x åº§æ¨™ [0, 1, 2, ..., W-1]
        x_coords = torch.arange(W, device=device, dtype=dtype)  # (W,)

        # 2. ç²å– phase å’Œ kappa
        # row_phases: (1, max_height) â†’ (B, H)
        phases = self.row_phases[:, :H].expand(B, -1)  # (B, H)
        phases = torch.sigmoid(phases) * 2 * math.pi  # ç¯„åœ [0, 2Ï€]

        kappa = self.kappa  # scalar

        # 3. è¨ˆç®—æ¯è¡Œçš„æ³¢å½¢
        # freq: (B, H) â†’ (B, H, 1)
        # x: (W,) â†’ (1, 1, W)
        freq = dominant_freq.unsqueeze(-1)  # (B, H, 1)
        phase = phases.unsqueeze(-1)         # (B, H, 1)
        x = x_coords.view(1, 1, W)           # (1, 1, W)

        # å°‡é »ç‡è½‰æ›ç‚ºé€±æœŸæ•¸ï¼ˆfreq æ˜¯æ­£è¦åŒ–çš„ï¼Œä¹˜ä»¥ W å¾—åˆ°å¯¦éš›é€±æœŸæ•¸ï¼‰
        # ä¾‹å¦‚ freq=0.1 è¡¨ç¤ºæ¯ 10 å€‹ pixel ä¸€å€‹é€±æœŸ
        actual_freq = freq * W / 2  # èª¿æ•´ç¯„åœ

        # Power Cosine Wave: ((cos(2Ï€fÂ·x/W + Ï†) + 1) / 2)^Îº
        angle = 2 * math.pi * actual_freq * x / W + phase  # (B, H, W)
        row_wave = ((torch.cos(angle) + 1) / 2) ** kappa   # (B, H, W)

        # 4. åˆ—æ–¹å‘èª¿è®Šï¼ˆå¯é¸ï¼‰
        if self.use_col_modulation:
            y_coords = torch.arange(H, device=device, dtype=dtype)  # (H,)
            y = y_coords.view(1, H, 1)  # (1, H, 1)

            col_freq = torch.sigmoid(self.col_freq) * H / 4  # åˆ—æ–¹å‘é »ç‡
            col_phase = torch.sigmoid(self.col_phase) * 2 * math.pi

            col_angle = 2 * math.pi * col_freq * y / H + col_phase
            col_wave = ((torch.cos(col_angle) + 1) / 2) ** kappa  # (1, H, 1)

            grid = row_wave * col_wave  # (B, H, W)
        else:
            grid = row_wave  # (B, H, W)

        # 5. æ–¹æ¡ˆ Cï¼šçµ±è¨ˆå…ˆé©— - åªåœ¨é€±æœŸæ€§æ˜é¡¯æ™‚èª¿è®Š
        if periodicity_score is not None:
            # periodicity_score: (B, H) â†’ (B, H, 1)
            score = periodicity_score.unsqueeze(-1)  # (B, H, 1)

            # ä½¿ç”¨ sigmoid åšè»Ÿé–¾å€¼
            periodicity_gate = torch.sigmoid(
                (score - 2.0) * 2.0  # threshold=2.0, temperature=2.0
            )  # (B, H, 1)

            grid = grid * periodicity_gate  # é€±æœŸæ€§å¼±çš„è¡Œæœƒè¢«æŠ‘åˆ¶

        # 6. Soft Modulationï¼ˆæ–¹æ¡ˆ A çš„ä¸€éƒ¨åˆ†ï¼‰
        if self.use_soft_modulation:
            grid = torch.sigmoid((grid - 0.5) * self.soft_temperature)

        # 7. å¢åŠ  channel ç¶­åº¦
        grid = grid.unsqueeze(1)  # (B, 1, H, W)

        return grid


# éœ€è¦ import F
import torch.nn.functional as F
```

### F.4 segm_adapter.py

```python
# segm_v2/models/segm_adapter.py

import torch
import torch.nn as nn
from torch import Tensor

from .frequency_estimator import RowFrequencyEstimator
from .grid_generator import PeriodicGridGenerator


class SEGMAdapter(nn.Module):
    """
    åœ¨ DINO Block ä¹‹é–“æ’å…¥çš„ SEGM é©é…å™¨

    è¼¸å…¥è¼¸å‡ºéƒ½æ˜¯ (B, N, C) æ ¼å¼ï¼Œèˆ‡ Block ç›¸å®¹
    """

    def __init__(
        self,
        embed_dim: int = 768,
        num_freq_bins: int = 32,
        hidden_dim: int = 256,
        kappa_init: float = 1.0,
        use_soft_modulation: bool = True,
        soft_temperature: float = 5.0,
        use_periodicity_gate: bool = True,
    ):
        super().__init__()

        self.embed_dim = embed_dim
        self.use_periodicity_gate = use_periodicity_gate

        # 1. Frequency Estimator
        self.freq_estimator = RowFrequencyEstimator(
            embed_dim=embed_dim,
            hidden_dim=hidden_dim,
            num_freq_bins=num_freq_bins,
        )

        # 2. Grid Generator
        self.grid_generator = PeriodicGridGenerator(
            kappa_init=kappa_init,
            use_soft_modulation=use_soft_modulation,
            soft_temperature=soft_temperature,
        )

        # 3. Channel Projection: (B, 1, H, W) â†’ (B, C, H, W)
        self.channel_proj = nn.Conv2d(1, embed_dim, kernel_size=1, bias=False)
        nn.init.zeros_(self.channel_proj.weight)  # Zero-init

        # 4. Zero-Init Gateï¼ˆé—œéµï¼åˆå§‹åŒ–ç‚º 0ï¼Œç¢ºä¿åˆå§‹è¼¸å‡º = åŸå§‹è¼¸å…¥ï¼‰
        self.gate = nn.Parameter(torch.zeros(1))

        # å„²å­˜ä¸­é–“çµæœç”¨æ–¼è¨ˆç®— loss
        self._freq_info = None
        self._grid = None

    def forward(self, patch_tokens: Tensor, H: int, W: int) -> Tensor:
        """
        Args:
            patch_tokens: (B, H*W, C) - åªæœ‰ patch tokensï¼Œä¸å« CLS
            H, W: spatial dimensions

        Returns:
            enhanced_tokens: (B, H*W, C)
        """
        B, N, C = patch_tokens.shape
        assert N == H * W, f"Expected N={H*W}, got N={N}"

        # 1. Reshape to 2D: (B, H*W, C) â†’ (B, H, W, C)
        spatial = patch_tokens.view(B, H, W, C)

        # 2. Row-wise frequency estimation
        freq_info = self.freq_estimator(spatial)
        self._freq_info = freq_info  # å„²å­˜ç”¨æ–¼ loss è¨ˆç®—

        # 3. Generate periodic grid
        periodicity_score = freq_info['periodicity_score'] if self.use_periodicity_gate else None
        grid = self.grid_generator(
            dominant_freq=freq_info['dominant_freq'],
            periodicity_score=periodicity_score,
            H=H,
            W=W,
        )  # (B, 1, H, W)
        self._grid = grid  # å„²å­˜ç”¨æ–¼ loss è¨ˆç®—

        # 4. Channel projection: (B, 1, H, W) â†’ (B, C, H, W)
        delta = self.channel_proj(grid)  # (B, C, H, W)

        # 5. è½‰æ›æ ¼å¼: (B, C, H, W) â†’ (B, H, W, C) â†’ (B, H*W, C)
        delta = delta.permute(0, 2, 3, 1)  # (B, H, W, C)
        delta = delta.reshape(B, H * W, C)  # (B, N, C)

        # 6. Zero-init gated residual
        # gate åˆå§‹åŒ–ç‚º 0ï¼Œæ‰€ä»¥åˆå§‹æ™‚ enhanced = patch_tokens
        enhanced = patch_tokens + self.gate * delta

        return enhanced

    def get_freq_info(self) -> dict:
        """ç²å–é »ç‡ä¼°è¨ˆè³‡è¨Šï¼ˆç”¨æ–¼ loss è¨ˆç®—ï¼‰"""
        return self._freq_info

    def get_grid(self) -> Tensor:
        """ç²å–ç”Ÿæˆçš„ Gridï¼ˆç”¨æ–¼ loss è¨ˆç®—å’Œè¦–è¦ºåŒ–ï¼‰"""
        return self._grid
```

### F.5 segm_vision_transformer.py

```python
# segm_v2/models/segm_vision_transformer.py

import sys
from typing import Dict, List, Optional

import torch
import torch.nn as nn
from torch import Tensor

# æ·»åŠ  DINOv3 è·¯å¾‘
# è«‹æ ¹æ“šå¯¦éš›è·¯å¾‘èª¿æ•´
sys.path.insert(0, '/path/to/dinov3-main')

from dinov3.models.vision_transformer import DinoVisionTransformer
from .segm_adapter import SEGMAdapter


class SEGMDinoVisionTransformer(DinoVisionTransformer):
    """
    ç¹¼æ‰¿ DINOv3 çš„ ViTï¼Œåœ¨æŒ‡å®š Block å¾Œæ’å…¥ SEGM

    ä½¿ç”¨æ–¹å¼:
        model = SEGMDinoVisionTransformer(
            img_size=224,
            patch_size=16,
            embed_dim=768,
            depth=12,
            num_heads=12,
            segm_after_blocks=[10],
            segm_config={'num_freq_bins': 32, 'hidden_dim': 256}
        )

        # è¼‰å…¥ pretrained weights
        pretrained = torch.load('dinov3_vitb16.pth')
        model.load_state_dict(pretrained, strict=False)
    """

    def __init__(
        self,
        *args,
        segm_after_blocks: List[int] = [10],
        segm_config: Optional[dict] = None,
        freeze_backbone: bool = True,
        **kwargs
    ):
        # åˆå§‹åŒ–çˆ¶é¡
        super().__init__(*args, **kwargs)

        # å‡çµåŸå§‹ DINO åƒæ•¸
        if freeze_backbone:
            for param in self.parameters():
                param.requires_grad = False

        # å»ºç«‹ SEGM æ¨¡çµ„ï¼ˆå¯è¨“ç·´ï¼‰
        self.segm_after_blocks = set(segm_after_blocks)
        self.segm_modules = nn.ModuleDict()

        segm_config = segm_config or {}
        for block_idx in segm_after_blocks:
            self.segm_modules[str(block_idx)] = SEGMAdapter(
                embed_dim=self.embed_dim,
                **segm_config
            )

    def forward_features_list(
        self,
        x_list: List[Tensor],
        masks_list: List[Optional[Tensor]]
    ) -> List[Dict[str, Tensor]]:
        """
        è¦†å¯« forward_features_listï¼Œåœ¨æŒ‡å®šä½ç½®æ’å…¥ SEGM

        é€™å€‹æ–¹æ³•åŸºæœ¬ä¸Šè¤‡è£½äº†çˆ¶é¡çš„å¯¦ä½œï¼Œä½†åœ¨ Block è¿´åœˆä¸­åŠ å…¥ SEGM æ’å…¥é»
        """
        # 1. æº–å‚™ tokens
        x = []
        rope = []
        for t_x, t_masks in zip(x_list, masks_list):
            t2_x, hw_tuple = self.prepare_tokens_with_masks(t_x, t_masks)
            x.append(t2_x)
            rope.append(hw_tuple)  # rope å­˜çš„æ˜¯ (H, W) tuple

        # 2. ä¿®æ”¹çš„ Block è¿´åœˆï¼ˆåŠ å…¥ index è¿½è¹¤ï¼‰
        for blk_idx, blk in enumerate(self.blocks):
            if self.rope_embed is not None:
                rope_sincos = [self.rope_embed(H=H, W=W) for H, W in rope]
            else:
                rope_sincos = [None for _ in rope]

            x = blk(x, rope_sincos)

            # â˜… åœ¨æŒ‡å®š Block å¾Œæ’å…¥ SEGM â˜…
            if blk_idx in self.segm_after_blocks:
                segm_module = self.segm_modules[str(blk_idx)]
                x = self._apply_segm(x, segm_module, rope)

        # 3. Norm å’Œè¼¸å‡ºè™•ç†ï¼ˆè¤‡è£½è‡ªçˆ¶é¡ï¼‰
        all_x = x
        output = []
        for idx, (x, masks) in enumerate(zip(all_x, masks_list)):
            if self.untie_cls_and_patch_norms or self.untie_global_and_local_cls_norm:
                if self.untie_global_and_local_cls_norm and self.training and idx == 1:
                    x_norm_cls_reg = self.local_cls_norm(x[:, : self.n_storage_tokens + 1])
                elif self.untie_cls_and_patch_norms:
                    x_norm_cls_reg = self.cls_norm(x[:, : self.n_storage_tokens + 1])
                else:
                    x_norm_cls_reg = self.norm(x[:, : self.n_storage_tokens + 1])
                x_norm_patch = self.norm(x[:, self.n_storage_tokens + 1 :])
            else:
                x_norm = self.norm(x)
                x_norm_cls_reg = x_norm[:, : self.n_storage_tokens + 1]
                x_norm_patch = x_norm[:, self.n_storage_tokens + 1 :]

            output.append({
                "x_norm_clstoken": x_norm_cls_reg[:, 0],
                "x_storage_tokens": x_norm_cls_reg[:, 1:],
                "x_norm_patchtokens": x_norm_patch,
                "x_prenorm": x,
                "masks": masks,
            })

        return output

    def _apply_segm(
        self,
        x_list: List[Tensor],
        segm_module: SEGMAdapter,
        rope: List[tuple]
    ) -> List[Tensor]:
        """
        å°æ¯å€‹ tensor æ‡‰ç”¨ SEGM

        Args:
            x_list: List of (B, N, C) tensors
            segm_module: SEGM adapter module
            rope: List of (H, W) tuples

        Returns:
            enhanced_x_list: List of (B, N, C) tensors
        """
        enhanced_x = []

        for x, (H, W) in zip(x_list, rope):
            # x shape: (B, N, C) å…¶ä¸­ N = 1 + n_storage + H*W
            B, N, C = x.shape

            # åˆ†é›¢ CLS/storage tokens å’Œ patch tokens
            prefix_len = 1 + self.n_storage_tokens
            prefix_tokens = x[:, :prefix_len, :]      # (B, prefix, C)
            patch_tokens = x[:, prefix_len:, :]       # (B, H*W, C)

            # SEGM åªè™•ç† patch tokens
            enhanced_patches = segm_module(patch_tokens, H, W)

            # é‡æ–°çµ„åˆ
            enhanced_x.append(
                torch.cat([prefix_tokens, enhanced_patches], dim=1)
            )

        return enhanced_x

    def get_segm_outputs(self) -> Dict[str, dict]:
        """
        ç²å–æ‰€æœ‰ SEGM æ¨¡çµ„çš„è¼¸å‡ºï¼ˆç”¨æ–¼ loss è¨ˆç®—ï¼‰

        Returns:
            dict mapping block_idx to {'freq_info': ..., 'grid': ...}
        """
        outputs = {}
        for block_idx, module in self.segm_modules.items():
            outputs[block_idx] = {
                'freq_info': module.get_freq_info(),
                'grid': module.get_grid(),
            }
        return outputs


def create_segm_dino_vitb16(
    pretrained_path: str = None,
    segm_after_blocks: List[int] = [10],
    segm_config: dict = None,
    **kwargs
) -> SEGMDinoVisionTransformer:
    """
    ä¾¿æ·å‡½æ•¸ï¼šå‰µå»º ViT-Base/16 with SEGM

    Args:
        pretrained_path: DINOv3 é è¨“ç·´æ¬Šé‡è·¯å¾‘
        segm_after_blocks: åœ¨å“ªäº› block å¾Œæ’å…¥ SEGM
        segm_config: SEGM é…ç½®

    Returns:
        SEGMDinoVisionTransformer model
    """
    model = SEGMDinoVisionTransformer(
        img_size=kwargs.get('img_size', 224),
        patch_size=16,
        embed_dim=768,
        depth=12,
        num_heads=12,
        ffn_ratio=4,
        segm_after_blocks=segm_after_blocks,
        segm_config=segm_config or {
            'num_freq_bins': 32,
            'hidden_dim': 256,
            'kappa_init': 1.0,
            'use_soft_modulation': True,
            'soft_temperature': 5.0,
            'use_periodicity_gate': True,
        },
        **kwargs
    )

    if pretrained_path:
        checkpoint = torch.load(pretrained_path, map_location='cpu')
        missing, unexpected = model.load_state_dict(checkpoint, strict=False)
        print(f"Loaded pretrained weights from {pretrained_path}")
        print(f"Missing keys (SEGM params): {len(missing)}")
        print(f"Unexpected keys: {len(unexpected)}")

    return model
```

### F.6 unsupervised_loss.py

```python
# segm_v2/losses/unsupervised_loss.py

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch import Tensor


class SEGMUnsupervisedLoss(nn.Module):
    """
    SEGM çš„è‡ªç›£ç£æå¤±å‡½æ•¸

    åŒ…å«:
        - L_intra: å³°å€¼ä½ç½®ç‰¹å¾µä¸€è‡´æ€§ï¼ˆæ ¸å¿ƒï¼‰
        - L_inter: å³°å€¼ vs è°·å€¼ç‰¹å¾µå€åˆ†åº¦ï¼ˆæ ¸å¿ƒï¼‰
        - L_period: Grid é€±æœŸæ€§ç´„æŸ
        - L_freq_smooth: é »ç‡å¹³æ»‘ç´„æŸ
        - L_sparse: ç¨€ç–æ€§ç´„æŸ
    """

    def __init__(
        self,
        intra_weight: float = 1.0,
        inter_weight: float = 1.0,
        period_weight: float = 0.5,
        freq_smooth_weight: float = 0.5,
        sparse_weight: float = 0.1,
        sparse_target: float = 0.1,
        peak_threshold: float = 0.5,
    ):
        super().__init__()

        self.intra_weight = intra_weight
        self.inter_weight = inter_weight
        self.period_weight = period_weight
        self.freq_smooth_weight = freq_smooth_weight
        self.sparse_weight = sparse_weight
        self.sparse_target = sparse_target
        self.peak_threshold = peak_threshold

    def forward(
        self,
        features: Tensor,
        grid: Tensor,
        freq_info: dict,
    ) -> dict:
        """
        è¨ˆç®—æ‰€æœ‰æå¤±é …

        Args:
            features: (B, H, W, C) - ç©ºé–“æ ¼å¼çš„ç‰¹å¾µ
            grid: (B, 1, H, W) - ç”Ÿæˆçš„ Grid
            freq_info: dict from RowFrequencyEstimator

        Returns:
            dict with 'total' and individual loss terms
        """
        B, H, W, C = features.shape
        grid_squeezed = grid.squeeze(1)  # (B, H, W)

        losses = {}

        # 1. L_intra: å³°å€¼ä½ç½®ç‰¹å¾µä¸€è‡´æ€§
        losses['intra'] = self._compute_intra_loss(features, grid_squeezed)

        # 2. L_inter: å³°å€¼ vs è°·å€¼ç‰¹å¾µå€åˆ†åº¦
        losses['inter'] = self._compute_inter_loss(features, grid_squeezed)

        # 3. L_period: Grid é€±æœŸæ€§ç´„æŸ
        losses['period'] = self._compute_period_loss(
            grid_squeezed,
            freq_info['dominant_freq']
        )

        # 4. L_freq_smooth: é »ç‡å¹³æ»‘ç´„æŸ
        losses['freq_smooth'] = self._compute_freq_smooth_loss(
            freq_info['dominant_freq']
        )

        # 5. L_sparse: ç¨€ç–æ€§ç´„æŸ
        losses['sparse'] = self._compute_sparse_loss(grid_squeezed)

        # ç¸½æå¤±
        losses['total'] = (
            self.intra_weight * losses['intra'] +
            self.inter_weight * losses['inter'] +
            self.period_weight * losses['period'] +
            self.freq_smooth_weight * losses['freq_smooth'] +
            self.sparse_weight * losses['sparse']
        )

        return losses

    def _compute_intra_loss(self, features: Tensor, grid: Tensor) -> Tensor:
        """
        L_intra: Grid å³°å€¼ä½ç½®çš„ç‰¹å¾µæ‡‰è©²å½¼æ­¤ç›¸ä¼¼

        Args:
            features: (B, H, W, C)
            grid: (B, H, W)

        Returns:
            scalar loss
        """
        B, H, W, C = features.shape

        # Flatten spatial dimensions
        features_flat = features.view(B, H * W, C)  # (B, N, C)
        grid_flat = grid.view(B, H * W)              # (B, N)

        total_loss = 0.0
        count = 0

        for b in range(B):
            # æ‰¾å‡ºå³°å€¼ä½ç½®
            peak_mask = grid_flat[b] > self.peak_threshold
            n_peaks = peak_mask.sum().item()

            if n_peaks < 2:
                continue

            # æå–å³°å€¼ç‰¹å¾µ
            peak_features = features_flat[b, peak_mask]  # (n_peaks, C)

            # æ­£è¦åŒ–
            peak_features_norm = F.normalize(peak_features, dim=-1)

            # è¨ˆç®—ç›¸ä¼¼åº¦çŸ©é™£
            sim_matrix = torch.mm(peak_features_norm, peak_features_norm.t())  # (n_peaks, n_peaks)

            # æ’é™¤å°è§’ç·šï¼Œè¨ˆç®—å¹³å‡ç›¸ä¼¼åº¦
            mask = ~torch.eye(n_peaks, dtype=torch.bool, device=sim_matrix.device)
            avg_sim = sim_matrix[mask].mean()

            # æœ€å¤§åŒ–ç›¸ä¼¼åº¦ = æœ€å°åŒ–è² ç›¸ä¼¼åº¦
            total_loss += -avg_sim
            count += 1

        if count == 0:
            return torch.tensor(0.0, device=features.device)

        return total_loss / count

    def _compute_inter_loss(self, features: Tensor, grid: Tensor) -> Tensor:
        """
        L_inter: å³°å€¼å€åŸŸå’Œè°·å€¼å€åŸŸçš„ç‰¹å¾µæ‡‰è©²ä¸åŒ

        Args:
            features: (B, H, W, C)
            grid: (B, H, W)

        Returns:
            scalar loss
        """
        B, H, W, C = features.shape

        # ä½¿ç”¨ grid ä½œç‚ºæ¬Šé‡
        grid_expanded = grid.unsqueeze(-1)  # (B, H, W, 1)

        # å³°å€¼å€åŸŸçš„åŠ æ¬Šå¹³å‡ç‰¹å¾µ
        peak_sum = (features * grid_expanded).sum(dim=[1, 2])  # (B, C)
        peak_weight = grid.sum(dim=[1, 2], keepdim=True) + 1e-6  # (B, 1)
        peak_features = peak_sum / peak_weight.squeeze(-1)  # (B, C)

        # è°·å€¼å€åŸŸçš„åŠ æ¬Šå¹³å‡ç‰¹å¾µ
        valley_mask = 1 - grid
        valley_expanded = valley_mask.unsqueeze(-1)  # (B, H, W, 1)
        valley_sum = (features * valley_expanded).sum(dim=[1, 2])  # (B, C)
        valley_weight = valley_mask.sum(dim=[1, 2], keepdim=True) + 1e-6  # (B, 1)
        valley_features = valley_sum / valley_weight.squeeze(-1)  # (B, C)

        # è¨ˆç®—ç›¸ä¼¼åº¦ï¼ˆæœ€å°åŒ– = æœ€å¤§åŒ–å€åˆ†åº¦ï¼‰
        peak_norm = F.normalize(peak_features, dim=-1)
        valley_norm = F.normalize(valley_features, dim=-1)
        similarity = (peak_norm * valley_norm).sum(dim=-1).mean()

        return similarity

    def _compute_period_loss(
        self,
        grid: Tensor,
        estimated_freq: Tensor
    ) -> Tensor:
        """
        L_period: Grid æ¯è¡Œçš„ FFT ä¸»é »ç‡æ‡‰èˆ‡ä¼°è¨ˆå€¼ä¸€è‡´

        Args:
            grid: (B, H, W)
            estimated_freq: (B, H) - ç¯„åœ [0, 1]

        Returns:
            scalar loss
        """
        B, H, W = grid.shape

        # å° Grid æ¯è¡Œåš FFT
        grid_fft = torch.fft.rfft(grid, dim=-1)  # (B, H, W//2+1)
        grid_power = torch.abs(grid_fft) ** 2

        # æ‰¾å‡º Grid çš„ä¸»é »ç‡ï¼ˆæ’é™¤ DCï¼‰
        grid_power_no_dc = grid_power[:, :, 1:]  # (B, H, W//2)
        grid_dominant_idx = grid_power_no_dc.argmax(dim=-1) + 1  # (B, H)

        # æ­£è¦åŒ–
        num_freq_bins = grid_power.shape[-1]
        grid_dominant_freq = grid_dominant_idx.float() / num_freq_bins

        # èˆ‡ä¼°è¨ˆçš„é »ç‡æ¯”è¼ƒ
        loss = F.l1_loss(grid_dominant_freq, estimated_freq)

        return loss

    def _compute_freq_smooth_loss(self, dominant_freq: Tensor) -> Tensor:
        """
        L_freq_smooth: ç›¸é„°è¡Œçš„é »ç‡æ‡‰è©²ç›¸ä¼¼

        Args:
            dominant_freq: (B, H)

        Returns:
            scalar loss
        """
        # è¨ˆç®—ç›¸é„°è¡Œçš„é »ç‡å·®
        freq_diff = torch.abs(dominant_freq[:, 1:] - dominant_freq[:, :-1])  # (B, H-1)
        loss = freq_diff.mean()

        return loss

    def _compute_sparse_loss(self, grid: Tensor) -> Tensor:
        """
        L_sparse: Grid æ‡‰è©²æ˜¯ç¨€ç–çš„

        Args:
            grid: (B, H, W)

        Returns:
            scalar loss
        """
        mean_activation = grid.mean()

        # è¶…éç›®æ¨™ç¨€ç–åº¦æ‰æ‡²ç½°
        loss = F.relu(mean_activation - self.sparse_target)

        return loss
```

### F.7 train.pyï¼ˆè¨“ç·´è…³æœ¬ç¯„ä¾‹ï¼‰

```python
# segm_v2/train.py

import argparse
import os
import sys

import torch
import torch.nn as nn
from torch.utils.data import DataLoader
from torchvision import transforms
from torchvision.datasets import ImageFolder
from tqdm import tqdm

# æ·»åŠ è·¯å¾‘
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from segm_v2.models.segm_vision_transformer import create_segm_dino_vitb16
from segm_v2.losses.unsupervised_loss import SEGMUnsupervisedLoss


def get_transform(img_size: int = 224):
    """ç²å–è³‡æ–™è½‰æ›"""
    return transforms.Compose([
        transforms.Resize((img_size, img_size)),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.485, 0.456, 0.406],
            std=[0.229, 0.224, 0.225]
        ),
    ])


def train_one_epoch(
    model: nn.Module,
    dataloader: DataLoader,
    criterion: SEGMUnsupervisedLoss,
    optimizer: torch.optim.Optimizer,
    device: torch.device,
    epoch: int,
):
    """è¨“ç·´ä¸€å€‹ epoch"""
    model.train()
    total_losses = {
        'total': 0.0,
        'intra': 0.0,
        'inter': 0.0,
        'period': 0.0,
        'freq_smooth': 0.0,
        'sparse': 0.0,
    }

    pbar = tqdm(dataloader, desc=f'Epoch {epoch}')
    for batch_idx, (images, _) in enumerate(pbar):
        images = images.to(device)
        B = images.shape[0]

        # Forward pass
        outputs = model.forward_features(images)

        # ç²å– SEGM è¼¸å‡º
        segm_outputs = model.get_segm_outputs()

        # å°æ¯å€‹ SEGM æ¨¡çµ„è¨ˆç®— loss
        batch_loss = 0.0
        for block_idx, segm_out in segm_outputs.items():
            freq_info = segm_out['freq_info']
            grid = segm_out['grid']

            # ç²å–å°æ‡‰çš„ features
            # éœ€è¦å¾ outputs ä¸­æå–ä¸¦ reshape
            patch_tokens = outputs['x_norm_patchtokens']  # (B, N, C)
            H = W = int(patch_tokens.shape[1] ** 0.5)
            features = patch_tokens.view(B, H, W, -1)  # (B, H, W, C)

            # è¨ˆç®— loss
            losses = criterion(features, grid, freq_info)
            batch_loss += losses['total']

            # ç´¯ç©å„é … loss ç”¨æ–¼è¨˜éŒ„
            for key in total_losses:
                total_losses[key] += losses[key].item()

        # Backward pass
        optimizer.zero_grad()
        batch_loss.backward()
        optimizer.step()

        # æ›´æ–°é€²åº¦æ¢
        pbar.set_postfix({
            'loss': f"{batch_loss.item():.4f}",
            'gate': f"{model.segm_modules['10'].gate.item():.4f}",
        })

    # å¹³å‡ loss
    n_batches = len(dataloader)
    for key in total_losses:
        total_losses[key] /= n_batches

    return total_losses


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--data_dir', type=str, required=True)
    parser.add_argument('--pretrained', type=str, required=True)
    parser.add_argument('--output_dir', type=str, default='./checkpoints')
    parser.add_argument('--img_size', type=int, default=224)
    parser.add_argument('--batch_size', type=int, default=16)
    parser.add_argument('--lr', type=float, default=1e-4)
    parser.add_argument('--epochs', type=int, default=100)
    parser.add_argument('--warmup_epochs', type=int, default=5)
    args = parser.parse_args()

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # å‰µå»ºæ¨¡å‹
    model = create_segm_dino_vitb16(
        pretrained_path=args.pretrained,
        img_size=args.img_size,
    ).to(device)

    # ç¢ºèªåªæœ‰ SEGM åƒæ•¸å¯è¨“ç·´
    trainable_params = [p for p in model.parameters() if p.requires_grad]
    print(f"Trainable parameters: {sum(p.numel() for p in trainable_params)}")

    # å‰µå»ºè³‡æ–™é›†
    transform = get_transform(args.img_size)
    dataset = ImageFolder(args.data_dir, transform=transform)
    dataloader = DataLoader(
        dataset,
        batch_size=args.batch_size,
        shuffle=True,
        num_workers=4,
        pin_memory=True,
    )
    print(f"Dataset size: {len(dataset)}")

    # å‰µå»ºæå¤±å‡½æ•¸å’Œå„ªåŒ–å™¨
    criterion = SEGMUnsupervisedLoss()
    optimizer = torch.optim.AdamW(
        trainable_params,
        lr=args.lr,
        weight_decay=0.01,
    )

    # å­¸ç¿’ç‡æ’ç¨‹ï¼ˆwarmupï¼‰
    def lr_lambda(epoch):
        if epoch < args.warmup_epochs:
            return (epoch + 1) / args.warmup_epochs
        return 1.0

    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)

    # è¨“ç·´è¿´åœˆ
    os.makedirs(args.output_dir, exist_ok=True)

    for epoch in range(args.epochs):
        losses = train_one_epoch(
            model, dataloader, criterion, optimizer, device, epoch
        )
        scheduler.step()

        # è¨˜éŒ„
        print(f"\nEpoch {epoch} Summary:")
        for key, value in losses.items():
            print(f"  {key}: {value:.4f}")
        print(f"  Gate value: {model.segm_modules['10'].gate.item():.4f}")
        print(f"  LR: {scheduler.get_last_lr()[0]:.6f}")

        # å„²å­˜ checkpoint
        if (epoch + 1) % 10 == 0:
            checkpoint_path = os.path.join(
                args.output_dir,
                f'segm_epoch_{epoch+1}.pth'
            )
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'losses': losses,
            }, checkpoint_path)
            print(f"Saved checkpoint to {checkpoint_path}")


if __name__ == '__main__':
    main()
```

### F.8 ä½¿ç”¨ç¯„ä¾‹

```python
# å®Œæ•´ä½¿ç”¨ç¯„ä¾‹

import torch
from segm_v2.models.segm_vision_transformer import create_segm_dino_vitb16

# 1. å‰µå»ºæ¨¡å‹
model = create_segm_dino_vitb16(
    pretrained_path='path/to/dinov3_vitb16.pth',
    segm_after_blocks=[10],
    segm_config={
        'num_freq_bins': 32,
        'hidden_dim': 256,
        'kappa_init': 1.0,
        'use_soft_modulation': True,
        'soft_temperature': 5.0,
        'use_periodicity_gate': True,
    }
)

# 2. ç¢ºèªåƒæ•¸ç‹€æ…‹
for name, param in model.named_parameters():
    if param.requires_grad:
        print(f"Trainable: {name}")
# è¼¸å‡ºæ‡‰è©²åªæœ‰ segm_modules.* çš„åƒæ•¸

# 3. Forward pass
model.eval()
with torch.no_grad():
    images = torch.randn(2, 3, 224, 224)  # å‡è¨­è¼¸å…¥
    outputs = model.forward_features(images)

    # è¼¸å‡ºçµæ§‹
    print(outputs['x_norm_clstoken'].shape)      # (2, 768)
    print(outputs['x_norm_patchtokens'].shape)   # (2, 196, 768)

    # ç²å– SEGM ä¸­é–“çµæœ
    segm_outputs = model.get_segm_outputs()
    grid = segm_outputs['10']['grid']            # (2, 1, 14, 14)
    freq_info = segm_outputs['10']['freq_info']
    print(freq_info['dominant_freq'].shape)      # (2, 14)

# 4. è¦–è¦ºåŒ– Grid
import matplotlib.pyplot as plt

grid_np = grid[0, 0].cpu().numpy()  # (14, 14)
plt.imshow(grid_np, cmap='hot')
plt.colorbar()
plt.title('Periodic Grid')
plt.savefig('grid_visualization.png')
```
